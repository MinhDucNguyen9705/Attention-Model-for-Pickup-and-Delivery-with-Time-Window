{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e09973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0236d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRPNode():\n",
    "    def __init__(self, idx, x, y, demand, a, b, s, role, pair):\n",
    "        super().__init__()\n",
    "        self.idx = idx\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.demand = demand\n",
    "        self.a = a  # earliest time\n",
    "        self.b = b  # latest time\n",
    "        self.s = s  # service time\n",
    "        self.role = role  # role of the node (1: pickup, 0: depot, -1: delivery)\n",
    "        self.pair = pair  # paired node (pickup-delivery)\n",
    "\n",
    "class VRPInstance():\n",
    "    def __init__(self, nodes, capacity, K, tmat):\n",
    "        super().__init__()\n",
    "        self.nodes = nodes\n",
    "        self.capacity = capacity  # vehicle capacity\n",
    "        self.K = K  # max number of vehicles\n",
    "        self.tmat = tmat  # [n, n] travel time matrix\n",
    "    \n",
    "    def build_tensors(self):\n",
    "        n = len(self.nodes)\n",
    "        coords = torch.tensor([[node.x, node.y] for node in self.nodes], dtype=torch.float32)\n",
    "        demand = torch.tensor([node.demand for node in self.nodes], dtype=torch.float32)\n",
    "        tw = torch.tensor([[node.a, node.b] for node in self.nodes], dtype=torch.float32)\n",
    "        service = torch.tensor([node.s for node in self.nodes], dtype=torch.float32)\n",
    "        role = torch.tensor([node.role for node in self.nodes], dtype=torch.int64)\n",
    "        pair = torch.tensor([node.pair for node in self.nodes], dtype=torch.int64)\n",
    "\n",
    "        return dict(\n",
    "            coords=coords,\n",
    "            demand=demand,\n",
    "            tw=tw,\n",
    "            service=service,\n",
    "            role=role,\n",
    "            pair=pair,\n",
    "            capacity=self.capacity,\n",
    "            K=self.K,\n",
    "            tmat=torch.tensor(self.tmat, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e515e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(instances):\n",
    "    ts = [ins.build_tensors() for ins in instances]\n",
    "    batch = {k: torch.stack([t[k] for t in ts]) for k in ts[0] if k not in ['capacity', 'K']}\n",
    "    batch['capacity'] = torch.tensor([ins.capacity for ins in instances], dtype=torch.float32)[:, None]\n",
    "    batch['K'] = torch.tensor([ins.K for ins in instances], dtype=torch.int64)[:, None]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31382437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdptw_file(filepath):\n",
    "    data = {\n",
    "        \"metadata\": {},\n",
    "        \"nodes\": [],\n",
    "        \"edges\": []\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    section = \"metadata\"\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Section switches\n",
    "        if line == \"NODES\":\n",
    "            section = \"nodes\"\n",
    "            continue\n",
    "        elif line == \"EDGES\":\n",
    "            section = \"edges\"\n",
    "            continue\n",
    "        elif line == \"EOF\":\n",
    "            break\n",
    "\n",
    "        if section == \"metadata\":\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                data[\"metadata\"][key.strip()] = value.strip()\n",
    "\n",
    "        elif section == \"nodes\":\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 8:\n",
    "                node = {\n",
    "                    \"id\": int(parts[0]),\n",
    "                    \"x\": float(parts[1]),\n",
    "                    \"y\": float(parts[2]),\n",
    "                    \"demand\": int(parts[3]),\n",
    "                    \"ready_time\": int(parts[4]),\n",
    "                    \"due_time\": int(parts[5]),\n",
    "                    \"service_time\": int(parts[6]),\n",
    "                    \"pickup_or_delivery\": 0 if (int(parts[7]) == 0 and int(parts[8]) == 0) else (-1 if int(parts[7]) > 0 else 1),  # 0 = depot, 1 = pickup, -1 = delivery,...\n",
    "                    \"pair_id\": int(parts[7]) if int(parts[7]) > 0 else int(parts[8])\n",
    "                }\n",
    "                data[\"nodes\"].append(node)\n",
    "\n",
    "        elif section == \"edges\":\n",
    "            weights = list(map(int, line.split()))\n",
    "            data[\"edges\"].append(weights)\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    for node_data in data[\"nodes\"]:\n",
    "        node = VRPNode(\n",
    "            idx=node_data[\"id\"],\n",
    "            x=node_data[\"x\"],\n",
    "            y=node_data[\"y\"],\n",
    "            demand=node_data[\"demand\"]/int(data['metadata'].get(\"CAPACITY\", 1)),\n",
    "            a=node_data[\"ready_time\"],\n",
    "            b=node_data[\"due_time\"],\n",
    "            s=node_data[\"service_time\"],\n",
    "            role=node_data[\"pickup_or_delivery\"],\n",
    "            pair=node_data[\"pair_id\"]\n",
    "        )\n",
    "        nodes.append(node)\n",
    "\n",
    "    capacity = int(data[\"metadata\"].get(\"CAPACITY\", 0))\n",
    "    K = int(data[\"metadata\"].get(\"NUM_VEHICLES\", 1e10))\n",
    "    dmat = data[\"edges\"]\n",
    "    instance = VRPInstance(nodes, capacity, K, dmat)\n",
    "\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03e0e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates tensor shape: torch.Size([101, 2])\n",
      "Demand tensor shape: torch.Size([101])\n",
      "Time windows tensor shape: torch.Size([101, 2])\n",
      "Service times tensor shape: torch.Size([101])\n",
      "Role tensor shape: torch.Size([101])\n",
      "Pair tensor shape: torch.Size([101])\n",
      "Travel time matrix shape: torch.Size([101, 101])\n"
     ]
    }
   ],
   "source": [
    "file_path = \"D:/OneDrive - Hanoi University of Science and Technology/Projects/Project 1/Data/Sartori&Buriol/Instances/n100/bar-n100-1.txt\"  # Replace with your actual file path\n",
    "instance = read_pdptw_file(file_path)\n",
    "instance_tensors = instance.build_tensors()\n",
    "print(\"Coordinates tensor shape:\", instance_tensors[\"coords\"].shape)\n",
    "print(\"Demand tensor shape:\", instance_tensors[\"demand\"].shape)\n",
    "print(\"Time windows tensor shape:\", instance_tensors[\"tw\"].shape)\n",
    "print(\"Service times tensor shape:\", instance_tensors[\"service\"].shape)\n",
    "print(\"Role tensor shape:\", instance_tensors[\"role\"].shape)\n",
    "print(\"Pair tensor shape:\", instance_tensors[\"pair\"].shape)\n",
    "print(\"Travel time matrix shape:\", instance_tensors[\"tmat\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e666ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "\n",
    "file_paths = glob.glob('D:/OneDrive - Hanoi University of Science and Technology/Projects/Project 1/Data/Sartori&Buriol/Instances/n100/*.txt')\n",
    "# instance2 = read_pdptw_file(\"D:/OneDrive - Hanoi University of Science and Technology/Projects/Project 1/Data/Sartori&Buriol/Instances/n100/bar-n100-2.txt\")\n",
    "for fp in file_paths:\n",
    "    instance = read_pdptw_file(fp)\n",
    "    instances.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418ea4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 101])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_instance = batchify(instances)\n",
    "batch_instance['demand'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be403ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "def _mask_long2byte(mask, n=None):\n",
    "    if n is None:\n",
    "        n = 8 * mask.size(-1)\n",
    "    return (mask[..., None] >> (torch.arange(8, out=mask.new()) * 8))[..., :n].to(torch.uint8).view(*mask.size()[:-1], -1)[..., :n]\n",
    "\n",
    "\n",
    "def _mask_byte2bool(mask, n=None):\n",
    "    if n is None:\n",
    "        n = 8 * mask.size(-1)\n",
    "    return (mask[..., None] & (mask.new_ones(8) << torch.arange(8, out=mask.new()) * 1)).view(*mask.size()[:-1], -1)[..., :n] > 0\n",
    "\n",
    "def mask_long2bool(mask, n=None):\n",
    "    assert mask.dtype == torch.int64\n",
    "    return _mask_byte2bool(_mask_long2byte(mask), n=n)\n",
    "\n",
    "def mask_long_scatter(mask, values, check_unset=True):\n",
    "    \"\"\"\n",
    "    Sets values in mask in dimension -1 with arbitrary batch dimensions\n",
    "    If values contains -1, nothing is set\n",
    "    Note: does not work for setting multiple values at once (like normal scatter)\n",
    "    \"\"\"\n",
    "    assert mask.size()[:-1] == values.size()\n",
    "    rng = torch.arange(mask.size(-1), out=mask.new())\n",
    "    values_ = values[..., None]  # Need to broadcast up do mask dim\n",
    "    # This indicates in which value of the mask a bit should be set\n",
    "    where = (values_ >= (rng * 64)) & (values_ < ((rng + 1) * 64))\n",
    "    # Optional: check that bit is not already set\n",
    "    assert not (check_unset and ((mask & (where.long() << (values_ % 64))) > 0).any())\n",
    "    # Set bit by shifting a 1 to the correct position\n",
    "    # (% not strictly necessary as bitshift is cyclic)\n",
    "    # since where is 0 if no value needs to be set, the bitshift has no effect\n",
    "    return mask | (where.long() << (values_ % 64))\n",
    "\n",
    "class StateCPDPTW(NamedTuple):\n",
    "    coords: torch.Tensor\n",
    "    demand: torch.Tensor\n",
    "    tw: torch.Tensor\n",
    "    service: torch.Tensor\n",
    "    role: torch.Tensor\n",
    "    pair: torch.Tensor\n",
    "    capacity: torch.Tensor\n",
    "    K: torch.Tensor\n",
    "    tmat: torch.Tensor\n",
    "\n",
    "    ids: torch.Tensor\n",
    "\n",
    "    prev_a: torch.Tensor\n",
    "    used_capacity: torch.Tensor\n",
    "    current_time: torch.Tensor\n",
    "    visited_: torch.Tensor\n",
    "    curr_visited: torch.Tensor\n",
    "    lengths: torch.Tensor\n",
    "    cur_coord: torch.Tensor\n",
    "    i: torch.Tensor\n",
    "\n",
    "    VEHICLE_CAPACITY = 1.0\n",
    "\n",
    "    @property\n",
    "    def visited(self):\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            return self.visited_\n",
    "        else:\n",
    "            return mask_long2bool(self.visited_, self.demand.size(-1))\n",
    "    \n",
    "    @property\n",
    "    def dist(self):\n",
    "        return (self.coords[:, :, None, :] - self.coords[:, None, :, :]).norm(p=2, dim=-1)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self._replace(\n",
    "            ids=self.ids[key],\n",
    "            prev_a=self.prev_a[key],\n",
    "            used_capacity=self.used_capacity[key],\n",
    "            current_time=self.current_time[key],\n",
    "            visited_=self.visited_[key],\n",
    "            lengths=self.lengths[key],\n",
    "            cur_coord=self.cur_coord[key],\n",
    "            curr_visited=self.curr_visited[key],\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize(input, visited_dtype=torch.uint8):\n",
    "\n",
    "        coords = input['coords']\n",
    "        demand = input['demand']\n",
    "        tw = input['tw']\n",
    "        service = input['service']\n",
    "        role = input['role']\n",
    "        pair = input['pair']\n",
    "        capacity = input['capacity']\n",
    "        K = input['K']\n",
    "        tmat = input['tmat']\n",
    "\n",
    "        batch_size, n_nodes, _ = coords.size()\n",
    "\n",
    "        return StateCPDPTW(\n",
    "            coords=coords,\n",
    "            demand=demand,\n",
    "            tw=tw,\n",
    "            service=service,\n",
    "            role=role,\n",
    "            pair=pair,\n",
    "            capacity=capacity,\n",
    "            K=K,\n",
    "            tmat=tmat,\n",
    "            ids=torch.arange(batch_size, dtype=torch.int64, device=coords.device)[:, None],\n",
    "            prev_a=torch.zeros(batch_size, 1, dtype=torch.long, device=coords.device),\n",
    "            used_capacity=demand.new_zeros(batch_size, 1),\n",
    "            current_time=torch.zeros(batch_size, 1, dtype=torch.long, device=coords.device),\n",
    "            visited_=(\n",
    "                torch.zeros(\n",
    "                    batch_size, 1, n_nodes,\n",
    "                    dtype=visited_dtype, device=coords.device\n",
    "                )\n",
    "                if visited_dtype == torch.uint8\n",
    "                else torch.zeros(batch_size, 1, (n_nodes + 62) // 64, dtype=torch.int64, device=coords.device)\n",
    "            ),\n",
    "            curr_visited=(\n",
    "                torch.zeros(\n",
    "                    batch_size, 1, n_nodes,\n",
    "                    dtype=visited_dtype, device=coords.device\n",
    "                )\n",
    "                if visited_dtype == torch.uint8\n",
    "                else torch.zeros(batch_size, 1, (n_nodes + 62) // 64, dtype=torch.int64, device=coords.device)\n",
    "            ),\n",
    "            lengths=torch.zeros(batch_size, 1, device=coords.device),\n",
    "            cur_coord=coords[:, 0, :],\n",
    "            i=torch.zeros(1, dtype=torch.long, device=coords.device),\n",
    "        )\n",
    "\n",
    "    def get_final_cost(self):\n",
    "\n",
    "        assert self.all_finished()\n",
    "\n",
    "        return self.lengths + (self.coords[self.ids, 0, :] - self.cur_coord).norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "    def update(self, selected):\n",
    "\n",
    "        selected = selected[:, None]\n",
    "        prev_a = selected\n",
    "        n_nodes = self.demand.size(-1) - 1\n",
    "\n",
    "        cur_coord = self.coords[self.ids, selected]\n",
    "        lengths = self.lengths + (cur_coord - self.cur_coord).norm(p=2, dim=-1)\n",
    "\n",
    "        selected_demand = self.demand[self.ids, torch.clamp(prev_a, 0, n_nodes)]\n",
    "\n",
    "        used_capacity = (self.used_capacity + selected_demand) * (prev_a != 0).float()\n",
    "        travel_time = self.tmat[self.ids, self.prev_a, prev_a]\n",
    "        arrival_time = self.current_time + travel_time\n",
    "        begin_service = torch.max(arrival_time, self.tw[self.ids, selected, 0:1])\n",
    "        current_time = begin_service + self.service[self.ids, selected]\n",
    "\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            visited_ = self.visited_.scatter(-1, prev_a[:, :, None], 1)\n",
    "            curr_visited = self.curr_visited.scatter(-1, prev_a[:, :, None], 1)\n",
    "            curr_visited = curr_visited * (prev_a[:, :, None] != 0).float()\n",
    "            current_time = current_time * (prev_a != 0).float()\n",
    "        else:\n",
    "            visited_ = mask_long_scatter(self.visited_, prev_a - 1)\n",
    "            curr_visited = mask_long_scatter(self.curr_visited, prev_a - 1)\n",
    "            reset_mask = (prev_a[:, :, None] == 0).long() * ((1 << (self.curr_visited.size(-1) * 64)) - 1)\n",
    "            curr_visited = curr_visited & (~reset_mask)\n",
    "            current_time = current_time * (prev_a != 0).float()\n",
    "        \n",
    "        return self._replace(\n",
    "            prev_a=prev_a, used_capacity=used_capacity, current_time=current_time,\n",
    "            visited_=visited_, curr_visited=curr_visited, lengths=lengths, cur_coord=cur_coord, i=self.i + 1\n",
    "        )\n",
    "    \n",
    "    def all_finished(self):\n",
    "        return self.i.item() >= self.demand.size(-1) and self.visited.all()\n",
    "\n",
    "    def get_finished(self):\n",
    "        return self.visited.sum(-1) == self.visited.size(-1)\n",
    "\n",
    "    def get_current_node(self):\n",
    "        return self.prev_a\n",
    "\n",
    "    def get_mask(self):\n",
    "\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            visited_loc = self.visited_[:, :, 1:]\n",
    "            curr_visited_loc = self.curr_visited[:, :, 1:]\n",
    "        else:\n",
    "            visited_loc = mask_long2bool(self.visited_, self.demand.size(-1))\n",
    "            curr_visited_loc = mask_long2bool(self.curr_visited, self.demand.size(-1))\n",
    "        \n",
    "        exceeds_cap = (self.demand[self.ids, 1:] + self.used_capacity[:, :, None] > self.VEHICLE_CAPACITY)\n",
    "\n",
    "        # print('Visited: ', visited_loc)\n",
    "        # print('Exceed:', exceeds_cap)\n",
    "\n",
    "        pairs = self.pair.long()[:, 1:]\n",
    "\n",
    "        delivery_mask = (self.role == -1)[:, 1:]\n",
    "\n",
    "        # print('Delivery: ', delivery_mask, delivery_mask.shape)\n",
    "\n",
    "        # delivery_unvisited = curr_visited_loc.squeeze(1)[delivery_mask]\n",
    "        # print('Delivery Unvisited: ', delivery_unvisited)\n",
    "\n",
    "        paired_pickup_unv = torch.gather(curr_visited_loc.squeeze(1), dim=1, index=pairs-1).to(delivery_mask.dtype)\n",
    "        # print('Paired Pickup Unvisited: ', paired_pickup_unv)\n",
    "        new_delivery_mask = delivery_mask ^ paired_pickup_unv\n",
    "        new_delivery_mask = new_delivery_mask.unsqueeze(1)\n",
    "        # print('Updated Delivery Mask: ', new_delivery_mask.to(delivery_mask.dtype), new_delivery_mask.shape)\n",
    "        # print('Mask Loc before update: ', mask_loc)\n",
    "        # print('Visited_loc shape: ', visited_loc.shape)\n",
    "        # print('Exceeds_cap shape: ', exceeds_cap.shape)\n",
    "        # print('New_delivery_mask shape: ', new_delivery_mask.shape)\n",
    "        mask_loc = visited_loc.to(exceeds_cap.dtype) | exceeds_cap | new_delivery_mask.to(delivery_mask.dtype)\n",
    "        # print('Mask Loc: ', mask_loc, mask_loc.shape)\n",
    "        # delivery_unvisited = mask_loc[delivery_mask.unsqueeze(1).expand_as(mask_loc)]\n",
    "            \n",
    "        delivery_unvisited = mask_loc[delivery_mask.unsqueeze(1).expand_as(mask_loc)]  # shape: (total_true,)\n",
    "        delivery_unvisited = delivery_unvisited.view(mask_loc.shape[0], -1)\n",
    "        # print('Delivery Unvisited: ', delivery_unvisited, delivery_unvisited.shape)\n",
    "\n",
    "        #Check time window constraints\n",
    "        batch_size, n_loc = mask_loc.shape[0], mask_loc.shape[2]\n",
    "        travel_time_to_v = self.tmat[self.ids, self.prev_a, :]                      # [B,1,Np1]\n",
    "        arrival_to_v = self.current_time + travel_time_to_v             # [B,1,Np1]\n",
    "        a_v = self.tw[self.ids, torch.arange(n_loc+1), 0][..., None, :]  # [B,1,Np1]\n",
    "        b_v = self.tw[self.ids, torch.arange(n_loc+1), 1][..., None, :]  # [B,1,Np1]\n",
    "\n",
    "        arrive_ok = (arrival_to_v <= b_v)                               # [B,1,Np1]\n",
    "        begin_service_v = torch.maximum(arrival_to_v, a_v)              # [B,1,Np1]\n",
    "        service_v = self.service[self.ids, torch.arange(n_loc+1)][..., None, :]  # [B,1,Np1]\n",
    "        time_after_v = begin_service_v + service_v\n",
    "        # print('Time After V: ', time_after_v, time_after_v.shape)\n",
    "\n",
    "        # If v is a pickup, include its delivery's travel + wait to a_d + service_d\n",
    "        is_v_pickup = (self.role == 1)                                            # [B,Np1]\n",
    "        d_of_v = self.pair                                                        # [B,Np1]\n",
    "        has_valid_d = (d_of_v > 0) & is_v_pickup                             # [B,Np1]\n",
    "\n",
    "        # Build per-(b,v) indexing to get t(v->d), a_d, b_d, service_d\n",
    "        bf = torch.arange(batch_size)[:, None].expand(batch_size, n_loc + 1)          # [B,Np1]\n",
    "        v_idx = torch.arange(n_loc+1)[None, :].expand(batch_size, n_loc + 1)                              # [B,Np1]\n",
    "        d_idx = d_of_v.clamp(min=0)                                          # [B,Np1]\n",
    "\n",
    "        t_v_d = self.tmat[bf, v_idx, d_idx]                                       # [B,Np1]\n",
    "        a_d = self.tw[bf, d_idx, 0]                                               # [B,Np1]\n",
    "        b_d = self.tw[bf, d_idx, 1]                                               # [B,Np1]\n",
    "        service_d = self.service[bf, d_idx]                                       # [B,Np1]\n",
    "\n",
    "        arrival_d = time_after_v.squeeze(1) + t_v_d                          # [B,Np1]\n",
    "        begin_d = torch.maximum(arrival_d, a_d)                              # [B,Np1]\n",
    "        complete_d = begin_d + service_d                                     # [B,Np1]\n",
    "\n",
    "        # Apply pickup adjustment only where valid (keep original time for others)\n",
    "        delta_pick = (complete_d - time_after_v.squeeze(1)) * has_valid_d    # [B,Np1]\n",
    "        time_after_v_adj = time_after_v + delta_pick[:, None, :]             # [B,1,Np1]\n",
    "        # print('Time After V Adj: ', time_after_v_adj, time_after_v_adj.shape)\n",
    "\n",
    "        # print(self.visited_.dtype, self.curr_visited.dtype)\n",
    "        visited_full = (self.visited_ if self.visited_.dtype == torch.uint8 else mask_long2bool(self.visited_, n_loc+1)).bool()\n",
    "        curr_vis_full = (self.curr_visited if self.visited_.dtype == torch.uint8 else mask_long2bool(self.curr_visited, n_loc+1)).bool()\n",
    "        visited = visited_full[:, :, 1:]                                     # [B,1,N]\n",
    "        curr_vis = curr_vis_full[:, :, 1:]                                   # [B,1,N]\n",
    "\n",
    "        is_del_full = (self.role == -1)                                           # [B,Np1]\n",
    "        is_del = is_del_full[:, 1:]                                          # [B,N]\n",
    "        not_visited = ~visited                                               # [B,1,N]\n",
    "        pairs_non_depot = self.pair[:, 1:]                                        # [B,N]\n",
    "        paired_pick_for_del = torch.gather(curr_vis.squeeze(1), 1, pairs_non_depot - 1).bool()  # [B,N]\n",
    "        open_del_before = (is_del & paired_pick_for_del & not_visited.squeeze(1))               # [B,N]\n",
    "\n",
    "        open_after_v = open_del_before.unsqueeze(1).expand(batch_size, n_loc+1, n_loc).clone() # [B,Np1,N]\n",
    "        # remove delivery j if v == j and v is a delivery\n",
    "        idx_all = torch.arange(n_loc+1)\n",
    "        idx_1_to_N = torch.arange(1, n_loc+1)\n",
    "        v_eq_j_mask = (idx_1_to_N.unsqueeze(0).unsqueeze(0) == idx_all.unsqueeze(0).unsqueeze(2))  # [1,Np1,N]\n",
    "        remove_mask = v_eq_j_mask & is_del_full.unsqueeze(-1)                # [B,Np1,N]\n",
    "        open_after_v = open_after_v & (~remove_mask)\n",
    "\n",
    "        # add paired delivery of v if v is pickup\n",
    "        one_hot_j = torch.zeros(batch_size, n_loc+1, n_loc, dtype=torch.bool)\n",
    "        for b in range(batch_size):\n",
    "            vs = torch.nonzero(has_valid_d[b], as_tuple=False).squeeze(-1)\n",
    "            if vs.numel() > 0:\n",
    "                js = (d_of_v[b, vs] - 1).clamp(min=0)\n",
    "                one_hot_j[b, vs, js] = True\n",
    "        open_after_v = open_after_v | one_hot_j\n",
    "\n",
    "        t_from_v_to_j = self.tmat[self.ids, idx_all[None, :, None], idx_1_to_N[None, None, :]]\n",
    "\n",
    "        a_j = self.tw[self.ids, idx_1_to_N, 0][:, None, :]                   # [B,1,N]\n",
    "        b_j = self.tw[self.ids, idx_1_to_N, 1][:, None, :]                   # [B,1,N]\n",
    "        service_j = self.service[self.ids, idx_1_to_N][:, None, :]\n",
    "\n",
    "        # arrival to j and begin_service_j considering earliest time\n",
    "        # print('Time after v adj shape: ', time_after_v_adj.shape)   \n",
    "        # print('t from v to j shape: ', t_from_v_to_j.shape)\n",
    "        arrival_vj = time_after_v_adj.transpose(1, 2)  + t_from_v_to_j                   # [B,Np1,N]\n",
    "        # print('Arrival VJ: ', arrival_vj, arrival_vj.shape)\n",
    "        # print('a_j shape: ', a_j.shape, a_j[:, None, :].shape)\n",
    "        begin_vj = torch.maximum(arrival_vj, a_j)           # [B,Np1,N]\n",
    "        # print('Begin VJ: ', begin_vj, begin_vj.shape)\n",
    "\n",
    "        # Feasible if we can START by b_j (standard PDPTW: b is latest start)\n",
    "        feas_open_after = (begin_vj <= b_j)                 # [B,Np1,N]\n",
    "        # print('Feas Open After: ', feas_open_after, feas_open_after.shape)\n",
    "        all_open_ok = torch.where(open_after_v, feas_open_after, torch.ones_like(feas_open_after)).all(dim=-1, keepdim=True)  # [B,Np1,1]\n",
    "\n",
    "        # Local feasibility at v: arrival_to_v must be â‰¤ b_v as usual\n",
    "        tw_ok_v = (arrival_to_v <= b_v) & all_open_ok.transpose(1, 2)\n",
    "        # print('TW OK V before depot check: ', tw_ok_v, tw_ok_v.shape) \n",
    "\n",
    "        INF = 1e12\n",
    "        B, Np1 = self.demand.size(0), self.demand.size(-1)\n",
    "        N = Np1 - 1\n",
    "        idx_all = torch.arange(Np1, device=self.demand.device)\n",
    "        idx_1_to_N = torch.arange(1, Np1, device=self.demand.device)\n",
    "\n",
    "        a0 = self.tw[self.ids, 0, 0]     # [B]\n",
    "        b0 = self.tw[self.ids, 0, 1]     # [B]\n",
    "\n",
    "        S = open_after_v                         # [B,Np1,N] bool\n",
    "        has_open = S.any(dim=-1)                 # [B,Np1]\n",
    "\n",
    "        # First leg: min_j t(v->j)\n",
    "        t_vj_masked = t_from_v_to_j.masked_fill(~S, INF)     # [B,Np1,N]\n",
    "        min_first_leg, _ = t_vj_masked.min(dim=-1)           # [B,Np1]\n",
    "        min_first_leg = torch.where(has_open, min_first_leg, torch.zeros_like(min_first_leg))\n",
    "\n",
    "        # Sum service over open deliveries\n",
    "        svc_sum = (service_j[:, None, :] * S.float()).sum(dim=-1)    # [B,Np1]\n",
    "\n",
    "        # Last leg: min_j t(j->0)\n",
    "        t_j0 = self.tmat[self.ids, idx_1_to_N, 0]                    # [B,N]\n",
    "        t_j0_masked = t_j0[:, None, :].masked_fill(~S, INF)          # [B,Np1,N]\n",
    "        min_last_leg, _ = t_j0_masked.min(dim=-1)                    # [B,Np1]\n",
    "\n",
    "        # If S non-empty: LB = T_v (squeezed) + min_first_leg + svc_sum + min_last_leg\n",
    "        # Else: LB = T_v + t(v->0)\n",
    "        t_v0 = self.tmat[self.ids, idx_all, 0]                       # [B,Np1]\n",
    "        lb_with_open = time_after_v_adj.squeeze(1) + min_first_leg + svc_sum + min_last_leg  # [B,Np1]\n",
    "        lb_no_open   = time_after_v_adj.squeeze(1) + t_v0                                    # [B,Np1]\n",
    "        lb_finish_and_return = torch.where(has_open, lb_with_open, lb_no_open)               # [B,Np1]\n",
    "\n",
    "        # Respect depot earliest; enforce latest\n",
    "        begin_depot = torch.maximum(lb_finish_and_return, a0[:, None])   # [B,Np1]\n",
    "        depot_ok = (begin_depot <= b0[:, None])                           # [B,Np1]\n",
    "\n",
    "        # Fold into the node-level TW check\n",
    "        # print('Depot OK: ', depot_ok, depot_ok.shape)\n",
    "        tw_ok_v = tw_ok_v & depot_ok                          # [B,1,Np1]\n",
    "        # print('TW OK V: ', tw_ok_v, tw_ok_v.shape)\n",
    "\n",
    "        # Check time constraints for deliveries\n",
    "        # for i in range(batch_size):\n",
    "        #     delivery_indices = torch.where(paired_pickup_unv[i])[0]+1\n",
    "        #     print('Batch ', i, ' Delivery Indices: ', delivery_indices)\n",
    "\n",
    "        mask_depot = ((self.prev_a == 0) | ~delivery_unvisited.all(dim=1, keepdim=True)) & ((mask_loc == 0).int().sum(-1) > 0)\n",
    "        # print('Mask Depot: ', self.prev_a == 0, ((mask_loc == 0).int().sum(-1) > 0), ~delivery_unvisited.all(dim=1, keepdim=True), mask_depot)\n",
    "        mask_loc = mask_loc | (~tw_ok_v[:, :, 1:].to(mask_loc.dtype))\n",
    "        # print('Mask loc final: ', mask_loc, mask_loc.shape)\n",
    "        mask = torch.cat([mask_depot[:, :, None], mask_loc], dim=-1)\n",
    "\n",
    "        if mask.all():\n",
    "            # Allow at least returning to depot\n",
    "            mask[:, :, 0] = 0\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def construct_solutions(self, actions):\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "067901fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "def _mask_long2byte(mask, n=None):\n",
    "    if n is None:\n",
    "        n = 8 * mask.size(-1)\n",
    "    return (mask[..., None] >> (torch.arange(8, out=mask.new()) * 8))[..., :n].to(torch.uint8).view(*mask.size()[:-1], -1)[..., :n]\n",
    "\n",
    "\n",
    "def _mask_byte2bool(mask, n=None):\n",
    "    if n is None:\n",
    "        n = 8 * mask.size(-1)\n",
    "    return (mask[..., None] & (mask.new_ones(8) << torch.arange(8, out=mask.new()) * 1)).view(*mask.size()[:-1], -1)[..., :n] > 0\n",
    "\n",
    "def mask_long2bool(mask, n=None):\n",
    "    assert mask.dtype == torch.int64\n",
    "    return _mask_byte2bool(_mask_long2byte(mask), n=n)\n",
    "\n",
    "def mask_long_scatter(mask, values, check_unset=True):\n",
    "    \"\"\"\n",
    "    Sets values in mask in dimension -1 with arbitrary batch dimensions\n",
    "    If values contains -1, nothing is set\n",
    "    Note: does not work for setting multiple values at once (like normal scatter)\n",
    "    \"\"\"\n",
    "    assert mask.size()[:-1] == values.size()\n",
    "    rng = torch.arange(mask.size(-1), out=mask.new())\n",
    "    values_ = values[..., None]  # Need to broadcast up do mask dim\n",
    "    # This indicates in which value of the mask a bit should be set\n",
    "    where = (values_ >= (rng * 64)) & (values_ < ((rng + 1) * 64))\n",
    "    # Optional: check that bit is not already set\n",
    "    assert not (check_unset and ((mask & (where.long() << (values_ % 64))) > 0).any())\n",
    "    # Set bit by shifting a 1 to the correct position\n",
    "    # (% not strictly necessary as bitshift is cyclic)\n",
    "    # since where is 0 if no value needs to be set, the bitshift has no effect\n",
    "    return mask | (where.long() << (values_ % 64))\n",
    "\n",
    "class StateCPDPTW(NamedTuple):\n",
    "    coords: torch.Tensor\n",
    "    demand: torch.Tensor\n",
    "    tw: torch.Tensor\n",
    "    service: torch.Tensor\n",
    "    role: torch.Tensor\n",
    "    pair: torch.Tensor\n",
    "    capacity: torch.Tensor\n",
    "    K: torch.Tensor\n",
    "    tmat: torch.Tensor\n",
    "\n",
    "    ids: torch.Tensor\n",
    "\n",
    "    prev_a: torch.Tensor\n",
    "    used_capacity: torch.Tensor\n",
    "    current_time: torch.Tensor\n",
    "    visited_: torch.Tensor\n",
    "    curr_visited: torch.Tensor\n",
    "    lengths: torch.Tensor\n",
    "    cur_coord: torch.Tensor\n",
    "    i: torch.Tensor\n",
    "\n",
    "    VEHICLE_CAPACITY = 1.0\n",
    "\n",
    "    @property\n",
    "    def visited(self):\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            return self.visited_\n",
    "        else:\n",
    "            return mask_long2bool(self.visited_, self.demand.size(-1))\n",
    "    \n",
    "    @property\n",
    "    def dist(self):\n",
    "        return (self.coords[:, :, None, :] - self.coords[:, None, :, :]).norm(p=2, dim=-1)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self._replace(\n",
    "            ids=self.ids[key],\n",
    "            prev_a=self.prev_a[key],\n",
    "            used_capacity=self.used_capacity[key],\n",
    "            current_time=self.current_time[key],\n",
    "            visited_=self.visited_[key],\n",
    "            lengths=self.lengths[key],\n",
    "            cur_coord=self.cur_coord[key],\n",
    "            curr_visited=self.curr_visited[key],\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize(input, visited_dtype=torch.uint8):\n",
    "\n",
    "        coords = input['coords']\n",
    "        demand = input['demand']\n",
    "        tw = input['tw']\n",
    "        service = input['service']\n",
    "        role = input['role']\n",
    "        pair = input['pair']\n",
    "        capacity = input['capacity']\n",
    "        K = input['K']\n",
    "        tmat = input['tmat']\n",
    "\n",
    "        batch_size, n_nodes, _ = coords.size()\n",
    "\n",
    "        return StateCPDPTW(\n",
    "            coords=coords,\n",
    "            demand=demand,\n",
    "            tw=tw,\n",
    "            service=service,\n",
    "            role=role,\n",
    "            pair=pair,\n",
    "            capacity=capacity,\n",
    "            K=K,\n",
    "            tmat=tmat,\n",
    "            ids=torch.arange(batch_size, dtype=torch.int64, device=coords.device)[:, None],\n",
    "            prev_a=torch.zeros(batch_size, 1, dtype=torch.long, device=coords.device),\n",
    "            used_capacity=demand.new_zeros(batch_size, 1),\n",
    "            current_time=torch.zeros(batch_size, 1, dtype=torch.long, device=coords.device),\n",
    "            visited_=(\n",
    "                torch.zeros(\n",
    "                    batch_size, 1, n_nodes,\n",
    "                    dtype=visited_dtype, device=coords.device\n",
    "                )\n",
    "                if visited_dtype == torch.uint8\n",
    "                else torch.zeros(batch_size, 1, (n_nodes + 62) // 64, dtype=torch.int64, device=coords.device)\n",
    "            ),\n",
    "            curr_visited=(\n",
    "                torch.zeros(\n",
    "                    batch_size, 1, n_nodes,\n",
    "                    dtype=visited_dtype, device=coords.device\n",
    "                )\n",
    "                if visited_dtype == torch.uint8\n",
    "                else torch.zeros(batch_size, 1, (n_nodes + 62) // 64, dtype=torch.int64, device=coords.device)\n",
    "            ),\n",
    "            lengths=torch.zeros(batch_size, 1, device=coords.device),\n",
    "            cur_coord=coords[:, 0, :],\n",
    "            i=torch.zeros(1, dtype=torch.long, device=coords.device),\n",
    "        )\n",
    "\n",
    "    def get_final_cost(self):\n",
    "\n",
    "        assert self.all_finished()\n",
    "\n",
    "        return self.lengths + (self.coords[self.ids, 0, :] - self.cur_coord).norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "    def update(self, selected):\n",
    "\n",
    "        selected = selected[:, None]\n",
    "        prev_a = selected\n",
    "        n_nodes = self.demand.size(-1) - 1\n",
    "\n",
    "        cur_coord = self.coords[self.ids, selected]\n",
    "        lengths = self.lengths + (cur_coord - self.cur_coord).norm(p=2, dim=-1)\n",
    "\n",
    "        selected_demand = self.demand[self.ids, torch.clamp(prev_a, 0, n_nodes)]\n",
    "\n",
    "        used_capacity = (self.used_capacity + selected_demand) * (prev_a != 0).float()\n",
    "        travel_time = self.tmat[self.ids, self.prev_a, prev_a]\n",
    "        # print('travel_time shape: ', travel_time.shape)\n",
    "        arrival_time = self.current_time + travel_time\n",
    "        # print('arrival_time shape: ', arrival_time.shape)\n",
    "        # print('self.tw shape: ', self.tw[self.ids, selected, 0:1].shape)\n",
    "        begin_service = torch.max(arrival_time[:, None, :], self.tw[self.ids, selected, 0:1])\n",
    "        current_time = begin_service.squeeze(1) + self.service[self.ids, selected]\n",
    "\n",
    "        # print('service shape: ', self.service.shape)\n",
    "        # print('begin_service shape: ', begin_service.shape)\n",
    "        # print('current_time shape: ', self.current_time.shape)\n",
    "\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            visited_ = self.visited_.scatter(-1, prev_a[:, :, None], 1)\n",
    "            curr_visited = self.curr_visited.scatter(-1, prev_a[:, :, None], 1)\n",
    "            curr_visited = curr_visited * (prev_a[:, :, None] != 0).float()\n",
    "            current_time = current_time * (prev_a != 0).float()\n",
    "        else:\n",
    "            visited_ = mask_long_scatter(self.visited_, prev_a - 1)\n",
    "            curr_visited = mask_long_scatter(self.curr_visited, prev_a - 1)\n",
    "            reset_mask = (prev_a[:, :, None] == 0).long() * ((1 << (self.curr_visited.size(-1) * 64)) - 1)\n",
    "            curr_visited = curr_visited & (~reset_mask)\n",
    "            current_time = current_time * (prev_a != 0).float()\n",
    "        \n",
    "        return self._replace(\n",
    "            prev_a=prev_a, used_capacity=used_capacity, current_time=current_time,\n",
    "            visited_=visited_, curr_visited=curr_visited, lengths=lengths, cur_coord=cur_coord, i=self.i + 1\n",
    "        )\n",
    "    \n",
    "    def all_finished(self):\n",
    "        return self.i.item() >= self.demand.size(-1) and self.visited.all()\n",
    "\n",
    "    def get_finished(self):\n",
    "        return self.visited.sum(-1) == self.visited.size(-1)\n",
    "\n",
    "    def get_current_node(self):\n",
    "        return self.prev_a\n",
    "\n",
    "    def get_mask(self):\n",
    "\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            visited_loc = self.visited_[:, :, 1:]\n",
    "            curr_visited_loc = self.curr_visited[:, :, 1:]\n",
    "        else:\n",
    "            visited_loc = mask_long2bool(self.visited_, self.demand.size(-1))\n",
    "            curr_visited_loc = mask_long2bool(self.curr_visited, self.demand.size(-1))\n",
    "        \n",
    "        exceeds_cap = (self.demand[self.ids, 1:] + self.used_capacity[:, :, None] > self.VEHICLE_CAPACITY)\n",
    "        # print('Demand: ', self.demand[self.ids, 1:])\n",
    "        # print('Used Capacity: ', self.used_capacity[:, :, None])\n",
    "        # print('Sum: ', self.demand[self.ids, 1:] + self.used_capacity[:, :, None])\n",
    "        # print('Exceed:', exceeds_cap)\n",
    "\n",
    "        pairs = self.pair.long()[:, 1:]\n",
    "\n",
    "        delivery_mask = (self.role == -1)[:, 1:]\n",
    "\n",
    "        # print('Delivery: ', delivery_mask, delivery_mask.shape)\n",
    "\n",
    "        # delivery_unvisited = curr_visited_loc.squeeze(1)[delivery_mask]\n",
    "        # print('Delivery Unvisited: ', delivery_unvisited)\n",
    "\n",
    "        paired_pickup_unv = torch.gather(curr_visited_loc.squeeze(1), dim=1, index=pairs-1).to(delivery_mask.dtype)\n",
    "        # print('Paired Pickup Unvisited: ', paired_pickup_unv)\n",
    "        new_delivery_mask = delivery_mask ^ paired_pickup_unv\n",
    "        new_delivery_mask = new_delivery_mask.unsqueeze(1)\n",
    "        # print('Updated Delivery Mask: ', new_delivery_mask.to(delivery_mask.dtype), new_delivery_mask.shape)\n",
    "        # print('Mask Loc before update: ', mask_loc)\n",
    "        # print('Visited_loc shape: ', visited_loc.shape)\n",
    "        # print('Exceeds_cap shape: ', exceeds_cap.shape)\n",
    "        # print('New_delivery_mask shape: ', new_delivery_mask.shape)\n",
    "        mask_loc = visited_loc.to(exceeds_cap.dtype) | exceeds_cap | new_delivery_mask.to(delivery_mask.dtype)\n",
    "        # print('Mask Loc: ', mask_loc, mask_loc.shape)\n",
    "        # delivery_unvisited = mask_loc[delivery_mask.unsqueeze(1).expand_as(mask_loc)]\n",
    "            \n",
    "        delivery_unvisited = mask_loc[delivery_mask.unsqueeze(1).expand_as(mask_loc)]  # shape: (total_true,)\n",
    "        delivery_unvisited = delivery_unvisited.view(mask_loc.shape[0], -1)\n",
    "        # print('Delivery Unvisited: ', delivery_unvisited, delivery_unvisited.shape)\n",
    "\n",
    "        #Check time window constraints\n",
    "        batch_size, n_loc = mask_loc.shape[0], mask_loc.shape[2]\n",
    "        travel_time_to_v = self.tmat[self.ids, self.prev_a, :]                      # [B,1,Np1]\n",
    "        arrival_to_v = self.current_time[:, None, :] + travel_time_to_v             # [B,1,Np1]\n",
    "        # print('self.current_time shape: ', self.current_time.shape)\n",
    "        # print('travel_time_to_v shape: ', travel_time_to_v.shape)\n",
    "        a_v = self.tw[self.ids, torch.arange(n_loc+1), 0][..., None, :]  # [B,1,Np1]\n",
    "        b_v = self.tw[self.ids, torch.arange(n_loc+1), 1][..., None, :]  # [B,1,Np1]\n",
    "\n",
    "        arrive_ok = (arrival_to_v <= b_v)                               # [B,1,Np1]\n",
    "        # print('arrival_to_v shape: ', arrival_to_v.shape)\n",
    "        # print('a_v shape: ', a_v.shape)\n",
    "        begin_service_v = torch.maximum(arrival_to_v, a_v)              # [B,1,Np1]\n",
    "        service_v = self.service[self.ids, torch.arange(n_loc+1)][..., None, :]  # [B,1,Np1]\n",
    "        time_after_v = begin_service_v + service_v\n",
    "        # print('Time After V: ', time_after_v, time_after_v.shape)\n",
    "        # print('service_v shape: ', service_v.shape)\n",
    "        # print('begin_service_v shape: ', begin_service_v.shape)\n",
    "        # print('time_after_v shape: ', time_after_v.shape)\n",
    "\n",
    "        # If v is a pickup, include its delivery's travel + wait to a_d + service_d\n",
    "        is_v_pickup = (self.role == 1)                                            # [B,Np1]\n",
    "        d_of_v = self.pair                                                        # [B,Np1]\n",
    "        has_valid_d = (d_of_v > 0) & is_v_pickup                             # [B,Np1]\n",
    "\n",
    "        # Build per-(b,v) indexing to get t(v->d), a_d, b_d, service_d\n",
    "        bf = torch.arange(batch_size)[:, None].expand(batch_size, n_loc + 1)          # [B,Np1]\n",
    "        v_idx = torch.arange(n_loc+1)[None, :].expand(batch_size, n_loc + 1)                              # [B,Np1]\n",
    "        d_idx = d_of_v.clamp(min=0)                                          # [B,Np1]\n",
    "\n",
    "        t_v_d = self.tmat[bf, v_idx, d_idx]                                       # [B,Np1]\n",
    "        a_d = self.tw[bf, d_idx, 0]                                               # [B,Np1]\n",
    "        b_d = self.tw[bf, d_idx, 1]                                               # [B,Np1]\n",
    "        service_d = self.service[bf, d_idx]                                       # [B,Np1]\n",
    "\n",
    "        arrival_d = time_after_v.squeeze(1) + t_v_d                          # [B,Np1]\n",
    "        begin_d = torch.maximum(arrival_d, a_d)                              # [B,Np1]\n",
    "        complete_d = begin_d + service_d                                     # [B,Np1]\n",
    "        # print('arrival_d shape: ', arrival_d.shape)\n",
    "        # print('a_d shape: ', a_d.shape)\n",
    "        # print('begin_d shape: ', begin_d.shape)\n",
    "        # print('complete_d shape: ', complete_d.shape)\n",
    "\n",
    "        # Apply pickup adjustment only where valid (keep original time for others)\n",
    "        delta_pick = (complete_d - time_after_v.squeeze(1)) * has_valid_d    # [B,Np1]\n",
    "        time_after_v_adj = time_after_v + delta_pick[:, None, :]             # [B,1,Np1]\n",
    "        # print('Time After V Adj: ', time_after_v_adj, time_after_v_adj.shape)\n",
    "        # print(d_idx[has_valid_d])\n",
    "\n",
    "        # for i in range(batch_size):\n",
    "        #     remaining_delivery_indices = torch.where(paired_pickup_unv[i])[0]+1\n",
    "        #     # Append d_idx to remaining_delivery_indices\n",
    "        #     remaining_delivery_indices = torch.cat([remaining_delivery_indices, d_idx[has_valid_d]], dim=0)\n",
    "        #     print('Batch ', i, ' Remaining Delivery Indices: ', remaining_delivery_indices)\n",
    "\n",
    "        visited_full = (self.visited_ if self.visited_.dtype == torch.uint8 else mask_long2bool(self.visited_, n_loc+1)).bool()\n",
    "        curr_vis_full = (self.curr_visited if self.visited_.dtype == torch.uint8 else mask_long2bool(self.curr_visited, n_loc+1)).bool()\n",
    "        visited = visited_full[:, :, 1:]                                     # [B,1,N]\n",
    "        curr_vis = curr_vis_full[:, :, 1:]                                   # [B,1,N]\n",
    "\n",
    "        is_del_full = (self.role == -1)                                           # [B,Np1]\n",
    "        is_del = is_del_full[:, 1:]                                          # [B,N]\n",
    "        not_visited = ~visited                                               # [B,1,N]\n",
    "        pairs_non_depot = self.pair[:, 1:]                                        # [B,N]\n",
    "        paired_pick_for_del = torch.gather(curr_vis.squeeze(1), 1, pairs_non_depot - 1).bool()  # [B,N]\n",
    "        open_del_before = (is_del & paired_pick_for_del & not_visited.squeeze(1))               # [B,N]\n",
    "\n",
    "        open_after_v = open_del_before.unsqueeze(1).expand(batch_size, n_loc+1, n_loc).clone() # [B,Np1,N]\n",
    "\n",
    "        # remove delivery j if v == j and v is a delivery\n",
    "        idx_all = torch.arange(n_loc+1)\n",
    "        idx_1_to_N = torch.arange(1, n_loc+1)\n",
    "        v_eq_j_mask = (idx_1_to_N.unsqueeze(0).unsqueeze(0) == idx_all.unsqueeze(0).unsqueeze(2))  # [1,Np1,N]\n",
    "        remove_mask = v_eq_j_mask & is_del_full.unsqueeze(-1)                # [B,Np1,N]\n",
    "        open_after_v = open_after_v & (~remove_mask)\n",
    "\n",
    "        # add paired delivery of v if v is pickup\n",
    "        one_hot_j = torch.zeros(batch_size, n_loc+1, n_loc, dtype=torch.bool)\n",
    "        for b in range(batch_size):\n",
    "            vs = torch.nonzero(has_valid_d[b], as_tuple=False).squeeze(-1)\n",
    "            if vs.numel() > 0:\n",
    "                js = (d_of_v[b, vs] - 1).clamp(min=0)\n",
    "                one_hot_j[b, vs, js] = True\n",
    "        open_after_v = open_after_v | one_hot_j\n",
    "        # print('Open after v', open_after_v[:, 0, :], open_after_v.shape)\n",
    "\n",
    "        # print(idx_all.shape, idx_1_to_N.shape)\n",
    "        B = len(self.ids)\n",
    "        N_all = idx_all.shape[0]       # 101\n",
    "        N_1_to_N = idx_1_to_N.shape[0] # 100\n",
    "\n",
    "        # print(self.ids[:, None]\n",
    "        # .shape, idx_all[None, :, None].shape, idx_1_to_N[None, None, :].shape)\n",
    "        batch_idx = self.ids[:, None].expand(B, N_all, N_1_to_N)\n",
    "        from_idx  = idx_all[None, :, None].expand(B, N_all, N_1_to_N)\n",
    "        to_idx    = idx_1_to_N[None, None, :].expand(B, N_all, N_1_to_N)\n",
    "        # print(batch_idx.shape, from_idx.shape, to_idx.shape)\n",
    "        t_from_v_to_j = self.tmat[batch_idx, from_idx, to_idx]\n",
    "        # print('T from V to J: ', t_from_v_to_j, t_from_v_to_j.shape)\n",
    "        # t_from_v_to_j = self.tmat[self.ids, idx_all[None, :, None], idx_1_to_N[None, None, :]]\n",
    "\n",
    "        a_j = self.tw[self.ids, idx_1_to_N, 0][:, None, :]                   # [B,1,N]\n",
    "        b_j = self.tw[self.ids, idx_1_to_N, 1][:, None, :]                   # [B,1,N]\n",
    "        service_j = self.service[self.ids, idx_1_to_N][:, None, :]\n",
    "\n",
    "        # arrival to j and begin_service_j considering earliest time\n",
    "        # print('Time after v adj shape: ', time_after_v_adj.transpose(1, 2).shape)   \n",
    "        # print('t from v to j shape: ', t_from_v_to_j.shape)\n",
    "        arrival_vj = time_after_v_adj.transpose(1, 2)  + t_from_v_to_j                   # [B,Np1,N]\n",
    "        # print('Arrival VJ: ', arrival_vj, arrival_vj.shape)\n",
    "        # print('a_j shape: ', a_j.shape, a_j[:, None, :].shape)\n",
    "        begin_vj = torch.maximum(arrival_vj, a_j)           # [B,Np1,N]\n",
    "        # print('Begin VJ: ', begin_vj, begin_vj.shape)\n",
    "\n",
    "        # Feasible if we can START by b_j (standard PDPTW: b is latest start)\n",
    "        feas_open_after = (begin_vj <= b_j)                 # [B,Np1,N]\n",
    "        # print('Feas Open After: ', feas_open_after, feas_open_after.shape)\n",
    "        all_open_ok = torch.where(open_after_v, feas_open_after, torch.ones_like(feas_open_after)).all(dim=-1, keepdim=True)  # [B,Np1,1]\n",
    "\n",
    "        # Local feasibility at v: arrival_to_v must be â‰¤ b_v as usual\n",
    "        tw_ok_v = (arrival_to_v <= b_v) & all_open_ok.transpose(1, 2)\n",
    "\n",
    "        B = self.demand.size(0)\n",
    "        Np1 = self.demand.size(-1)\n",
    "        N = Np1 - 1\n",
    "        device = self.demand.device\n",
    "\n",
    "        idx_all = torch.arange(Np1, device=device)        # 0..N\n",
    "        idx_1_N = torch.arange(1, Np1, device=device)     # 1..N\n",
    "\n",
    "        # Depot window\n",
    "        a0 = self.tw[self.ids, 0, 0]    # [B]\n",
    "        b0 = self.tw[self.ids, 0, 1]    # [B]\n",
    "\n",
    "        # Per-delivery data\n",
    "        a_j_full = self.tw[self.ids, idx_1_N, 0]          # [B,N]\n",
    "        b_j_full = self.tw[self.ids, idx_1_N, 1]          # [B,N]\n",
    "        svc_j_full = self.service[self.ids, idx_1_N]      # [B,N]\n",
    "\n",
    "        # Open deliveries after choosing each v\n",
    "        S = open_after_v.clone()                          # [B,Np1,N] bool\n",
    "\n",
    "        # State per (b,v)\n",
    "        T = time_after_v_adj.squeeze(1).clone()           # [B,Np1]\n",
    "        prev_node = idx_all[None, :].expand(B, Np1).clone()   # start at v\n",
    "        batch_idx_bv = torch.arange(B, device=device)[:, None].expand(B, Np1)\n",
    "\n",
    "        # Track feasibility per (b,v)\n",
    "        all_steps_feasible = torch.ones(B, Np1, dtype=torch.bool, device=device)\n",
    "\n",
    "        # Iterate up to N selections\n",
    "        for _ in range(N):\n",
    "            # If nothing left open for some (b,v), we can skip them\n",
    "            has_open = S.any(dim=-1)                      # [B,Np1]\n",
    "            if not has_open.any():\n",
    "                break\n",
    "\n",
    "            # t(prev -> j) for all j (1..N), per (b,v)\n",
    "            # Shape: [B,Np1,Np1] then slice to deliveries 1..N -> [B,Np1,N]\n",
    "            t_prev_to_all = self.tmat[batch_idx_bv, prev_node, :]      # [B,Np1,Np1]\n",
    "            t_prev_to_j   = t_prev_to_all[:, :, 1:]                    # [B,Np1,N]\n",
    "\n",
    "            # Expand per-delivery windows/services to [B,Np1,N]\n",
    "            a_j = a_j_full[:, None, :].expand(B, Np1, N)               # [B,Np1,N]\n",
    "            b_j = b_j_full[:, None, :].expand(B, Np1, N)               # [B,Np1,N]\n",
    "            svc_j = svc_j_full[:, None, :].expand(B, Np1, N)           # [B,Np1,N]\n",
    "\n",
    "            # Arrival / begin / finish\n",
    "            arrive_j = T[:, :, None] + t_prev_to_j                     # [B,Np1,N]\n",
    "            begin_j  = torch.maximum(arrive_j, a_j)                    # [B,Np1,N]\n",
    "            feas_j   = (begin_j <= b_j) & S                            # must be open and time-feasible\n",
    "            any_feas = feas_j.any(dim=-1)                              # [B,Np1]\n",
    "\n",
    "            # If a (b,v) has open deliveries but none feasible now -> deadlock for that (b,v)\n",
    "            deadlock_now = has_open & (~any_feas)\n",
    "            if deadlock_now.any():\n",
    "                all_steps_feasible = all_steps_feasible & (~deadlock_now)\n",
    "                # For these, we won't update T/prev/S anymore; just keep them marked infeasible.\n",
    "                # To avoid updating them below, mask their feas_j to all False:\n",
    "                feas_j = torch.where(deadlock_now[:, :, None], torch.zeros_like(feas_j), feas_j)\n",
    "\n",
    "            # Finish times (INF where infeasible)\n",
    "            INF = 1e12\n",
    "            finish_j = torch.where(feas_j, begin_j + svc_j, torch.full_like(begin_j, INF))  # [B,Np1,N]\n",
    "\n",
    "            # Select the j with minimal finish time (ties arbitrary)\n",
    "            best_finish, best_pos = finish_j.min(dim=-1)               # [B,Np1], [B,Np1] (pos in 0..N-1)\n",
    "            # Build the chosen index (1..N), but only where any_feas is True\n",
    "            chosen_j = (best_pos + 1)                                  # [B,Np1]\n",
    "            # Update only on those (b,v) where we had any feasible\n",
    "            upd_mask = any_feas & (~deadlock_now)\n",
    "\n",
    "            # Gather begin/finish at chosen j for updates\n",
    "            # (indexing gather needs shape align)\n",
    "            gather_idx = best_pos.clamp(min=0).unsqueeze(-1)           # [B,Np1,1]\n",
    "            begin_star = begin_j.gather(-1, gather_idx).squeeze(-1)    # [B,Np1]\n",
    "            finish_star = (begin_star + svc_j.gather(-1, gather_idx).squeeze(-1))  # [B,Np1]\n",
    "\n",
    "            # Apply updates\n",
    "            T = torch.where(upd_mask, finish_star, T)                  # [B,Np1]\n",
    "            prev_node = torch.where(upd_mask, chosen_j, prev_node)     # [B,Np1]\n",
    "\n",
    "            # Remove chosen from S\n",
    "            # Build one-hot at position best_pos for removal\n",
    "            rem_mask = torch.zeros_like(S, dtype=torch.bool)           # [B,Np1,N]\n",
    "            rem_mask.scatter_(-1, best_pos.unsqueeze(-1), True)\n",
    "            S = S & (~rem_mask)                                        # remove chosen j where it was picked\n",
    "\n",
    "        # After serving all open deliveries (where possible), go to depot\n",
    "        t_prev_to_0 = self.tmat[batch_idx_bv, prev_node, torch.zeros_like(prev_node)]   # [B,Np1]\n",
    "        arrive_0 = T + t_prev_to_0\n",
    "        # print('Arrive 0: ', arrive_0.shape)\n",
    "        # print('a0 shape: ', a0.shape, a0[:, None].shape)\n",
    "        begin_0  = torch.maximum(arrive_0, a0)                                  # [B,Np1]\n",
    "        # print(begin_0.shape, b0.shape)\n",
    "        depot_ok_exact = (begin_0 <= b0) & all_steps_feasible                   # [B,Np1]\n",
    "\n",
    "        # Combine with your per-node checks\n",
    "        # print(tw_ok_v.shape, depot_ok_exact.shape)\n",
    "        tw_ok_v = tw_ok_v & depot_ok_exact[:, None, :]   # keep [B,1,Np1]\n",
    "        # print('TW OK V: ', tw_ok_v.shape)\n",
    "            \n",
    "        mask_depot = ((self.prev_a == 0) | ~delivery_unvisited.all(dim=1, keepdim=True)) & ((mask_loc == 0).int().sum(-1) > 0)\n",
    "        # print('Mask Depot: ', self.prev_a == 0, ((mask_loc == 0).int().sum(-1) > 0), ~delivery_unvisited.all(dim=1, keepdim=True), mask_depot)\n",
    "        # print('Mask loc final: ', mask_loc.shape)\n",
    "        # print('TW ok v: ', tw_ok_v[:, :, 1:].shape)\n",
    "        mask_loc = mask_loc | (~tw_ok_v[:, :, 1:].to(mask_loc.dtype))\n",
    "        # print('Mask loc final: ', mask_loc.shape)\n",
    "        # print('Mask depot: ', mask_depot.shape)\n",
    "        mask = torch.cat([mask_depot[:, :, None], mask_loc], dim=-1)\n",
    "        # print('Final mask: ', mask, mask.shape)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def construct_solutions(self, actions):\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2af75e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[44.]]) tensor([[0.1200]])\n",
      "0.11999999731779099 1.0\n",
      "tensor([[58.]]) tensor([[0.4133]])\n",
      "0.41333332657814026 1.0\n",
      "tensor([[80.]]) tensor([[0.4800]])\n",
      "0.47999998927116394 1.0\n",
      "tensor([[97.]]) tensor([[0.6600]])\n",
      "0.6599999666213989 1.0\n",
      "tensor([[112.]]) tensor([[0.5933]])\n",
      "0.5933333039283752 1.0\n",
      "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True, True, True, True, True, True, True, True, True, True,\n",
      "          True, True]]])\n"
     ]
    }
   ],
   "source": [
    "#Sample usage\n",
    "batch_instance = batchify([instances[0]])\n",
    "state = StateCPDPTW.initialize(batch_instance)\n",
    "action_list = [44, 15, 2, 31, 52]\n",
    "for action in action_list:\n",
    "    state = state.update(selected=torch.tensor([action]))\n",
    "    print(state.current_time, state.used_capacity)\n",
    "    print(state.used_capacity.item(), state.VEHICLE_CAPACITY)\n",
    "    # if state.used_capacity.item() > state.VEHICLE_CAPACITY:\n",
    "    if action == action_list[-1]:\n",
    "        print(state.get_mask())\n",
    "# # print(state.current_time, state.used_capacity)\n",
    "# state = state.update(selected=torch.tensor([56]))\n",
    "# print(state.current_time, state.used_capacity)\n",
    "# state = state.update(selected=torch.tensor([1]))\n",
    "# print(state.current_time, state.used_capacity)\n",
    "# state = state.update(selected=torch.tensor([51]))\n",
    "# print(state.current_time, state.used_capacity)\n",
    "# state = state.update(selected=torch.tensor([96]))\n",
    "# state = state.update(selected=torch.tensor([1, 57]))\n",
    "# state = state.update(selected=torch.tensor([0]))\n",
    "# print(state.used_capacity)\n",
    "# state.get_mask()\n",
    "# state.update(selected=torch.tensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e04c95c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Actions: tensor([31,  5, 22, 24, 22, 14, 36, 12, 13, 20, 14, 19, 20, 31, 22, 16,  3, 27,\n",
      "        46, 18, 17, 28, 49, 23, 37]), Used Capacity: [0.18000000715255737, 0.44999998807907104, 0.5733333230018616, 0.3566666543483734, 0.5799999833106995, 0.4300000071525574, 0.6000000238418579, 0.3700000047683716, 0.47999998927116394, 0.5299999713897705, 0.15000000596046448, 0.2266666740179062, 0.36000001430511475, 0.1666666716337204, 0.1666666716337204, 0.1666666716337204, 0.1666666716337204, 0.1666666716337204, 0.23999999463558197, 0.17666666209697723, 0.38333332538604736, 0.11999999731779099, 0.09666666388511658, 0.33000001311302185, 0.15000000596046448], Current Time: [9.0, 118.0, 20.0, 143.0, 131.0, 317.0, 67.0, 33.0, 381.0, 144.0, 38.0, 30.0, 137.0, 10.0, 18.0, 18.0, 17.0, 289.0, 27.0, 102.0, 52.0, 51.0, 141.0, 14.0, 134.0]\n",
      "Step 2, Actions: tensor([81, 23, 21, 41, 26, 26, 86, 49, 22, 46, 64, 69, 14, 81, 14, 45,  4, 14,\n",
      "        96, 19, 49,  3, 29, 26, 87]), Used Capacity: [0.0, 0.7200000286102295, 0.7300000190734863, 0.48666664958000183, 0.7400000095367432, 0.7766666412353516, 0.0, 0.7400000095367432, 0.9199999570846558, 0.7333332896232605, 0.0, 0.0, 0.7400000095367432, 0.0, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.3333333432674408, 0.0, 0.7200000286102295, 0.5466666221618652, 0.5699999928474426, 0.4933333396911621, 0.5800000429153442, 0.0], Current Time: [25.0, 154.0, 47.0, 168.0, 171.0, 332.0, 112.0, 204.0, 398.0, 231.0, 52.0, 57.0, 159.0, 29.0, 27.0, 33.0, 38.0, 319.0, 52.0, 123.0, 75.0, 209.0, 148.0, 42.0, 154.0]\n",
      "Step 3, Actions: tensor([24, 32, 72, 91, 72, 76,  4, 36, 72, 25,  3, 10, 70, 47, 33, 36, 34, 38,\n",
      "        13, 68, 26, 53,  4, 36, 42]), Used Capacity: [0.5766666531562805, 0.9100000262260437, 0.15666669607162476, 0.3566666543483734, 0.1600000262260437, 0.429999977350235, 0.5566666722297668, 0.9399999976158142, 0.47999995946884155, 0.9933332800865173, 0.17000000178813934, 0.21666666865348816, 0.3799999952316284, 0.1666666716337204, 0.5, 0.5, 0.5, 0.5, 0.28999999165534973, 0.5433333516120911, 0.9266666173934937, 0.12000000476837158, 0.6633333563804626, 0.8300000429153442, 0.15000000596046448], Current Time: [43.0, 184.0, 71.0, 187.0, 204.0, 352.0, 142.0, 252.0, 412.0, 243.0, 153.0, 113.0, 171.0, 38.0, 39.0, 41.0, 75.0, 325.0, 95.0, 143.0, 103.0, 300.0, 157.0, 58.0, 281.0]\n",
      "Step 4, Actions: tensor([12, 55,  3, 74, 46, 64, 54, 99, 63, 96, 53, 60, 34, 15, 72, 27, 53, 50,\n",
      "        24, 69, 99, 30, 54, 39, 10]), Used Capacity: [0.8500000238418579, 0.46000003814697266, 0.46000003814697266, 0.0, 0.4400000274181366, -2.9802322387695312e-08, 0.0, 0.5699999928474426, -2.9802322387695312e-08, 0.7899999618530273, 0.0, 0.0, 0.49000000953674316, 0.3333333432674408, 0.3333333134651184, 0.6666666865348816, 0.3333333134651184, 0.6666666865348816, 0.8500000238418579, 0.0, 0.7633333206176758, 0.49000000953674316, 0.4933333396911621, 0.9500000476837158, 0.4699999988079071], Current Time: [57.0, 257.0, 81.0, 213.0, 238.0, 379.0, 172.0, 269.0, 423.0, 253.0, 167.0, 150.0, 310.0, 49.0, 43.0, 48.0, 92.0, 336.0, 141.0, 162.0, 119.0, 361.0, 166.0, 78.0, 315.0]\n",
      "Step 5, Actions: tensor([44, 48, 49,  0, 96, 24,  0, 86, 20, 75,  6, 38, 84,  8, 25, 30, 43, 64,\n",
      "        63,  0, 67, 78, 14, 86, 92]), Used Capacity: [0.9700000286102295, 0.5800000429153442, 0.690000057220459, 0.0, 0.1600000262260437, 0.5133333206176758, 0.0, 0.3700000047683716, 0.5499999523162842, 0.5299999713897705, 0.12999999523162842, 0.31333333253860474, 0.3799999952316284, 0.5, 0.6666666269302368, 0.8333333730697632, 0.8333333134651184, 0.5, 0.5600000619888306, 0.0, 0.3799999952316284, 0.3700000047683716, 0.7733333110809326, 0.7000000476837158, 0.3199999928474426], Current Time: [66.0, 284.0, 93.0, 0.0, 274.0, 391.0, 0.0, 319.0, 435.0, 264.0, 205.0, 191.0, 334.0, 52.0, 46.0, 53.0, 104.0, 340.0, 156.0, 0.0, 134.0, 385.0, 175.0, 95.0, 334.0]\n",
      "Step 6, Actions: tensor([94,  3, 71, 48, 76, 36, 15, 24, 70, 70, 44, 88, 64, 25, 75, 95, 54, 88,\n",
      "        74,  7, 25, 80, 99, 89, 60]), Used Capacity: [0.8500000238418579, 0.7700000405311584, 0.533333420753479, 0.24666666984558105, 2.9802322387695312e-08, 0.6233333349227905, 0.09333333373069763, 0.6499999761581421, -5.960464477539063e-08, 0.0, 0.3399999737739563, 0.0, 0.0, 0.6666666865348816, 0.333333283662796, 0.6666666865348816, 0.6666666269302368, 0.3333333134651184, 5.960464477539063e-08, 0.3233333230018616, 0.8666666746139526, 0.0, 0.6766666173934937, 0.5800000429153442, 0.0], Current Time: [86.0, 302.0, 115.0, 117.0, 300.0, 417.0, 34.0, 354.0, 444.0, 275.0, 301.0, 208.0, 371.0, 56.0, 57.0, 59.0, 114.0, 346.0, 183.0, 55.0, 155.0, 404.0, 183.0, 111.0, 356.0]\n",
      "Step 7, Actions: tensor([ 49,  98,  53,  98,  32,  33,  23,  62,   0,  27,  56,   0,  44,  58,\n",
      "         83,  77,  14, 100,   0,  47,  76,   0,  64,  73,   0]), Used Capacity: [0.8966667056083679, 0.6500000357627869, 0.2300000786781311, 0.0, 0.37000003457069397, 0.949999988079071, 0.5266666412353516, 0.2799999713897705, -0.0, 0.4399999976158142, 0.20999997854232788, 0.0, 0.2800000011920929, 0.5, 0.16666661202907562, 0.5, 0.8333333134651184, 0.166666641831398, 0.0, 0.3566666543483734, 0.4866666793823242, 0.0, 0.39666661620140076, 0.2500000298023224, 0.0], Current Time: [106.0, 320.0, 134.0, 151.0, 330.0, 428.0, 45.0, 382.0, 0.0, 344.0, 343.0, 0.0, 423.0, 69.0, 73.0, 67.0, 120.0, 356.0, 0.0, 77.0, 178.0, 0.0, 192.0, 124.0, 0.0]\n",
      "Step 8, Actions: tensor([74, 73, 99, 43, 17, 74, 73, 74,  7, 26, 94,  8, 94, 97, 64, 66, 13, 34,\n",
      "        36, 57, 75, 42, 79, 11, 36]), Used Capacity: [0.3200000524520874, 0.3800000250339508, 7.450580596923828e-08, 0.2633333206176758, 0.7200000286102295, 0.43666666746139526, 0.09333330392837524, -2.9802322387695312e-08, 0.5799999833106995, 0.6633332967758179, -1.4901161193847656e-08, 0.23999999463558197, 0.0, 0.3333333134651184, -5.960464477539063e-08, 0.3333333134651184, 1.0, 0.3333333134651184, 0.5699999928474426, 0.03333333134651184, 0.0, 0.3100000023841858, -5.960464477539063e-08, 0.7699999809265137, 0.3799999952316284], Current Time: [122.0, 347.0, 160.0, 182.0, 351.0, 441.0, 64.0, 416.0, 120.0, 385.0, 383.0, 112.0, 441.0, 75.0, 89.0, 75.0, 124.0, 360.0, 98.0, 98.0, 193.0, 139.0, 203.0, 132.0, 366.0]\n",
      "Step 9, Actions: tensor([62, 53, 25, 93, 82, 86, 65,  0, 21, 76, 12, 58,  0, 75, 34, 80, 63, 84,\n",
      "         5, 13,  0, 92,  0, 61, 86]), Used Capacity: [0.0466667115688324, 0.1900000274181366, 0.0633334070444107, 0.0, 0.3500000238418579, 0.3266666531562805, -2.9802322387695312e-08, -0.0, 0.8299999833106995, 0.4399999678134918, 0.11999998241662979, 0.0, 0.0, 0.166666641831398, 0.333333283662796, 0.166666641831398, 0.8333333134651184, 0.166666641831398, 0.7400000095367432, 0.38999998569488525, 0.0, 0.0, -0.0, 0.25, 0.0], Current Time: [149.0, 378.0, 177.0, 206.0, 371.0, 454.0, 93.0, 0.0, 128.0, 393.0, 419.0, 152.0, 0.0, 81.0, 135.0, 83.0, 132.0, 371.0, 114.0, 115.0, 0.0, 174.0, 0.0, 142.0, 386.0]\n",
      "Step 10, Actions: tensor([ 6, 41, 75,  0, 67, 83, 10, 38, 71,  5, 62,  0, 19, 65, 19, 86, 64, 77,\n",
      "        86, 97, 30, 13, 27, 76, 13]), Used Capacity: [0.49666669964790344, 0.6500000357627869, 7.450580596923828e-08, 0.0, 2.9802322387695312e-08, 0.0, 0.41999995708465576, 0.28999999165534973, 0.5799999833106995, 0.8766666650772095, -1.4901161193847656e-08, 0.0, 0.4399999976158142, -2.9802322387695312e-08, 0.4999999403953552, -2.9802322387695312e-08, 0.6666666269302368, -2.9802322387695312e-08, 0.17000001668930054, 0.3566666543483734, 0.4033333361148834, 0.5899999737739563, 0.24666666984558105, 0.0, 0.4000000059604645], Current Time: [163.0, 410.0, 192.0, 0.0, 395.0, 463.0, 119.0, 297.0, 137.0, 435.0, 433.0, 0.0, 254.0, 91.0, 158.0, 90.0, 139.0, 380.0, 151.0, 153.0, 71.0, 209.0, 146.0, 160.0, 404.0]\n",
      "Step 11, Actions: tensor([56, 91,  6,  9, 39,  0, 60, 17, 40, 77,  0, 25, 69,  5, 28, 18, 23, 47,\n",
      "        55, 63, 47,  1, 12, 29, 63]), Used Capacity: [0.0466667115688324, 0.1900000274181366, 0.43666672706604004, 0.5533333420753479, 0.3400000333786011, 0.0, -2.9802322387695312e-08, 0.6799999475479126, 0.7199999690055847, 0.43666666746139526, -0.0, 0.22333332896232605, 0.0, 0.166666641831398, 0.6666666269302368, 0.3333333134651184, 0.8333333134651184, 0.3333333134651184, 1.4901161193847656e-08, 0.0, 0.46000000834465027, 0.949999988079071, 0.54666668176651, 0.2199999988079071, 0.0], Current Time: [174.0, 426.0, 209.0, 37.0, 424.0, 0.0, 156.0, 345.0, 195.0, 443.0, 0.0, 136.0, 350.0, 121.0, 168.0, 94.0, 147.0, 406.0, 185.0, 187.0, 102.0, 231.0, 157.0, 179.0, 424.0]\n",
      "Step 12, Actions: tensor([99, 82, 56, 29, 89, 40,  0, 67, 90, 55, 15, 75, 22, 43, 69, 39, 47, 37,\n",
      "         0,  0, 80, 51, 77, 46,  0]), Used Capacity: [4.470348358154297e-08, 2.9802322387695312e-08, 5.960464477539063e-08, 0.6066666841506958, 2.9802322387695312e-08, 0.14000000059604645, -0.0, 0.28999996185302734, 0.5799999833106995, 0.0, 0.30000001192092896, 0.0, 0.33000001311302185, 0.3333333134651184, 0.4999999403953552, 0.5, 1.0, 0.6666666269302368, 0.0, 0.0, 0.056666672229766846, 0.5899999737739563, 0.30000001192092896, 0.3199999928474426, 0.0], Current Time: [185.0, 453.0, 217.0, 69.0, 446.0, 113.0, 0.0, 359.0, 211.0, 449.0, 41.0, 170.0, 384.0, 147.0, 175.0, 102.0, 154.0, 422.0, 0.0, 0.0, 161.0, 264.0, 166.0, 405.0, 0.0]\n",
      "Step 13, Actions: tensor([36,  0,  0, 59,  0, 23, 33, 88, 38,  0, 65,  0, 72,  6, 84, 42, 97, 97,\n",
      "        10,  5, 97,  7, 62, 96, 46]), Used Capacity: [0.16333337128162384, 0.0, 0.0, 0.0533333420753479, 0.0, 0.2433333396911621, 0.18333333730697632, -2.9802322387695312e-08, 0.8899999856948853, 0.0, 0.0, 0.0, 0.0, 0.5, 0.16666659712791443, 0.6666666865348816, 0.8333333134651184, 0.333333283662796, 0.3700000047683716, 0.33000001311302185, 3.725290298461914e-09, 0.699999988079071, 0.0, 0.2199999988079071, 0.12999999523162842], Current Time: [198.0, 0.0, 0.0, 90.0, 0.0, 203.0, 41.0, 404.0, 220.0, 0.0, 62.0, 0.0, 403.0, 156.0, 184.0, 115.0, 161.0, 441.0, 101.0, 120.0, 196.0, 340.0, 179.0, 413.0, 333.0]\n",
      "Step 14, Actions: tensor([86,  7,  8, 79, 48,  7, 34,  0, 57,  7, 19, 16,  0, 93, 42,  8, 73, 87,\n",
      "        18, 55,  0, 63,  0, 42, 96]), Used Capacity: [4.470348358154297e-08, 0.20999999344348907, 0.23333333432674408, 7.450580596923828e-09, 0.46000000834465027, 0.84333336353302, 0.4533333480358124, -0.0, 0.3100000023841858, 0.5766666531562805, 0.5699999928474426, 0.49000000953674316, 0.0, 0.3333333134651184, 0.33333325386047363, 0.8333333730697632, 0.6666666269302368, -5.960464477539063e-08, 0.7599999904632568, 0.0, 0.0, 0.11000001430511475, 0.0, 0.7999999523162842, 0.0], Current Time: [214.0, 379.0, 42.0, 127.0, 26.0, 212.0, 66.0, 0.0, 228.0, 16.0, 359.0, 48.0, 0.0, 166.0, 198.0, 123.0, 172.0, 461.0, 116.0, 154.0, 0.0, 364.0, 0.0, 424.0, 353.0]\n",
      "Step 15, Actions: tensor([ 0, 57, 16, 22, 18, 73, 84, 28, 11, 49, 69,  1, 17, 55, 78, 89, 93,  0,\n",
      "        60,  0, 27, 57, 13, 92, 28]), Used Capacity: [0.0, 0.0, 0.7900000214576721, 0.15333333611488342, 0.8500000238418579, 0.7400000095367432, 0.18333333730697632, 0.4099999964237213, 0.8299999833106995, 0.746666669845581, 0.0, 0.9166666865348816, 0.1899999976158142, 0.166666641831398, 0.16666658222675323, 0.6666666865348816, 0.16666662693023682, -0.0, 0.38999998569488525, 0.0, 0.4099999964237213, 1.4901161193847656e-08, 0.11999999731779099, 0.21999996900558472, 0.5099999904632568], Current Time: [0.0, 403.0, 124.0, 152.0, 61.0, 220.0, 84.0, 167.0, 236.0, 163.0, 379.0, 65.0, 28.0, 174.0, 202.0, 130.0, 183.0, 0.0, 149.0, 0.0, 32.0, 393.0, 22.0, 430.0, 382.0]\n",
      "Step 16, Actions: tensor([48,  0, 10, 72, 98, 57, 83, 30, 61, 22, 37, 51, 67, 56, 92, 92, 84,  6,\n",
      "        68, 27, 77,  0, 32, 48, 78]), Used Capacity: [0.1899999976158142, 0.0, 0.9033333659172058, 0.0, 0.39000001549720764, 0.13999998569488525, 0.0, 0.9800000190734863, 0.3100000023841858, 0.7933333516120911, 0.5799999833106995, 0.49000000953674316, 0.0, -2.9802322387695312e-08, -8.940696716308594e-08, 0.5, -4.470348358154297e-08, 0.1666666716337204, 0.0, 0.476666659116745, 0.0, 0.0, 0.5433333516120911, 0.5399999618530273, 0.0], Current Time: [17.0, 0.0, 135.0, 185.0, 88.0, 233.0, 105.0, 181.0, 245.0, 190.0, 411.0, 85.0, 80.0, 185.0, 211.0, 136.0, 204.0, 77.0, 177.0, 108.0, 82.0, 0.0, 31.0, 437.0, 401.0]\n",
      "Step 17, Actions: tensor([39, 46, 58,  0, 34, 90, 37, 78,  6, 72, 87, 66, 33, 10,  0, 58, 28, 10,\n",
      "         0, 77, 13,  5, 82, 98, 33]), Used Capacity: [0.6766666769981384, 0.15000000596046448, 0.6700000166893005, 0.0, 0.5900000333786011, -1.4901161193847656e-08, 0.28333333134651184, 0.5700000524520874, 0.8799999952316284, 0.746666669845581, 0.0, 0.0, 0.18000000715255737, 0.166666641831398, -0.0, 0.3333333134651184, 0.16666662693023682, 0.3333333432674408, 0.0, 0.0, 0.6000000238418579, 0.6000000238418579, 0.12000000476837158, 0.21999996900558472, 0.44999998807907104], Current Time: [30.0, 312.0, 156.0, 0.0, 117.0, 246.0, 125.0, 210.0, 259.0, 199.0, 427.0, 127.0, 159.0, 195.0, 0.0, 144.0, 318.0, 91.0, 0.0, 151.0, 127.0, 362.0, 40.0, 446.0, 421.0]\n",
      "Step 18, Actions: tensor([21, 49, 60, 46, 68, 15, 87,  3, 88, 99,  0,  0, 39, 60,  2, 68, 78,  8,\n",
      "        34, 35, 36, 55, 63, 79, 83]), Used Capacity: [0.8799999952316284, 0.7300000190734863, 0.5566666722297668, 0.4833333194255829, 0.20000004768371582, 0.5899999737739563, 0.0, 0.8700000643730164, 0.5699999928474426, 0.5766666531562805, 0.0, 0.0, 0.7400000095367432, -2.9802322387695312e-08, 0.1666666716337204, -2.9802322387695312e-08, -4.470348358154297e-08, 0.5, 0.25, 0.6000000238418579, 0.9766666889190674, 0.0, 7.450580596923828e-09, -2.9802322387695312e-08, 0.0], Current Time: [45.0, 345.0, 181.0, 39.0, 140.0, 259.0, 163.0, 255.0, 272.0, 224.0, 0.0, 0.0, 202.0, 203.0, 137.0, 149.0, 342.0, 98.0, 32.0, 176.0, 158.0, 402.0, 51.0, 458.0, 442.0]\n",
      "Step 19, Actions: tensor([ 2, 96, 66, 96, 84,  2,  0, 80, 28, 32, 22, 23, 89,  0, 17, 15, 44, 58,\n",
      "        17, 85, 86,  0,  7,  0,  0]), Used Capacity: [0.9466666579246521, 0.5800000429153442, 0.0, 0.0, 4.470348358154297e-08, 0.6799999475479126, 0.0, 0.30000007152557373, 0.9300000071525574, 0.8399999737739563, 0.4099999964237213, 0.3933333456516266, 0.18000000715255737, -0.0, 0.5, 0.3333333134651184, 0.16666662693023682, 0.3333333134651184, 0.5, 0.0, 0.6000000238418579, 0.0, 0.20000001788139343, -0.0, 0.0], Current Time: [56.0, 379.0, 205.0, 57.0, 162.0, 284.0, 0.0, 278.0, 285.0, 374.0, 392.0, 50.0, 229.0, 0.0, 151.0, 158.0, 372.0, 131.0, 48.0, 193.0, 179.0, 0.0, 120.0, 0.0, 0.0]\n",
      "Step 20, Actions: tensor([52, 99,  0,  5, 41,  5, 30, 53, 78, 28, 72, 73, 83, 44, 43, 22,  8, 56,\n",
      "        19,  0, 63, 12, 39, 22, 35]), Used Capacity: [0.8799999952316284, 5.960464477539063e-08, 0.0, 0.20333333313465118, 0.12000004202127457, 0.90666663646698, 0.23000000417232513, 5.960464477539063e-08, 0.5699999928474426, 0.9599999785423279, 0.0, 0.0, 0.0, 0.1666666716337204, 0.6666666865348816, 0.5, 0.3333333134651184, 0.166666641831398, 0.699999988079071, 0.0, 0.0, 0.5299999713897705, 0.7899999618530273, 0.17000000178813934, 0.20000000298023224], Current Time: [68.0, 411.0, 0.0, 82.0, 194.0, 300.0, 106.0, 322.0, 293.0, 388.0, 404.0, 83.0, 256.0, 15.0, 160.0, 169.0, 403.0, 145.0, 102.0, 0.0, 202.0, 52.0, 151.0, 12.0, 410.0]\n",
      "Step 21, Actions: tensor([98,  0, 19, 49, 91, 52, 80,  5, 56, 78,  0, 33, 29,  9, 52, 65, 58, 60,\n",
      "        84, 10,  0, 62, 57, 24, 85]), Used Capacity: [0.6899999976158142, 0.0, 0.5600000023841858, 0.3766666650772095, 4.470348358154297e-08, 0.8166666030883789, 0.0, 0.18000006675720215, 0.0, 0.8399999737739563, 0.0, 0.2433333396911621, 0.47999998927116394, 0.3333333432674408, 0.5, 0.1666666567325592, 0.166666641831398, -2.9802322387695312e-08, 0.44999998807907104, 0.2266666740179062, 0.0, 0.0, 0.5899999737739563, 0.3400000035762787, 0.0], Current Time: [86.0, 0.0, 15.0, 108.0, 220.0, 328.0, 150.0, 371.0, 301.0, 402.0, 0.0, 105.0, 320.0, 24.0, 167.0, 176.0, 411.0, 159.0, 140.0, 50.0, 0.0, 105.0, 163.0, 216.0, 432.0]\n",
      "Step 22, Actions: tensor([71, 30, 38, 99,  8, 27,  0, 55, 23, 57, 41, 83, 79, 94, 67, 48, 37, 46,\n",
      "        69, 60,  6,  2, 17, 32,  0]), Used Capacity: [0.4866666793823242, 0.2199999988079071, 0.9166666269302368, 0.20333333313465118, 0.14000004529953003, 0.9233332872390747, 0.0, 5.960464477539063e-08, 0.5, 0.2633333206176758, 0.44999998807907104, 0.0, 0.0, 0.1666666716337204, 0.1666666567325592, 0.5, 0.3333333134651184, 0.3333333134651184, 0.2499999850988388, 0.0, 0.5866666436195374, 0.5400000214576721, 0.7966666221618652, 0.8999999761581421, 0.0], Current Time: [107.0, 59.0, 27.0, 141.0, 375.0, 345.0, 0.0, 397.0, 312.0, 409.0, 104.0, 135.0, 353.0, 40.0, 185.0, 184.0, 418.0, 225.0, 172.0, 68.0, 118.0, 186.0, 177.0, 281.0, 0.0]\n",
      "Step 23, Actions: tensor([27, 42, 88, 55, 58, 55,  5,  0, 36, 10, 25, 30, 11, 59, 93, 23, 87, 31,\n",
      "        67, 42, 56, 52, 89, 74, 16]), Used Capacity: [0.5300000309944153, 0.3700000047683716, 0.559999942779541, 0.0, 4.470348358154297e-08, 0.6966665983200073, 0.5933333039283752, 0.0, 0.7699999809265137, 0.7699999809265137, 0.949999988079071, 0.43666666746139526, 0.4099999964237213, 0.0, -1.4901161193847656e-08, 0.6666666865348816, 0.166666641831398, 0.6666666269302368, -1.4901161193847656e-08, 0.34333333373069763, 0.0, 0.0, 0.20666664838790894, 0.7299999594688416, 0.25999999046325684], Current Time: [118.0, 87.0, 40.0, 170.0, 405.0, 360.0, 109.0, 0.0, 324.0, 417.0, 117.0, 161.0, 398.0, 55.0, 205.0, 191.0, 423.0, 244.0, 204.0, 100.0, 152.0, 225.0, 186.0, 290.0, 26.0]\n",
      "Step 24, Actions: tensor([89, 19, 50,  0,  0, 49, 55, 42, 16, 60, 75, 80, 61, 18,  0, 98, 94, 96,\n",
      "         0, 92,  0, 18, 67, 10, 66]), Used Capacity: [0.043333351612091064, 0.9200000166893005, 0.9399999380111694, 0.0, 0.0, 0.9799998998641968, 0.0, 0.14000000059604645, 0.9599999785423279, 0.2633333206176758, 0.44999998807907104, 0.0, 0.0, 0.3333333432674408, -0.0, 0.3333333432674408, -2.9802322387695312e-08, 0.333333283662796, -0.0, 0.0, 0.0, 0.4699999988079071, -1.4901161193847656e-08, 0.8499999642372131, 0.0], Current Time: [134.0, 106.0, 94.0, 0.0, 0.0, 382.0, 164.0, 233.0, 341.0, 426.0, 133.0, 191.0, 423.0, 124.0, 0.0, 195.0, 429.0, 250.0, 0.0, 137.0, 0.0, 286.0, 193.0, 300.0, 44.0]\n",
      "Step 25, Actions: tensor([38, 92, 69, 12, 49, 77,  0, 92, 86, 11, 91,  0,  0, 29,  7, 26,  0, 81,\n",
      "        38,  0, 38, 68,  0, 60,  7]), Used Capacity: [0.17333334684371948, 0.7699999809265137, 0.37999993562698364, 0.35333332419395447, 0.12999999523162842, 0.873333215713501, 0.0, 0.0, 0.6899999380111694, 0.4466666579246521, 0.0, 0.0, 0.0, 0.5, 0.1666666716337204, 0.5, -0.0, -5.960464477539063e-08, 0.4699999988079071, 0.0, 0.23666666448116302, 0.0, -0.0, 0.7299999594688416, 0.4099999964237213], Current Time: [147.0, 126.0, 105.0, 157.0, 258.0, 397.0, 0.0, 285.0, 360.0, 436.0, 162.0, 0.0, 0.0, 134.0, 7.0, 203.0, 0.0, 258.0, 37.0, 0.0, 103.0, 334.0, 0.0, 311.0, 389.0]\n",
      "Step 26, Actions: tensor([28, 80,  7, 62, 38, 65,  7, 23, 66, 82,  0, 34, 26, 68, 48, 76, 32, 23,\n",
      "        41,  3, 37, 17, 28,  1, 57]), Used Capacity: [0.550000011920929, 0.5499999523162842, 0.51666659116745, 0.0, 0.25999999046325684, 0.2833332419395447, 0.28333333134651184, 0.4000000059604645, 0.4999999403953552, 0.18333333730697632, 0.0, 0.09333333373069763, 0.5699999928474426, 0.1666666567325592, 0.3333333432674408, 0.3333333134651184, 0.1666666716337204, 0.333333283662796, 0.7400000095367432, 0.17000000178813934, 0.54666668176651, 0.47999998927116394, 0.12999999523162842, 0.8399999737739563, 0.0], Current Time: [156.0, 155.0, 121.0, 183.0, 298.0, 405.0, 45.0, 352.0, 372.0, 444.0, 0.0, 90.0, 95.0, 145.0, 16.0, 206.0, 211.0, 293.0, 53.0, 101.0, 121.0, 376.0, 19.0, 357.0, 410.0]\n",
      "Step 27, Actions: tensor([77, 69, 29,  0, 14, 99, 57, 73, 47, 61, 29, 84, 76, 79, 45, 72,  1, 42,\n",
      "        88, 53, 88, 67,  2, 72,  0]), Used Capacity: [0.5066666603088379, -5.960464477539063e-08, 0.5699999332427979, 0.0, 0.8399999737739563, -8.940696716308594e-08, 0.0, 0.0, 0.9999999403953552, 0.0, 0.41999998688697815, 0.0, 0.0, -1.4901161193847656e-08, 0.5, 0.166666641831398, 0.6666666865348816, 0.4999999403953552, 0.27000001072883606, 0.0, 0.3100000023841858, 0.0, 0.6966666579246521, 0.6699999570846558, 0.0], Current Time: [166.0, 182.0, 149.0, 0.0, 320.0, 425.0, 65.0, 367.0, 384.0, 455.0, 86.0, 140.0, 132.0, 158.0, 24.0, 214.0, 220.0, 312.0, 71.0, 135.0, 145.0, 408.0, 30.0, 367.0, 0.0]\n",
      "Step 28, Actions: tensor([88, 10, 79, 45, 99,  0, 38, 31, 97,  0, 79,  0, 28, 35, 13, 73, 10, 32,\n",
      "        91,  4, 87,  0, 78, 51, 49]), Used Capacity: [0.3766666650772095, 0.34999993443489075, 0.51666659116745, 0.05666666850447655, 0.7099999785423279, -0.0, 0.476666659116745, 0.5, 0.4999999403953552, 0.0, 0.0, 0.0, 0.550000011920929, 0.6666666865348816, 0.6666666865348816, -2.9802322387695312e-08, 0.8333333730697632, 0.6666666269302368, 0.0, 0.11666666716337204, 0.0, 0.0, 0.5666666626930237, 0.559999942779541, 0.3400000035762787], Current Time: [183.0, 283.0, 166.0, 136.0, 343.0, 0.0, 123.0, 403.0, 393.0, 0.0, 105.0, 0.0, 209.0, 190.0, 35.0, 224.0, 235.0, 334.0, 93.0, 170.0, 182.0, 0.0, 43.0, 376.0, 145.0]\n",
      "Step 29, Actions: tensor([ 78,  14, 100,  33,  88,  43,  88,  81,   2,  23,  34,  35,  78,  85,\n",
      "          9,   0,  18,  73,   2,  54,   0,   9,  52,  82,  22]), Used Capacity: [0.0, 0.8899999856948853, 0.13666659593582153, 0.5766666531562805, 0.5799999833106995, 0.5233333110809326, 0.0, 0.0, 0.9899999499320984, 0.3799999952316284, 0.17000000178813934, 0.596666693687439, 0.0, 0.0, 1.0, -0.0, 1.0, 0.333333283662796, 0.44999998807907104, 0.0, 0.0, 0.4399999976158142, 0.0, -5.960464477539063e-08, 0.7699999809265137], Current Time: [191.0, 357.0, 180.0, 164.0, 364.0, 19.0, 162.0, 423.0, 404.0, 33.0, 392.0, 53.0, 242.0, 207.0, 45.0, 0.0, 244.0, 340.0, 114.0, 188.0, 0.0, 229.0, 56.0, 386.0, 183.0]\n",
      "Step 30, Actions: tensor([26, 60, 57, 83, 64, 12,  0,  0, 73, 44, 48, 85,  2,  0, 63,  9, 68, 43,\n",
      "        44,  0, 41, 59, 47, 43, 72]), Used Capacity: [0.6000000238418579, 0.5399999618530273, -7.450580596923828e-08, 0.056666672229766846, 0.0, 0.7966666221618652, 0.0, 0.0, 0.4899999499320984, 0.4333333373069763, 0.5099999904632568, 0.0, 0.5400000214576721, 0.0, 0.8333333134651184, 0.1666666716337204, 0.8333333134651184, 0.4999999403953552, 0.6399999856948853, 0.0, 0.4033333361148834, 0.0, 0.30000001192092896, 0.559999942779541, 0.3399999737739563], Current Time: [210.0, 376.0, 211.0, 184.0, 389.0, 73.0, 0.0, 0.0, 413.0, 59.0, 408.0, 95.0, 259.0, 0.0, 50.0, 82.0, 275.0, 352.0, 143.0, 0.0, 143.0, 276.0, 70.0, 400.0, 210.0]\n",
      "Step 31, Actions: tensor([76, 64,  0, 95,  0, 62, 29,  4, 52, 36, 84, 28, 30, 16, 11, 14, 51, 93,\n",
      "        94, 49,  5, 24, 21, 93, 99]), Used Capacity: [0.0, -5.960464477539063e-08, -0.0, 3.725290298461914e-09, 0.0, 0.5233333110809326, 0.27666667103767395, 0.20999999344348907, -5.960464477539063e-08, 0.9333333373069763, 0.3399999737739563, 0.23666666448116302, 0.9700000286102295, 0.3333333432674408, 1.0, 0.3333333432674408, 0.3333333134651184, 0.33333325386047363, 0.44999998807907104, 0.503333330154419, 0.9099999666213989, 0.3499999940395355, 0.8799999952316284, -5.960464477539063e-08, -2.9802322387695312e-08], Current Time: [219.0, 395.0, 0.0, 207.0, 0.0, 93.0, 80.0, 197.0, 426.0, 66.0, 424.0, 127.0, 327.0, 97.0, 56.0, 104.0, 292.0, 361.0, 164.0, 63.0, 166.0, 317.0, 80.0, 418.0, 246.0]\n",
      "Step 32, Actions: tensor([ 0,  4, 48,  0, 30, 47, 16,  2,  0, 94, 98, 78, 80, 23, 57, 64, 30, 92,\n",
      "        52, 99, 55, 74, 22, 41,  0]), Used Capacity: [0.0, 0.3399999439716339, 0.5199999809265137, 0.0, 0.10000000149011612, 0.7999999523162842, 0.7066667079925537, 0.3499999940395355, -0.0, 0.8799999952316284, -2.9802322387695312e-08, 0.0, 0.5400000214576721, 0.5, 0.8333333134651184, 0.1666666716337204, 0.5, 0.16666658222675323, 0.0, 0.0, 0.40333330631256104, 0.0, 0.9233333468437195, 0.5099999308586121, -0.0], Current Time: [0.0, 423.0, 99.0, 0.0, 57.0, 107.0, 101.0, 243.0, 0.0, 75.0, 442.0, 170.0, 360.0, 104.0, 61.0, 114.0, 298.0, 367.0, 185.0, 88.0, 184.0, 359.0, 86.0, 436.0, 0.0]\n",
      "Step 33, Actions: tensor([14, 54, 18,  8, 45, 97, 79, 52, 35, 34,  0,  0, 52, 19, 61, 59, 60, 82,\n",
      "         0,  8, 91,  0, 71, 91, 30]), Used Capacity: [0.2199999988079071, -5.960464477539063e-08, 0.7699999809265137, 0.31333333253860474, 0.550000011920929, 0.5233333110809326, 0.43000003695487976, 0.20999999344348907, 0.2199999988079071, 0.9733333587646484, -0.0, 0.0, 0.0, 0.6666666865348816, 0.6666666269302368, 0.0, 0.3333333134651184, -8.940696716308594e-08, 0.0, 0.5566666722297668, -2.9802322387695312e-08, 0.0, 0.34333336353302, -5.960464477539063e-08, 0.4300000071525574], Current Time: [9.0, 443.0, 136.0, 73.0, 86.0, 124.0, 119.0, 282.0, 124.0, 86.0, 0.0, 0.0, 374.0, 113.0, 64.0, 118.0, 305.0, 376.0, 0.0, 121.0, 200.0, 0.0, 95.0, 449.0, 117.0]\n",
      "Step 34, Actions: tensor([17,  0, 41, 58, 25, 93, 66, 54, 30, 86, 38, 13,  0, 73, 98, 35, 50, 40,\n",
      "        42, 58,  0, 47, 72,  0, 80]), Used Capacity: [0.6733333468437195, -0.0, 0.8899999856948853, 0.0, 0.9600000381469727, 0.0, 2.9802322387695312e-08, 0.0, 0.6200000047683716, 0.47333335876464844, 0.5799999833106995, 0.3233333230018616, 0.0, 0.5, 0.4999999403953552, 0.1666666716337204, 0.5, 0.16666658222675323, 0.46000000834465027, 0.0, -0.0, 0.4000000059604645, 0.30000004172325134, -0.0, 0.0], Current Time: [27.0, 0.0, 157.0, 111.0, 107.0, 142.0, 146.0, 318.0, 159.0, 95.0, 168.0, 146.0, 0.0, 123.0, 78.0, 130.0, 312.0, 383.0, 24.0, 157.0, 0.0, 97.0, 103.0, 0.0, 136.0]\n",
      "Step 35, Actions: tensor([10, 27, 91,  2, 95, 10,  2, 44, 85, 42, 88, 63, 41, 66, 95, 85, 82, 90,\n",
      "        22,  0, 42, 97,  6, 16, 43]), Used Capacity: [0.8566666841506958, 0.23000000417232513, 0.7699999809265137, 0.28999999165534973, 0.5100000500679016, 0.5299999713897705, 0.17000003159046173, 0.4000000059604645, 0.4000000059604645, 1.0, 0.0, 0.0, 0.1899999976158142, 0.1666666567325592, 0.33333325386047363, 0.0, 0.3333333134651184, -8.940696716308594e-08, 0.6299999952316284, 0.0, 0.38999998569488525, 0.0, 0.6600000858306885, 0.3100000023841858, 0.5400000214576721], Current Time: [39.0, 25.0, 178.0, 132.0, 129.0, 298.0, 169.0, 351.0, 194.0, 104.0, 186.0, 181.0, 284.0, 133.0, 83.0, 151.0, 321.0, 395.0, 71.0, 0.0, 152.0, 121.0, 115.0, 78.0, 332.0]\n",
      "Step 36, Actions: tensor([64,  9, 98, 52, 75, 44, 52, 94,  1, 73, 36,  0, 91, 69, 59, 38, 80, 13,\n",
      "        72, 41,  9, 23, 97, 33, 93]), Used Capacity: [0.6366666555404663, 0.6600000262260437, 0.25, 0.0, 0.1000000536441803, 0.7733333110809326, 2.9802322387695312e-08, 0.0, 0.6700000166893005, 0.6200000047683716, 0.2800000011920929, 0.0, 0.0, -1.4901161193847656e-08, -8.940696716308594e-08, 0.1666666716337204, 0.166666641831398, 0.33333325386047363, 0.4599999785423279, 0.3199999928474426, 0.8933333158493042, 0.1899999976158142, 0.3600000739097595, 0.8500000238418579, 0.0], Current Time: [56.0, 161.0, 195.0, 160.0, 166.0, 309.0, 182.0, 398.0, 292.0, 133.0, 395.0, 0.0, 333.0, 143.0, 91.0, 170.0, 325.0, 404.0, 113.0, 100.0, 164.0, 359.0, 126.0, 172.0, 352.0]\n",
      "Step 37, Actions: tensor([20, 59, 68,  0, 80, 13,  0,  0, 51, 84, 86, 49,  0, 48, 47, 88, 46, 63,\n",
      "        92, 91, 92, 73,  9, 66,  0]), Used Capacity: [0.9466666579246521, 0.23000001907348633, 0.0, 0.0, 5.21540641784668e-08, 0.8399999737739563, 0.0, 0.0, 0.4000000059604645, 0.5266666412353516, 0.0, 0.36000001430511475, 0.0, 0.3333333134651184, 0.16666658222675323, 0.0, 0.3333333134651184, -8.940696716308594e-08, -2.9802322387695312e-08, 0.0, 0.503333330154419, 0.0, 0.7633334398269653, 0.5400000214576721, 0.0], Current Time: [75.0, 182.0, 215.0, 0.0, 193.0, 328.0, 0.0, 0.0, 301.0, 160.0, 418.0, 31.0, 0.0, 151.0, 147.0, 184.0, 332.0, 415.0, 138.0, 143.0, 187.0, 386.0, 135.0, 186.0, 0.0]\n",
      "Step 38, Actions: tensor([60, 77,  0, 39, 21, 94, 12, 25, 15, 12,  0,  5, 43, 50, 36, 46, 96,  0,\n",
      "         3,  0, 59,  0, 59, 19, 24]), Used Capacity: [0.7633333206176758, 1.4901161193847656e-08, 0.0, 0.10999999940395355, 0.5400000810623169, 0.5966666340827942, 0.07333333045244217, 0.10000000149011612, 0.8400000333786011, 0.9833333492279053, 0.0, 0.596666693687439, 0.5, 0.5, 0.33333325386047363, 0.1666666716337204, 0.166666641831398, -0.0, 0.3399999737739563, 0.0, 0.0, 0.0, 0.3600001037120819, 0.6600000262260437, 0.5899999737739563], Current Time: [86.0, 206.0, 0.0, 125.0, 253.0, 339.0, 51.0, 241.0, 372.0, 170.0, 0.0, 56.0, 312.0, 156.0, 159.0, 200.0, 343.0, 0.0, 165.0, 0.0, 213.0, 0.0, 147.0, 202.0, 391.0]\n",
      "Step 39, Actions: tensor([ 67,  21,   9,  89,  16,   3,  17,  33,  65,  92,  28,  55,  93, 100,\n",
      "         40,  96, 100,  36,  53,  29,   0,  48,  56,  28,  74]), Used Capacity: [0.3099999725818634, 0.4100000262260437, 0.5, 0.0, 0.9300000667572021, 0.8399999737739563, 0.42666664719581604, 0.5, 0.40000003576278687, 0.4566667079925537, 0.4399999976158142, 0.36000001430511475, 0.0, 0.3333333134651184, 0.4999999403953552, 0.0, -2.9802322387695312e-08, 0.1666666716337204, -2.9802322387695312e-08, 0.28333333134651184, 0.0, 0.5899999737739563, 8.940696716308594e-08, 0.89000004529953, 0.0], Current Time: [96.0, 276.0, 70.0, 153.0, 287.0, 355.0, 87.0, 278.0, 384.0, 181.0, 345.0, 83.0, 335.0, 176.0, 171.0, 208.0, 351.0, 336.0, 179.0, 123.0, 0.0, 318.0, 163.0, 219.0, 411.0]\n",
      "Step 40, Actions: tensor([70, 44, 11,  0, 66, 63, 62, 75, 80,  6, 78, 99,  0, 98, 90,  0,  9, 19,\n",
      "         0, 79, 48, 98, 48, 78,  0]), Used Capacity: [-2.9802322387695312e-08, 0.7200000286102295, 0.9766666889190674, 0.0, 0.5400000810623169, 0.7733333110809326, 0.35333332419395447, 0.4000000059604645, 2.9802322387695312e-08, 0.6333333849906921, 0.0, 0.0, 0.0, -2.9802322387695312e-08, 0.33333325386047363, 0.0, 0.166666641831398, 0.3333333432674408, -0.0, 0.0, 0.33666667342185974, 0.0, 0.5600000619888306, 0.6600000262260437, 0.0], Current Time: [123.0, 304.0, 82.0, 0.0, 313.0, 370.0, 119.0, 303.0, 423.0, 212.0, 357.0, 104.0, 0.0, 193.0, 181.0, 0.0, 360.0, 352.0, 0.0, 150.0, 84.0, 352.0, 195.0, 237.0, 0.0]\n",
      "Step 41, Actions: tensor([ 1, 94, 59, 38, 71, 60, 67, 83,  0, 56,  0, 29, 16,  0,  6, 40, 36, 69,\n",
      "        45,  0, 98,  0, 98, 83,  8]), Used Capacity: [0.07333330065011978, 0.4100000262260437, 0.4766666889190674, 0.1599999964237213, 5.960464477539063e-08, 0.2433333396911621, 0.0, 0.0, 0.0, 0.4566667079925537, 0.0, 0.1966666728258133, 0.5400000214576721, -0.0, 0.4999999403953552, 0.3333333432674408, 0.3333333134651184, 0.1666666716337204, 0.10999999940395355, 0.0, 0.0, 0.0, 5.960464477539063e-08, 0.12000000476837158, 0.5899999737739563], Current Time: [140.0, 325.0, 96.0, 27.0, 329.0, 398.0, 161.0, 351.0, 0.0, 225.0, 0.0, 139.0, 22.0, 0.0, 186.0, 44.0, 369.0, 360.0, 55.0, 0.0, 136.0, 0.0, 204.0, 253.0, 30.0]\n",
      "Step 42, Actions: tensor([18, 13, 20, 88,  2, 50,  0,  0, 50,  1,  9, 79, 66, 34, 56, 25, 86, 44,\n",
      "        95, 12,  0, 26,  0, 69, 58]), Used Capacity: [0.503333330154419, 0.6500000357627869, 0.6833333373069763, 0.0, 0.46000006794929504, 0.40666666626930237, 0.0, 0.0, 0.44999998807907104, 0.690000057220459, 0.28999999165534973, 0.0, 0.0, 0.1666666716337204, 0.33333325386047363, 0.5, 0.166666641831398, 0.3333333432674408, 0.0, 0.5233333110809326, 0.0, 0.20000000298023224, 0.0, 7.450580596923828e-09, 0.0], Current Time: [152.0, 346.0, 105.0, 49.0, 368.0, 407.0, 0.0, 0.0, 33.0, 249.0, 323.0, 175.0, 65.0, 68.0, 195.0, 58.0, 377.0, 370.0, 95.0, 119.0, 0.0, 300.0, 0.0, 269.0, 62.0]\n",
      "Step 43, Actions: tensor([ 51,  63,  61,  11,  52, 100,  35,   9,  24,  51,  59,   0,  36,  27,\n",
      "         86,  90,  16,  94,  43,  62,  40,  76,  37,  18,  18]), Used Capacity: [0.4300000071525574, 0.4100000262260437, 0.20666667819023132, 0.03999999910593033, 5.960464477539063e-08, 0.2433333396911621, 0.4233333468437195, 0.10999999940395355, 0.7300000190734863, 0.4566667079925537, 0.0, 0.0, 0.5400000214576721, 0.3333333432674408, 0.16666658222675323, 0.1666666567325592, 0.3333333134651184, 0.1666666716337204, 0.2800000011920929, 0.0, 0.5433333516120911, 0.0, 0.5166666507720947, 0.5099999904632568, 0.25999999046325684], Current Time: [162.0, 365.0, 115.0, 74.0, 400.0, 432.0, 137.0, 304.0, 51.0, 258.0, 344.0, 0.0, 167.0, 98.0, 200.0, 67.0, 383.0, 377.0, 131.0, 142.0, 93.0, 338.0, 47.0, 323.0, 388.0]\n",
      "Step 44, Actions: tensor([ 25,  71,  70,  61,   0,  53,  85,  43, 100,  37,  46,  42,  86,  77,\n",
      "         97,  21,  22,  86,  93,   0,  90,   0,  19,  38,  68]), Used Capacity: [0.9800000190734863, 2.9802322387695312e-08, 1.4901161193847656e-08, 0.0, 0.0, 0.0, 0.0, 0.5199999809265137, 0.2800000309944153, 0.9600000381469727, 0.18000000715255737, 0.550000011920929, 0.0, 0.1666666716337204, -8.940696716308594e-08, 0.3333333134651184, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.949999988079071, 0.9299999475479126, 0.0], Current Time: [177.0, 387.0, 138.0, 109.0, 0.0, 456.0, 174.0, 346.0, 160.0, 342.0, 386.0, 59.0, 175.0, 118.0, 213.0, 76.0, 395.0, 384.0, 163.0, 0.0, 122.0, 0.0, 62.0, 333.0, 407.0]\n",
      "Step 45, Actions: tensor([75, 39, 34, 25,  7,  0,  0, 59, 74, 87, 96, 92, 45, 84,  0, 75, 66,  0,\n",
      "         0,  6, 45, 25, 69, 88,  0]), Used Capacity: [0.4300000071525574, 0.3500000238418579, 0.3500000238418579, 0.14000000059604645, 0.30000001192092896, 0.0, 0.0, 0.4099999666213989, 2.9802322387695312e-08, 0.4566667079925537, 0.0, 0.0, 0.4000000059604645, 0.0, -0.0, 0.166666641831398, 0.3333333134651184, 0.0, 0.0, 0.36000001430511475, 0.5866666436195374, 0.4699999988079071, 0.5166666507720947, 0.5099999904632568, 0.0], Current Time: [195.0, 417.0, 164.0, 146.0, 296.0, 0.0, 0.0, 368.0, 178.0, 351.0, 404.0, 91.0, 239.0, 130.0, 0.0, 81.0, 408.0, 0.0, 0.0, 54.0, 156.0, 222.0, 71.0, 348.0, 0.0]\n",
      "Step 46, Actions: tensor([68, 89, 42, 75,  1, 11, 26, 93, 33, 47,  0, 43, 40, 13, 32, 50, 72,  1,\n",
      "        47, 28, 95, 15, 30, 12, 26]), Used Capacity: [0.0, 2.9802322387695312e-08, 0.6233333349227905, 0.0, 0.48000001907348633, 0.12333333492279053, 0.41333332657814026, -2.9802322387695312e-08, 0.4700000286102295, 0.7633333802223206, 0.0, 0.3333333432674408, 0.9099999666213989, 0.1666666716337204, 0.3333333432674408, 0.3333333134651184, 0.166666641831398, 0.1666666716337204, 0.38999998569488525, 0.45000001788139343, 0.0, 0.6499999761581421, 0.6100000143051147, 0.949999988079071, 0.28999999165534973], Current Time: [210.0, 440.0, 183.0, 180.0, 327.0, 226.0, 43.0, 403.0, 235.0, 362.0, 0.0, 107.0, 288.0, 185.0, 139.0, 92.0, 423.0, 133.0, 25.0, 79.0, 188.0, 284.0, 78.0, 366.0, 29.0]\n",
      "Step 47, Actions: tensor([ 0,  0, 84,  0, 51, 28, 20,  0, 45, 19,  8, 93, 95, 32, 82,  4, 59, 41,\n",
      "        49, 78,  0, 75, 80, 62,  5]), Used Capacity: [0.0, 0.0, 0.273333340883255, 0.0, 0.30000001192092896, 0.2133333384990692, 0.4699999988079071, -0.0, 0.8600000143051147, 0.9966667294502258, 0.2800000011920929, 0.0, 0.5099999904632568, 0.3333333432674408, 0.0, 1.0, -2.9802322387695312e-08, 0.3333333432674408, 0.5899999737739563, 0.36000001430511475, 0.0, 0.17999997735023499, 0.5166666507720947, 0.5099999904632568, 0.7300000190734863], Current Time: [0.0, 0.0, 198.0, 0.0, 367.0, 257.0, 113.0, 0.0, 281.0, 373.0, 328.0, 154.0, 299.0, 189.0, 158.0, 109.0, 431.0, 145.0, 42.0, 116.0, 0.0, 311.0, 87.0, 379.0, 53.0]\n",
      "Step 48, Actions: tensor([ 42,  29,  92,  32,  57,  45,  76,  35,  83,  97,  58,   0,  90,  82,\n",
      "          8, 100,   0,  51,  97,  56,  29,  65,  87,  13,  76]), Used Capacity: [0.47333332896232605, 0.10000000149011612, 0.0, 0.5199999809265137, 0.0, 0.4566666781902313, 0.056666672229766846, 0.1899999976158142, 0.39000001549720764, 0.690000057220459, 0.0, 0.0, 0.0, 0.1666666716337204, 0.5, 0.8333333134651184, -0.0, 0.1666666716337204, 0.19999998807907104, 0.0, 0.40666666626930237, -2.9802322387695312e-08, 0.0, 0.9900000095367432, 0.4400000274181366], Current Time: [21.0, 33.0, 211.0, 142.0, 393.0, 280.0, 147.0, 311.0, 315.0, 383.0, 350.0, 0.0, 329.0, 197.0, 170.0, 132.0, 0.0, 164.0, 58.0, 144.0, 136.0, 330.0, 102.0, 389.0, 70.0]\n",
      "Step 49, Actions: tensor([16, 26,  0, 82,  0, 61, 70, 85, 95, 62, 16, 11,  0, 63, 58, 71, 15,  5,\n",
      "        99,  0, 10,  0, 46, 68, 55]), Used Capacity: [0.9900000095367432, 0.4899999797344208, 0.0, 0.0, 0.0, 0.3333333432674408, 3.725290298461914e-09, 0.0, 2.9802322387695312e-08, 0.23333337903022766, 0.15000000596046448, 0.12333333492279053, 0.0, 0.0, 0.0, 0.6666666269302368, 0.1666666716337204, 0.5, -1.4901161193847656e-08, 0.0, 0.846666693687439, -0.0, 0.44333332777023315, 0.48000001907348633, 2.9802322387695312e-08], Current Time: [47.0, 62.0, 0.0, 174.0, 0.0, 300.0, 177.0, 366.0, 351.0, 389.0, 381.0, 59.0, 0.0, 207.0, 185.0, 147.0, 12.0, 168.0, 87.0, 0.0, 161.0, 0.0, 171.0, 401.0, 91.0]\n",
      "Step 50, Actions: tensor([92, 76, 26,  0, 44, 95,  0,  0, 26, 30, 66, 61, 15,  0,  0, 31, 31, 55,\n",
      "        37, 50, 79,  4, 96, 63, 11]), Used Capacity: [0.5166666507720947, 0.09999999403953552, 0.44999998807907104, 0.0, 0.3499999940395355, 0.09000000357627869, 0.0, 0.0, 0.5400000810623169, 0.34333336353302, 0.0, 0.0, 0.14000000059604645, 0.0, 0.0, 0.8333333134651184, 0.6666666865348816, 0.1666666567325592, 0.47999995946884155, 0.4000000059604645, 0.4400000274181366, 0.33000001311302185, 0.0, 2.9802322387695312e-08, 0.2800000309944153], Current Time: [66.0, 81.0, 12.0, 0.0, 58.0, 318.0, 0.0, 0.0, 389.0, 399.0, 410.0, 106.0, 269.0, 0.0, 0.0, 155.0, 54.0, 184.0, 126.0, 29.0, 186.0, 256.0, 186.0, 417.0, 358.0]\n",
      "Step 51, Actions: tensor([23, 43, 31, 17, 15,  9, 13, 27, 76, 69,  0, 14, 65,  2, 15, 54,  2, 91,\n",
      "        87, 38, 60, 54,  8,  0, 29]), Used Capacity: [0.699999988079071, 0.5399999618530273, 0.7300000190734863, 0.07000000029802322, 0.6200000047683716, 0.6633332967758179, 0.5933333039283752, 0.36000001430511475, 5.960464477539063e-08, 0.11000002920627594, 0.0, 0.20333333313465118, 0.0, 0.6666666865348816, 0.1666666716337204, 0.16666662693023682, 0.8333333730697632, -1.4901161193847656e-08, -2.9802322387695312e-08, 0.5133333206176758, 2.9802322387695312e-08, 0.0, 0.5166666507720947, 0.0, 0.75], Current Time: [141.0, 108.0, 23.0, 57.0, 82.0, 327.0, 73.0, 49.0, 398.0, 409.0, 0.0, 136.0, 309.0, 14.0, 144.0, 161.0, 88.0, 210.0, 167.0, 80.0, 205.0, 285.0, 194.0, 0.0, 387.0]\n",
      "Step 52, Actions: tensor([66, 93, 13, 67, 36, 78, 45, 50,  0, 80, 17, 64,  6, 38, 65, 41, 29, 21,\n",
      "         0, 88,  0,  0, 58, 20, 79]), Used Capacity: [0.18333333730697632, 0.09999996423721313, 0.9766666889190674, 0.0, 0.7300000190734863, 0.5733332633972168, 0.9133332967758179, 0.8799999952316284, 0.0, 2.9802322387695312e-08, 0.5799999833106995, 0.0, 0.4399999976158142, 0.8333333730697632, 0.0, 0.3333333134651184, 1.0, 0.1666666567325592, -0.0, 0.3999999761581421, 0.0, 0.0, 0.0, 0.27000001072883606, 0.2800000011920929], Current Time: [156.0, 128.0, 44.0, 96.0, 106.0, 345.0, 99.0, 70.0, 0.0, 417.0, 287.0, 173.0, 344.0, 29.0, 169.0, 166.0, 95.0, 269.0, 0.0, 102.0, 0.0, 0.0, 200.0, 187.0, 409.0]\n",
      "Step 53, Actions: tensor([ 46,  79,  81,  44,  86,  59,  95, 100,  19,   0,  67,   0,  56,  52,\n",
      "          0,  91,  65,  24,  25, 100,  24,  32,   0,  21,  61]), Used Capacity: [0.25333333015441895, -3.725290298461914e-08, 0.6966667175292969, 0.5366666913032532, 0.6200000047683716, -5.960464477539063e-08, 0.5933333039283752, 0.36000001430511475, 0.5699999928474426, 0.0, 0.0, 0.0, 0.0, 0.1666666865348816, 0.0, 0.166666641831398, 0.8333333134651184, 0.3333333134651184, 0.1899999976158142, -2.9802322387695312e-08, 0.43666666746139526, 0.5899999737739563, 0.0, 0.5199999809265137, 0.0], Current Time: [172.0, 148.0, 59.0, 138.0, 138.0, 365.0, 129.0, 92.0, 25.0, 0.0, 307.0, 0.0, 361.0, 42.0, 0.0, 183.0, 111.0, 335.0, 41.0, 165.0, 170.0, 207.0, 0.0, 372.0, 432.0]\n",
      "Step 54, Actions: tensor([96, 16, 36, 94, 19, 46, 63, 32, 49, 29, 21, 50,  0, 88, 29, 81, 25, 25,\n",
      "        75,  0, 74, 82, 11, 70,  0]), Used Capacity: [0.18333333730697632, 0.16999995708465576, 0.9200000762939453, 0.0, 1.0, 0.3233332633972168, 0.0, 0.4700000286102295, 0.8899999856948853, 0.596666693687439, 0.4399999976158142, 0.33666667342185974, 0.0, 1.4901161193847656e-08, 0.5, -2.9802322387695312e-08, 1.0, 0.5, 0.0, -0.0, 0.0, 0.0, 0.15333333611488342, 0.2499999701976776, 0.0], Current Time: [190.0, 203.0, 69.0, 163.0, 169.0, 385.0, 170.0, 121.0, 65.0, 52.0, 330.0, 30.0, 0.0, 50.0, 121.0, 190.0, 125.0, 350.0, 73.0, 0.0, 188.0, 254.0, 117.0, 392.0, 0.0]\n",
      "Step 55, Actions: tensor([ 73,  25,  86,  15,  65,  96,   0,  82,  99,   4,  71, 100,  31,  46,\n",
      "         35,   0,  79,  71,  15,  45,   0,   0,  26,  71,  31]), Used Capacity: [0.0, 0.7099999785423279, 0.6966667175292969, 0.2566666603088379, 0.7300000190734863, -5.960464477539063e-08, 0.0, 0.36000001430511475, 0.5699999928474426, 0.9066666960716248, 0.0, 0.0, 0.550000011920929, 0.1666666865348816, 0.6666666865348816, -0.0, 0.8333333134651184, 0.3333333134651184, 0.5400000214576721, 0.30666667222976685, 0.0, 0.0, 0.5066666603088379, -2.9802322387695312e-08, 0.10999999940395355], Current Time: [211.0, 290.0, 93.0, 181.0, 190.0, 404.0, 0.0, 137.0, 74.0, 75.0, 353.0, 72.0, 64.0, 110.0, 141.0, 0.0, 134.0, 364.0, 104.0, 53.0, 0.0, 0.0, 151.0, 410.0, 223.0]\n",
      "Step 56, Actions: tensor([ 0, 75, 76, 65, 69,  0, 40, 77, 69, 79, 49,  0, 18, 24, 85, 28, 81, 74,\n",
      "        65, 95,  3, 10, 76, 44, 81]), Used Capacity: [0.0, 0.16999995708465576, 0.24666672945022583, 0.0, 0.3500000238418579, -0.0, 0.5699999928474426, 0.0, 0.0, 0.3100000023841858, 0.23999999463558197, 0.0, 0.75, 0.3333333730697632, 0.5, 0.1666666716337204, 0.3333333134651184, 0.166666641831398, 0.0, 0.0, 0.3400000035762787, 0.28999999165534973, 0.15333333611488342, 0.38999995589256287, 0.0], Current Time: [0.0, 311.0, 118.0, 206.0, 216.0, 0.0, 142.0, 151.0, 115.0, 99.0, 415.0, 0.0, 130.0, 129.0, 151.0, 6.0, 143.0, 372.0, 133.0, 73.0, 28.0, 162.0, 160.0, 426.0, 239.0]\n",
      "Step 57, Actions: tensor([11, 66, 63,  0, 23, 48, 90,  8, 31, 48, 99, 27, 68, 74, 18, 78, 75, 75,\n",
      "         0, 48, 53, 60, 61, 25, 19]), Used Capacity: [0.5099999904632568, -4.470348358154297e-08, 5.960464477539063e-08, 0.0, 0.5600000023841858, 0.15666666626930237, 0.0, 0.44999998807907104, 0.25, 0.7766666412353516, 0.0, 0.550000011920929, 0.550000011920929, 0.16666670143604279, 1.0, 0.0, 0.166666641831398, -2.9802322387695312e-08, 0.0, 0.05000000074505806, 0.0, 0.0, 0.0, 0.9499999284744263, 0.14000000059604645], Current Time: [89.0, 334.0, 140.0, 0.0, 251.0, 131.0, 169.0, 180.0, 153.0, 123.0, 432.0, 50.0, 147.0, 148.0, 159.0, 30.0, 153.0, 393.0, 0.0, 94.0, 52.0, 222.0, 184.0, 445.0, 274.0]\n",
      "Step 58, Actions: tensor([ 4,  0,  2, 27, 73, 34,  0, 58, 42,  9,  0, 77, 81, 96, 68, 12, 52,  0,\n",
      "        27, 98, 11, 40,  0, 94, 69]), Used Capacity: [0.753333330154419, -0.0, 0.21000005304813385, 0.43666666746139526, 0.3500000238418579, 0.19333332777023315, 0.0, 0.0, 0.7599999904632568, 0.996666669845581, 0.0, 0.0, 0.0, 2.9802322387695312e-08, 0.5, 0.1666666716337204, -2.9802322387695312e-08, -0.0, 0.5199999809265137, 0.0, 0.4099999964237213, 0.33000001311302185, 0.0, 0.559999942779541, 0.0], Current Time: [122.0, 0.0, 153.0, 49.0, 279.0, 148.0, 0.0, 201.0, 189.0, 131.0, 0.0, 95.0, 167.0, 165.0, 166.0, 95.0, 167.0, 0.0, 99.0, 129.0, 124.0, 366.0, 0.0, 457.0, 292.0]\n",
      "Step 59, Actions: tensor([61,  2, 35, 21, 94, 18,  6, 41, 81, 59,  4, 24, 50,  0, 10,  2, 21, 33,\n",
      "        77,  0, 61, 90, 40, 75,  4]), Used Capacity: [0.2433333396911621, 0.5799999833106995, 0.3966667056083679, 0.9133332967758179, 2.9802322387695312e-08, 0.3866666555404663, 0.46666666865348816, 0.5699999928474426, 0.5099999904632568, 0.7766666412353516, 0.3100000023841858, 0.23333333432674408, 0.2800000011920929, 0.0, 0.6666666865348816, 0.3333333432674408, 0.3333333134651184, 0.1666666716337204, 0.0, 0.0, 0.0, 0.0, 0.25, -5.960464477539063e-08, 0.5099999904632568], Current Time: [142.0, 339.0, 159.0, 78.0, 298.0, 175.0, 37.0, 235.0, 230.0, 138.0, 160.0, 125.0, 258.0, 0.0, 173.0, 113.0, 287.0, 344.0, 155.0, 0.0, 169.0, 405.0, 117.0, 469.0, 320.0]\n",
      "Step 60, Actions: tensor([  9,  35,  52,  71,  43,  68,  56,  16,  92,  54,  54,  74, 100,  41,\n",
      "         79,  24,  71,  83,   0,  44,   0,   0,  90,   0,  54]), Used Capacity: [0.8366666436195374, 0.7199999690055847, 0.18666671216487885, 0.4366666376590729, 0.3100000321865082, 0.19333332777023315, 0.0, 0.6899999976158142, 0.0, 0.46666663885116577, 0.0, 0.0, 0.0, 0.1666666716337204, 0.1666666865348816, 0.5, -2.9802322387695312e-08, 0.0, 0.0, 0.4099999964237213, 0.0, 0.0, 0.0, -0.0, 0.0], Current Time: [157.0, 379.0, 173.0, 101.0, 324.0, 190.0, 71.0, 255.0, 268.0, 148.0, 174.0, 153.0, 293.0, 26.0, 188.0, 127.0, 315.0, 373.0, 0.0, 97.0, 0.0, 0.0, 129.0, 0.0, 338.0]\n",
      "Step 61, Actions: tensor([59, 85, 17, 77, 93, 84,  0, 91, 48, 98,  2,  0,  9,  1, 60, 74, 12,  0,\n",
      "         7, 94, 18, 33, 34,  9,  9]), Used Capacity: [0.2433333396911621, 0.5799999833106995, 0.46000003814697266, -2.9802322387695312e-08, 2.9802322387695312e-08, 0.15666666626930237, 0.0, 0.12000000476837158, 0.5299999713897705, -2.9802322387695312e-08, 0.4399999976158142, 0.0, 0.23999999463558197, 0.3333333432674408, 1.4901161193847656e-08, 0.3333333134651184, 0.3333333134651184, 0.0, 0.41999998688697815, 0.0, 0.503333330154419, 0.5099999904632568, 0.3100000023841858, 0.4399999976158142, 0.46000000834465027], Current Time: [164.0, 396.0, 189.0, 123.0, 356.0, 212.0, 0.0, 297.0, 278.0, 159.0, 248.0, 0.0, 346.0, 34.0, 191.0, 148.0, 321.0, 0.0, 39.0, 136.0, 18.0, 153.0, 142.0, 214.0, 376.0]\n",
      "Step 62, Actions: tensor([37, 52, 67, 14,  0, 19, 21, 66, 27,  2, 45,  6, 59, 51,  0, 62, 62, 28,\n",
      "        57,  0, 68, 83, 84, 59, 59]), Used Capacity: [0.8199999928474426, 0.0, 0.18666669726371765, 0.2733333110809326, 0.0, 0.3733333349227905, 0.3266666531562805, 7.450580596923828e-09, 0.7999999523162842, 0.4233333170413971, 0.6100000143051147, 0.03999999910593033, 0.0, 0.1666666716337204, 0.0, 0.166666641831398, -2.9802322387695312e-08, 0.1666666716337204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Current Time: [172.0, 435.0, 201.0, 164.0, 0.0, 224.0, 35.0, 315.0, 289.0, 175.0, 274.0, 32.0, 362.0, 50.0, 0.0, 158.0, 330.0, 20.0, 69.0, 0.0, 45.0, 223.0, 159.0, 233.0, 393.0]\n",
      "Step 63, Actions: tensor([87,  0, 85, 64, 37, 98, 71,  6, 77, 18, 95, 56,  0, 91, 37, 52,  0, 11,\n",
      "        16, 16,  8, 34,  0,  0,  0]), Used Capacity: [0.2433333396911621, 0.0, 2.9802322387695312e-08, -2.9802322387695312e-08, 0.5600000023841858, 0.21666666865348816, 0.0, 0.550000011920929, 0.5299999713897705, 0.8500000238418579, 0.4399999976158142, 0.0, 0.0, 0.0, 0.1666666716337204, -2.9802322387695312e-08, -0.0, 0.3333333432674408, 0.5199999809265137, 0.0833333358168602, 0.3766666650772095, 0.5199999809265137, 0.0, 0.0, 0.0], Current Time: [184.0, 0.0, 213.0, 183.0, 24.0, 244.0, 47.0, 345.0, 300.0, 202.0, 297.0, 63.0, 0.0, 64.0, 7.0, 165.0, 0.0, 39.0, 142.0, 101.0, 85.0, 280.0, 0.0, 0.0, 0.0]\n",
      "Step 64, Actions: tensor([54, 34,  0,  0, 31, 69, 31, 56, 98, 68, 52, 18, 10, 14, 30,  0, 19, 15,\n",
      "        66, 66, 58, 84, 33, 47, 50]), Used Capacity: [0.0, 0.4300000071525574, 0.0, -0.0, 0.9099999666213989, 0.0, 0.5299999713897705, 0.0, 0.0, 0.4233333468437195, 0.0, 0.20999999344348907, 0.28999999165534973, 0.1666666716337204, 0.3333333432674408, -0.0, 0.3333333432674408, 0.5, 0.0, 0.0, 0.0, 0.0, 0.36666667461395264, 0.20999999344348907, 0.2800000011920929], Current Time: [196.0, 23.0, 0.0, 0.0, 53.0, 256.0, 78.0, 371.0, 313.0, 211.0, 321.0, 104.0, 176.0, 92.0, 14.0, 0.0, 15.0, 55.0, 174.0, 155.0, 133.0, 306.0, 77.0, 15.0, 214.0]\n",
      "Step 65, Actions: tensor([  0,  15,  15,   3,  81,   0,  41,   0,  29,  31,   5,  68,  60,  64,\n",
      "          3,  17,  38,  17,   0,   0,  31,   0,  23,  35, 100]), Used Capacity: [0.0, 0.75, 0.5600000023841858, 0.30666667222976685, 0.559999942779541, 0.0, 0.5733333230018616, 0.0, 0.20999999344348907, 0.8799999952316284, 0.25, 0.0, 0.0, 0.0, 0.5, 0.1666666716337204, 0.5, 0.6666666865348816, 0.0, 0.0, 0.04333333298563957, 0.0, 0.9100000262260437, 0.5, 0.0], Current Time: [0.0, 46.0, 152.0, 73.0, 88.0, 0.0, 119.0, 0.0, 356.0, 239.0, 345.0, 142.0, 221.0, 110.0, 28.0, 124.0, 65.0, 60.0, 0.0, 0.0, 172.0, 0.0, 99.0, 34.0, 235.0]\n",
      "Step 66, Actions: tensor([30, 17, 65, 31, 87, 29, 91, 21, 12, 81, 55,  0, 27, 33, 53, 67, 41, 65,\n",
      "        20, 25, 81, 43, 73, 97,  3]), Used Capacity: [0.54666668176651, 0.8600000143051147, 0.0, 0.84333336353302, -5.960464477539063e-08, 0.46000000834465027, 0.5299999713897705, 0.5299999713897705, 0.7799999713897705, 0.4233333170413971, 0.0, 0.0, 0.38999998569488525, 0.1666666716337204, 0.3333333134651184, 0.0, 0.6666666865348816, 0.5, 0.2199999988079071, 0.4933333396911621, 0.0, 0.2199999988079071, 0.36666667461395264, 0.2900000214576721, 0.10999999940395355], Current Time: [14.0, 75.0, 174.0, 93.0, 126.0, 68.0, 139.0, 146.0, 367.0, 248.0, 370.0, 0.0, 302.0, 153.0, 46.0, 152.0, 76.0, 73.0, 34.0, 62.0, 194.0, 47.0, 110.0, 52.0, 296.0]\n",
      "Step 67, Actions: tensor([35, 84,  0, 81, 13,  4, 81, 71, 62, 52,  0, 40, 77, 20, 23,  0, 49, 67,\n",
      "        70, 75,  0, 93, 83, 34, 53]), Used Capacity: [0.8400000333786011, 0.4300000071525574, 0.0, 0.30666667222976685, 0.5799999237060547, 0.6399999856948853, 0.0, 0.0, 0.20999997854232788, -2.9802322387695312e-08, 0.0, 0.4466666579246521, 0.0, 0.3333333432674408, 0.5, 0.0, 0.8333333730697632, 0.3333333134651184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48000001907348633, 0.0], Current Time: [27.0, 98.0, 0.0, 113.0, 152.0, 79.0, 155.0, 189.0, 383.0, 286.0, 0.0, 69.0, 326.0, 161.0, 53.0, 0.0, 105.0, 80.0, 67.0, 102.0, 0.0, 77.0, 141.0, 67.0, 318.0]\n",
      "Step 68, Actions: tensor([80, 65, 40, 53, 63, 25,  0, 13, 79, 21, 31, 90,  0, 83,  4, 43, 99, 78,\n",
      "        14,  0, 35, 45, 16,  6, 27]), Used Capacity: [0.29333335161209106, 0.11000001430511475, 0.2800000011920929, 0.0, -5.960464477539063e-08, 0.8899999856948853, 0.0, 0.3700000047683716, -1.4901161193847656e-08, 0.4633333086967468, 0.3799999952316284, 0.0, 0.0, 0.1666666716337204, 0.6666666865348816, 0.1666666716337204, 0.6666666865348816, 0.166666641831398, 0.5799999833106995, 0.0, 0.5833333134651184, 0.11999999731779099, 0.5133333206176758, 0.8300000429153442, 0.27000001072883606], Current Time: [43.0, 116.0, 20.0, 133.0, 170.0, 104.0, 0.0, 214.0, 401.0, 315.0, 213.0, 119.0, 0.0, 180.0, 59.0, 14.0, 122.0, 88.0, 102.0, 0.0, 31.0, 177.0, 177.0, 86.0, 384.0]\n",
      "Step 69, Actions: tensor([41, 31, 43,  0, 10, 79, 48, 63,  0,  3, 43,  0, 12, 70, 87,  7, 69, 61,\n",
      "        64, 32, 12, 95, 43, 56, 77]), Used Capacity: [0.5400000214576721, 0.5900000333786011, 0.8666666746139526, 0.0, 0.15999993681907654, 0.429999977350235, 0.1599999964237213, 0.0, -0.0, 0.7266666293144226, 0.6000000238418579, 0.0, 0.3400000035762787, 0.0, 0.5, 0.3333333432674408, 0.3333333432674408, -2.9802322387695312e-08, 0.0, 0.4300000071525574, 0.8433333039283752, 0.0, 0.7999999523162842, 0.4800000488758087, 0.0], Current Time: [59.0, 140.0, 46.0, 0.0, 195.0, 132.0, 42.0, 226.0, 0.0, 325.0, 232.0, 0.0, 155.0, 190.0, 68.0, 30.0, 136.0, 101.0, 131.0, 36.0, 71.0, 253.0, 189.0, 92.0, 404.0]\n",
      "Step 70, Actions: tensor([43, 67, 90, 26, 42, 54, 98, 19, 43,  8, 93,  3, 42,  0, 54, 19, 88,  0,\n",
      "         0, 82, 85,  0, 93,  3,  0]), Used Capacity: [0.7300000190734863, 0.48000001907348633, 0.5866667032241821, 0.12999999523162842, 0.6099998950958252, 0.2499999701976776, 0.0, 0.11999999731779099, 0.33000001311302185, 0.7833333015441895, 0.3800000250339508, 0.28999999165534973, 0.46000000834465027, 0.0, 0.3333333134651184, 0.5, 0.1666666716337204, -0.0, 0.0, 0.0, 0.25999999046325684, 0.0, 0.5133333206176758, 0.9300000667572021, 0.0], Current Time: [88.0, 163.0, 71.0, 62.0, 218.0, 158.0, 72.0, 257.0, 100.0, 335.0, 248.0, 61.0, 180.0, 0.0, 77.0, 41.0, 167.0, 0.0, 0.0, 79.0, 88.0, 0.0, 199.0, 102.0, 0.0]\n",
      "Step 71, Actions: tensor([85, 33,  5, 76, 60,  8, 44, 69, 41, 71, 81, 53, 62, 21, 80, 57, 91,  7,\n",
      "        26, 46, 62, 36, 66, 85, 39]), Used Capacity: [0.43666669726371765, 0.9500000476837158, 0.7900000214576721, 0.0, 0.4499998986721039, 0.4399999678134918, 0.33000001311302185, 0.0, 0.5600000023841858, 0.31999996304512024, 2.9802322387695312e-08, 0.0, 0.12000000476837158, 0.1666666716337204, 0.166666641831398, 0.3333333134651184, 0.0, 0.1666666716337204, 0.49000000953674316, 0.5733333230018616, 0.0, 0.49000000953674316, 0.0, 0.6400001049041748, 0.5199999809265137], Current Time: [101.0, 182.0, 87.0, 97.0, 256.0, 181.0, 114.0, 292.0, 110.0, 344.0, 262.0, 116.0, 198.0, 10.0, 87.0, 47.0, 181.0, 149.0, 92.0, 118.0, 115.0, 155.0, 208.0, 116.0, 314.0]\n",
      "Step 72, Actions: tensor([93, 83, 55, 34, 92, 30, 94, 22, 91, 58, 33,  0, 92, 11, 20, 29,  6, 49,\n",
      "        76, 96, 34, 86,  0, 53, 23]), Used Capacity: [0.24666669964790344, 0.4800000488758087, 0.5866667032241821, 0.1733333319425583, -8.940696716308594e-08, 0.5799999833106995, 0.0, 0.5600000023841858, 0.32999998331069946, 0.2633332908153534, 0.5800000429153442, 0.0, 7.450580596923828e-09, 0.3333333432674408, 0.3333333134651184, 0.5, 0.1666666716337204, 0.3333333432674408, 0.0, 0.0, 0.03999999910593033, 0.0, 0.0, 0.19000011682510376, 0.9800000190734863], Current Time: [127.0, 200.0, 109.0, 163.0, 294.0, 193.0, 138.0, 328.0, 122.0, 356.0, 302.0, 0.0, 239.0, 17.0, 94.0, 58.0, 194.0, 201.0, 133.0, 149.0, 147.0, 187.0, 0.0, 138.0, 344.0]\n",
      "Step 73, Actions: tensor([91,  6, 28, 84,  0, 17,  0, 72, 93, 53, 83, 22, 13, 12, 73, 79, 40, 57,\n",
      "         0,  0, 84, 31, 24, 84, 73]), Used Capacity: [2.9802322387695312e-08, 0.9900000095367432, 0.6633333563804626, 0.0, -0.0, 0.9333332777023315, 0.0, 0.0, -2.9802322387695312e-08, -2.9802322387695312e-08, 5.960464477539063e-08, 0.2566666603088379, 0.14000001549720764, 0.5, 0.166666641831398, 0.3333333134651184, 0.3333333432674408, 0.1666666716337204, 0.0, 0.0, 0.0, 0.4000000059604645, 0.12999999523162842, 1.1920928955078125e-07, 0.5199999809265137], Current Time: [141.0, 223.0, 136.0, 188.0, 0.0, 214.0, 0.0, 357.0, 131.0, 370.0, 324.0, 73.0, 281.0, 27.0, 113.0, 69.0, 205.0, 229.0, 0.0, 0.0, 174.0, 240.0, 55.0, 157.0, 373.0]\n",
      "Step 74, Actions: tensor([ 7, 81, 78,  0,  6, 67, 27,  0, 25,  0, 27, 72, 63, 61, 70, 69, 90, 99,\n",
      "        11, 36,  0, 81, 74,  0, 89]), Used Capacity: [0.42333337664604187, 0.5099999904632568, 0.5866667032241821, 0.0, 0.6000000238418579, 0.5799999237060547, 0.11999999731779099, 0.0, 0.5799999237060547, -0.0, 0.5700000524520874, 0.0, 1.4901161193847656e-08, 0.3333333134651184, -2.9802322387695312e-08, 0.166666641831398, 0.1666666716337204, 0.0, 0.14000000059604645, 0.11666666716337204, 0.0, 0.0, 0.0, 0.0, 0.0], Current Time: [157.0, 244.0, 153.0, 0.0, 155.0, 229.0, 60.0, 0.0, 387.0, 0.0, 352.0, 106.0, 304.0, 33.0, 125.0, 79.0, 216.0, 258.0, 35.0, 68.0, 0.0, 269.0, 123.0, 0.0, 418.0]\n",
      "Step 75, Actions: tensor([57, 22, 93, 47, 56, 75, 42, 45, 75, 24, 77,  0,  0, 62,  0, 93, 56,  0,\n",
      "        48, 86,  4,  0, 18, 31,  0]), Used Capacity: [2.9802322387695312e-08, 0.8400000333786011, 5.960464477539063e-08, 0.550000011920929, 0.0, 0.3299999237060547, 0.4233333468437195, 0.5400000214576721, -5.960464477539063e-08, 0.39666667580604553, 5.960464477539063e-08, 0.0, 0.0, 0.166666641831398, -0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.7099999785423279, 0.0, 0.3566666543483734, 0.0, 0.1666666716337204, 0.550000011920929, 0.0], Current Time: [166.0, 270.0, 167.0, 29.0, 188.0, 251.0, 74.0, 107.0, 394.0, 325.0, 376.0, 0.0, 0.0, 43.0, 0.0, 88.0, 231.0, 0.0, 56.0, 115.0, 30.0, 0.0, 132.0, 42.0, 0.0]\n",
      "Step 76, Actions: tensor([ 0, 72,  0, 97, 47, 21, 92, 95,  0, 33,  0, 20,  7, 71, 24,  0,  0, 16,\n",
      "        61, 14, 54, 29, 68, 81, 48]), Used Capacity: [0.0, 0.5099999904632568, 0.0, 0.0, 0.5799999833106995, 0.9233332276344299, 0.12000000476837158, 0.0, -0.0, 0.9800000190734863, 0.0, 0.13333334028720856, 0.46000000834465027, -2.9802322387695312e-08, 0.1666666716337204, -0.0, 0.0, 0.3333333432674408, 0.5699999928474426, 0.4466666579246521, 0.0, 0.3100000023841858, 0.0, 0.0, 0.1599999964237213], Current Time: [0.0, 292.0, 0.0, 59.0, 220.0, 266.0, 92.0, 167.0, 0.0, 366.0, 0.0, 131.0, 163.0, 47.0, 79.0, 0.0, 0.0, 57.0, 72.0, 162.0, 57.0, 193.0, 141.0, 53.0, 27.0]\n",
      "Step 77, Actions: tensor([ 5, 56, 37,  4, 97, 71, 77, 37,  8, 83, 18, 70, 57, 30, 27, 49, 42,  2,\n",
      "        98, 64, 32, 79,  0,  0, 98]), Used Capacity: [0.5266666412353516, 0.0, 0.5066666603088379, 0.4300000071525574, 0.0, 0.3299999237060547, 7.450580596923828e-09, 0.4699999988079071, 0.3499999940395355, 0.3966667056083679, 0.5600000023841858, 0.0, 0.0, 0.166666641831398, 0.3333333432674408, 0.1666666716337204, 0.1666666716337204, 0.8333333730697632, 0.0, 0.0, 0.4266666769981384, 0.0, 0.0, 0.0, 0.0], Current Time: [20.0, 311.0, 74.0, 103.0, 256.0, 280.0, 138.0, 217.0, 239.0, 376.0, 93.0, 170.0, 223.0, 54.0, 86.0, 63.0, 16.0, 75.0, 94.0, 191.0, 139.0, 244.0, 0.0, 0.0, 45.0]\n",
      "Step 78, Actions: tensor([47, 38, 23, 54,  9, 35, 11, 87, 10, 74, 11,  0,  0, 80, 77, 47, 92, 66,\n",
      "        29,  0, 82,  0, 10,  2, 21]), Used Capacity: [0.6399999856948853, 0.27000001072883606, 0.9633333683013916, 0.0, 0.5400000214576721, 0.43333324790000916, 0.31333333253860474, 0.0, 0.7899999618530273, 2.9802322387695312e-08, 0.8500000238418579, 0.0, 0.0, -2.9802322387695312e-08, 0.1666666716337204, 0.3333333432674408, 0.0, 0.5, 0.3700000047683716, 0.0, 0.0, 0.0, 0.36000001430511475, 0.36000001430511475, 0.15000000596046448], Current Time: [44.0, 364.0, 99.0, 141.0, 288.0, 295.0, 161.0, 257.0, 272.0, 421.0, 111.0, 0.0, 0.0, 65.0, 92.0, 67.0, 38.0, 99.0, 135.0, 0.0, 170.0, 0.0, 33.0, 230.0, 287.0]\n",
      "Step 79, Actions: tensor([33, 88, 73,  0, 59, 80, 61, 34, 60,  0, 61, 46,  3,  0, 38, 11, 48, 52,\n",
      "        79,  2,  0, 49, 36, 50, 71]), Used Capacity: [0.8433333039283752, 0.0, 0.5066666603088379, 0.0, 0.0, 0.2933332324028015, 0.0, 0.3400000035762787, 0.34999996423721313, 0.0, 0.5600000619888306, 0.23666666448116302, 0.33000001311302185, -0.0, 0.3333333432674408, 0.5, 0.1666666716337204, 0.0, 0.0, 0.2866666615009308, 0.0, 0.44999998807907104, 0.46000000834465027, 0.9399999976158142, 0.0], Current Time: [63.0, 387.0, 126.0, 0.0, 309.0, 305.0, 189.0, 312.0, 287.0, 0.0, 126.0, 77.0, 198.0, 0.0, 114.0, 73.0, 52.0, 106.0, 162.0, 86.0, 0.0, 123.0, 64.0, 242.0, 307.0]\n",
      "Step 80, Actions: tensor([ 83,   0,  87,  37,  33,  85,   0,  84,  18,  38,  68,  96,   5,  49,\n",
      "          5,  97,  17,   9,   0,  52,  33,  46,  60, 100,   0]), Used Capacity: [0.6399999856948853, 0.0, 0.0, 0.476666659116745, 0.550000011920929, 0.18999990820884705, 0.0, 0.0, 0.7799999713897705, 0.5766666531562805, 5.960464477539063e-08, 0.0, 0.5199999809265137, 0.1666666716337204, 0.6666666865348816, 0.3333333134651184, 0.3333333432674408, 0.1666666716337204, 0.0, 0.0, 0.4866666793823242, 0.8299999833106995, 0.09999999403953552, 0.36000001430511475, 0.0], Current Time: [82.0, 0.0, 157.0, 140.0, 384.0, 315.0, 0.0, 357.0, 299.0, 94.0, 139.0, 112.0, 252.0, 65.0, 119.0, 82.0, 67.0, 162.0, 0.0, 106.0, 60.0, 146.0, 75.0, 271.0, 0.0]\n",
      "Step 81, Actions: tensor([55,  1,  0, 87, 83, 58, 50,  0, 68, 35, 42, 32, 53, 99, 41, 99,  5, 59,\n",
      "         9, 15, 83, 96,  1, 14, 47]), Used Capacity: [0.11333334445953369, 0.5400000214576721, 0.0, 0.0, 0.0, -8.940696716308594e-08, 0.3033333420753479, 0.0, 0.34999996423721313, 0.8833333253860474, 0.31000006198883057, 0.05000000074505806, 0.18999996781349182, 0.0, 0.8333333730697632, 0.166666641831398, 0.5, 0.0, 0.15000000596046448, 0.19333332777023315, 0.0, 0.44999998807907104, 0.5566666722297668, 0.9600000381469727, 0.30000001192092896], Current Time: [100.0, 224.0, 0.0, 174.0, 410.0, 327.0, 37.0, 0.0, 313.0, 118.0, 302.0, 136.0, 296.0, 84.0, 123.0, 89.0, 75.0, 184.0, 95.0, 132.0, 82.0, 173.0, 88.0, 291.0, 192.0]\n",
      "Step 82, Actions: tensor([ 97,   8,  14,   0,   0,  39, 100,  39,  58,  85,  92,  82,  55,   0,\n",
      "         55,  61,  35,   0,  59,  65,  44,  99,  51,  52,  97]), Used Capacity: [7.450580596923828e-09, 0.8899999856948853, 0.4300000071525574, 0.0, 0.0, 0.2699999213218689, 0.0, 0.28999999165534973, -2.9802322387695312e-08, 0.5766666531562805, 5.960464477539063e-08, 0.0, -2.9802322387695312e-08, 0.0, 0.5, -2.9802322387695312e-08, 0.6666666865348816, 0.0, 0.0, 0.0, 0.4300000071525574, 0.0, 0.09999999403953552, 0.6000000238418579, 0.0], Current Time: [121.0, 270.0, 99.0, 0.0, 0.0, 386.0, 86.0, 229.0, 329.0, 124.0, 319.0, 158.0, 342.0, 0.0, 136.0, 98.0, 79.0, 0.0, 156.0, 170.0, 112.0, 209.0, 101.0, 305.0, 214.0]\n",
      "Step 83, Actions: tensor([ 3, 51, 12, 18, 11, 89,  0, 89,  0, 88,  0,  0,  0, 28, 74,  6, 26, 12,\n",
      "         0,  0, 94,  0, 86, 64,  0]), Used Capacity: [0.49000000953674316, 0.34999996423721313, 0.7166666984558105, 0.4333333373069763, 0.5600000023841858, -8.940696716308594e-08, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, 0.1666666716337204, 0.3333333134651184, 0.166666641831398, 0.8333333730697632, 0.1666666716337204, 0.0, 0.0, 0.0, 0.0, -7.450580596923828e-09, 0.0, 0.0], Current Time: [141.0, 293.0, 125.0, 41.0, 76.0, 408.0, 0.0, 286.0, 0.0, 149.0, 0.0, 0.0, 0.0, 15.0, 146.0, 120.0, 85.0, 28.0, 0.0, 0.0, 146.0, 0.0, 113.0, 321.0, 0.0]\n",
      "Step 84, Actions: tensor([53, 58, 64, 68, 29,  0, 39,  0, 34,  0, 47, 31, 38, 42, 88, 56, 55, 62,\n",
      "        40, 23,  0, 39,  5, 27, 45]), Used Capacity: [0.0, -2.9802322387695312e-08, 0.2866666913032532, 0.0, 0.9200000166893005, -0.0, 0.2800000011920929, 0.0, 0.5, 0.0, 0.3499999940395355, 0.30000001192092896, 0.38999998569488525, 0.3333333432674408, 0.166666641831398, -2.9802322387695312e-08, 0.6666666865348816, 0.0, 0.6000000238418579, 0.2433333396911621, 0.0, 0.3499999940395355, 0.47999998927116394, 0.550000011920929, 0.10999999940395355], Current Time: [160.0, 317.0, 143.0, 75.0, 195.0, 0.0, 150.0, 0.0, 23.0, 0.0, 59.0, 106.0, 78.0, 22.0, 152.0, 140.0, 112.0, 49.0, 36.0, 72.0, 0.0, 57.0, 148.0, 380.0, 81.0]\n",
      "Step 85, Actions: tensor([ 0, 24, 46, 13, 61, 22, 89, 47, 32, 39, 97, 81, 88, 78, 91,  0, 67,  0,\n",
      "        90, 40, 28, 89, 55, 17, 95]), Used Capacity: [0.0, 0.47999995946884155, 0.75, 0.07333333045244217, 0.36000001430511475, 0.2266666740179062, 0.0, 0.10999999940395355, 0.8300000429153442, 0.5699999928474426, 0.0, 0.0, 0.0, 0.1666666716337204, -2.9802322387695312e-08, -0.0, 0.5, 0.0, 0.0, 0.3100000023841858, 0.15333333611488342, 0.0, 0.0, 0.6800000071525574, 0.0], Current Time: [0.0, 358.0, 158.0, 105.0, 229.0, 16.0, 176.0, 111.0, 58.0, 244.0, 79.0, 158.0, 129.0, 34.0, 162.0, 0.0, 143.0, 0.0, 109.0, 100.0, 113.0, 78.0, 158.0, 394.0, 101.0]\n",
      "Step 86, Actions: tensor([40, 74, 96, 63,  4, 32,  0, 97, 82, 15, 24,  0, 24, 92,  0,  3, 76, 39,\n",
      "         0, 73, 78, 20,  0, 77,  0]), Used Capacity: [0.18333333730697632, -2.9802322387695312e-08, 0.2866666615009308, 0.0, 0.8500000238418579, 0.3700000047683716, 0.0, 0.0, 0.5, 0.9866666793823242, 0.44999998807907104, 0.0, 0.14000000059604645, 0.0, -0.0, 0.1666666716337204, 0.3333333134651184, 0.3333333432674408, 0.0, 0.06666666269302368, 0.0, 0.18000000715255737, 0.0, 0.12999999523162842, 0.0], Current Time: [16.0, 376.0, 182.0, 140.0, 254.0, 36.0, 0.0, 161.0, 67.0, 272.0, 172.0, 0.0, 184.0, 45.0, 0.0, 42.0, 149.0, 104.0, 0.0, 122.0, 156.0, 102.0, 0.0, 411.0, 0.0]\n",
      "Step 87, Actions: tensor([13,  0, 62,  0, 54, 38, 22, 40, 84, 89, 74, 47, 74, 45,  1, 37, 85, 35,\n",
      "        50, 90,  0, 70, 15, 67, 40]), Used Capacity: [0.6633332967758179, -0.0, 0.0, 0.0, 0.36000001430511475, 0.9333333373069763, 0.3633333444595337, 0.46000000834465027, 0.0, 0.4166666865348816, 0.0, 0.0533333346247673, 0.0, 0.1666666716337204, 0.1666666716337204, 0.5, 0.166666641831398, 0.5, 0.25999999046325684, -7.450580596923828e-09, 0.0, 0.0, 0.54666668176651, 0.0, 0.5600000023841858], Current Time: [35.0, 0.0, 195.0, 0.0, 285.0, 59.0, 63.0, 217.0, 104.0, 299.0, 186.0, 24.0, 220.0, 49.0, 80.0, 54.0, 157.0, 110.0, 30.0, 151.0, 0.0, 139.0, 38.0, 427.0, 96.0]\n",
      "Step 88, Actions: tensor([ 63,  36,   0,  50,  79,  72,  28,  90,  17,  65,  30,  97,  37,  95,\n",
      "         12,  32,  98,  89, 100,   0,  43,   8,  65,   0,  90]), Used Capacity: [0.18333330750465393, 0.5199999809265137, 0.0, 0.23333333432674408, 0.0, 0.7066666483879089, 0.8666666746139526, 0.0, 0.5699999928474426, 2.9802322387695312e-08, 0.5699999928474426, 0.0, 0.38999998569488525, 0.0, 0.3333333432674408, 0.6666666865348816, -2.9802322387695312e-08, 0.1666666567325592, 0.0, -0.0, 0.38333332538604736, 0.14000000059604645, 0.0, 0.0, 0.0], Current Time: [49.0, 133.0, 0.0, 73.0, 322.0, 87.0, 79.0, 261.0, 152.0, 324.0, 222.0, 49.0, 295.0, 60.0, 90.0, 61.0, 165.0, 127.0, 83.0, 0.0, 88.0, 179.0, 50.0, 0.0, 116.0]\n",
      "Step 89, Actions: tensor([ 90,  86,  32, 100,   0,  88,  78,   0,  67,   0,  80,   9,  87,   0,\n",
      "         62,  82,   7,  85,  30,  43,  93,  58,  38,   7,  15]), Used Capacity: [-2.9802322387695312e-08, 0.0, 0.4566666781902313, 0.0, 0.0, 0.1433333158493042, 0.3633333444595337, 0.0, 0.0, 0.0, 0.0, 0.04333333298563957, 0.0, 0.0, 0.1666666716337204, 0.5, 0.166666641831398, -1.4901161193847656e-08, 0.41999998688697815, 0.5233333110809326, 0.0, 0.0, 0.3266666531562805, 0.17000000178813934, 0.12999999523162842], Current Time: [98.0, 160.0, 18.0, 105.0, 0.0, 100.0, 103.0, 0.0, 279.0, 0.0, 251.0, 103.0, 362.0, 0.0, 112.0, 68.0, 186.0, 141.0, 101.0, 88.0, 123.0, 211.0, 75.0, 248.0, 225.0]\n",
      "Step 90, Actions: tensor([50, 47, 39,  0,  5, 20, 72, 18, 14, 14,  0, 59,  0,  7, 51, 34, 27, 48,\n",
      "        80, 93,  0,  0, 35, 49,  6]), Used Capacity: [0.596666693687439, 0.2800000011920929, 1.0, 0.0, 0.18000000715255737, 0.6200000047683716, 0.0, 0.3799999952316284, 0.5299999713897705, 0.54666668176651, 0.0, 0.0, 0.0, 0.6666666865348816, 0.0, 0.6666666865348816, 0.3333333134651184, 0.1666666567325592, 0.0, 0.0, 0.0, 0.0, 0.8499999642372131, 0.38999998569488525, 0.7099999785423279], Current Time: [108.0, 255.0, 28.0, 0.0, 128.0, 118.0, 142.0, 111.0, 310.0, 100.0, 0.0, 139.0, 0.0, 49.0, 156.0, 71.0, 204.0, 327.0, 133.0, 130.0, 0.0, 0.0, 101.0, 265.0, 245.0]\n",
      "Step 91, Actions: tensor([100,  11,  82,  42,  12,  82,   0,  46,  64,  64,  13,   0,  23,  40,\n",
      "          0,  84,  77,  98,   0,   0,   1,  37,  85,  57,  65]), Used Capacity: [0.0, 0.6800000071525574, 0.5433332920074463, 0.1433333307504654, 0.4300000071525574, 0.4766666889190674, 0.0, 0.49000000953674316, 0.0, 0.0, 0.3799999952316284, 0.0, 0.550000011920929, 1.0, 0.0, 0.5, 0.166666641831398, -1.4901161193847656e-08, 0.0, 0.0, 0.28333333134651184, 0.17000000178813934, 0.3266666531562805, 0.2199999839067459, 0.5799999833106995], Current Time: [131.0, 281.0, 42.0, 158.0, 165.0, 131.0, 0.0, 146.0, 327.0, 111.0, 78.0, 0.0, 167.0, 55.0, 0.0, 76.0, 216.0, 353.0, 0.0, 0.0, 128.0, 179.0, 110.0, 283.0, 308.0]\n",
      "Step 92, Actions: tensor([ 8, 97,  1, 92, 55, 16, 25, 96,  0, 45, 50, 36, 73, 90, 46, 87, 57,  0,\n",
      "         1, 21, 51, 87, 42, 99, 56]), Used Capacity: [0.4533333480358124, 0.4000000059604645, 0.9199999570846558, 0.0, 0.25, 0.8500000238418579, 0.3400000035762787, 0.3799999952316284, 0.0, 0.5866666436195374, 0.7699999809265137, 0.15000000596046448, 0.0, 0.6666666269302368, 0.1666666716337204, 0.1666666567325592, -2.9802322387695312e-08, -0.0, 0.4699999988079071, 0.15333333611488342, 0.0, 0.0, 0.5133333206176758, -1.4901161193847656e-08, 0.0], Current Time: [145.0, 303.0, 58.0, 187.0, 200.0, 150.0, 72.0, 187.0, 0.0, 122.0, 93.0, 26.0, 215.0, 72.0, 45.0, 84.0, 225.0, 0.0, 55.0, 68.0, 168.0, 216.0, 143.0, 302.0, 325.0]\n",
      "Step 93, Actions: tensor([ 58,  61,  89,   0,  35,  70,  75,  68,  46,  95, 100,  86,   0,  57,\n",
      "         96,  53,   0,  22,  51,  11,   0,   0,  88,   8,   0]), Used Capacity: [0.0, 0.0, 0.3766666054725647, 0.0, 0.5399999618530273, 0.3733333647251129, 0.0, 0.0, 0.28999999165534973, 0.0, 0.3799999952316284, 0.0, 0.0, -5.960464477539063e-08, 0.0, -1.4901161193847656e-08, -0.0, 0.1666666716337204, 0.0, 0.27666667103767395, 0.0, 0.0, 0.18666666746139526, 0.3999999761581421, 0.0], Current Time: [173.0, 329.0, 76.0, 0.0, 240.0, 165.0, 98.0, 262.0, 143.0, 131.0, 106.0, 49.0, 0.0, 92.0, 66.0, 100.0, 0.0, 46.0, 101.0, 86.0, 0.0, 0.0, 158.0, 312.0, 0.0]\n",
      "Step 94, Actions: tensor([ 0,  0, 33, 36, 62,  6,  0,  0, 96, 43, 63, 21, 46,  0, 26,  0, 45,  3,\n",
      "         0, 61, 21, 50, 92, 58, 44]), Used Capacity: [0.0, 0.0, 0.9266666173934937, 0.3866666555404663, 0.28999996185302734, 0.9733333587646484, 0.0, 0.0, 0.0, 0.47999998927116394, 0.0, 0.4466666579246521, 0.3199999928474426, -0.0, 0.1666666716337204, -0.0, 0.1666666716337204, 0.3333333432674408, 0.0, 0.15333333611488342, 0.5933333039283752, 0.4099999964237213, 0.0, -2.9802322387695312e-08, 0.36000001430511475], Current Time: [0.0, 0.0, 91.0, 35.0, 265.0, 178.0, 0.0, 0.0, 152.0, 142.0, 126.0, 91.0, 98.0, 0.0, 90.0, 0.0, 124.0, 51.0, 0.0, 107.0, 18.0, 178.0, 175.0, 324.0, 141.0]\n",
      "Step 95, Actions: tensor([ 22,  50,  51,  20,  85,  56,  32,  14,   3,  93,  20,  71,  96,  36,\n",
      "         50,   5,  33,  26,   6,  71,  71, 100,   0,  15,  94]), Used Capacity: [0.1966666728258133, 0.4300000071525574, 0.5499999523162842, 0.6833332777023315, -2.9802322387695312e-08, 0.3733333349227905, 0.273333340883255, 0.38999998569488525, 0.5099999904632568, 0.0, 0.5, 0.0, 0.0, 0.1666666716337204, 0.3333333432674408, 0.1666666716337204, 0.3333333432674408, 0.5, 0.14000000059604645, 0.0, 0.0, 0.0, 0.0, 0.5099999904632568, 0.0], Current Time: [52.0, 145.0, 101.0, 58.0, 286.0, 198.0, 42.0, 28.0, 201.0, 184.0, 159.0, 116.0, 156.0, 28.0, 107.0, 13.0, 142.0, 57.0, 45.0, 137.0, 47.0, 203.0, 0.0, 375.0, 159.0]\n",
      "Step 96, Actions: tensor([19, 28, 27, 70, 20, 66, 82, 10, 53,  0, 70,  0, 21, 86, 76, 20, 20, 29,\n",
      "        56,  0, 20,  0, 45, 65, 41]), Used Capacity: [0.7599999904632568, 0.8700000047683716, 0.9566665887832642, 0.3866666257381439, 0.5099999904632568, 0.0, 0.0, 0.7799999713897705, 0.0, 0.0, 0.0, 0.0, 0.3700000047683716, 0.0, 0.1666666716337204, 0.3333333432674408, 0.5, 0.6666666865348816, 0.0, 0.0, 0.2566666603088379, 0.0, 0.03333333507180214, 0.0, 0.14000000059604645], Current Time: [74.0, 214.0, 119.0, 82.0, 323.0, 209.0, 87.0, 73.0, 334.0, 0.0, 179.0, 0.0, 225.0, 57.0, 112.0, 25.0, 153.0, 68.0, 76.0, 0.0, 87.0, 0.0, 56.0, 396.0, 274.0]\n",
      "Step 97, Actions: tensor([ 72, 100,  83,  86,  70,  42,  24,  64,   0,  13,  10,  26,  71,   0,\n",
      "        100,  10,  70,  79,   0,  22,  70,  19,  31,   0,  91]), Used Capacity: [0.5633333325386047, 0.4399999976158142, 0.4066665768623352, -2.9802322387695312e-08, 0.0, 0.10999999940395355, 0.4399999976158142, 0.38999998569488525, 0.0, 0.28333333134651184, 0.5799999833106995, 0.35333332419395447, 0.0, 0.0, 0.0, 0.5, 0.3333333134651184, 0.5, 0.0, 0.43666666746139526, 0.0, 0.46000000834465027, 0.5733333826065063, 0.0, 0.0], Current Time: [90.0, 284.0, 140.0, 101.0, 357.0, 228.0, 143.0, 96.0, 0.0, 21.0, 236.0, 28.0, 272.0, 0.0, 127.0, 35.0, 170.0, 79.0, 0.0, 38.0, 139.0, 203.0, 72.0, 0.0, 294.0]\n",
      "Step 98, Actions: tensor([69, 78, 77,  7,  0, 92, 74, 26,  4, 63, 60, 76,  0, 22, 49, 60, 83, 76,\n",
      "        21, 72,  0, 69, 95, 30,  0]), Used Capacity: [0.0, 0.0, -8.940696716308594e-08, 0.19333329796791077, 0.0, 0.0, 0.0, 0.5799999833106995, 0.4699999988079071, 0.0, 0.0, 0.0, 0.0, 0.1666666716337204, 0.3333333432674408, 0.3333333134651184, 0.166666641831398, 0.3333333134651184, 0.10999999940395355, 0.0, 0.0, 0.0, 0.5400000214576721, 0.6000000238418579, 0.0], Current Time: [115.0, 319.0, 169.0, 132.0, 0.0, 245.0, 178.0, 123.0, 189.0, 58.0, 256.0, 71.0, 0.0, 7.0, 141.0, 43.0, 191.0, 88.0, 45.0, 60.0, 0.0, 229.0, 88.0, 127.0, 0.0]\n",
      "Step 99, Actions: tensor([45,  0,  0, 57, 27,  0,  0, 76, 54, 16,  0,  0, 32, 17, 99, 44, 11, 72,\n",
      "        35,  0,  2,  0, 81, 45, 17]), Used Capacity: [0.3466666638851166, 0.0, -0.0, -2.9802322387695312e-08, 0.20999999344348907, 0.0, 0.0, 0.38999998569488525, 0.0, 0.54666668176651, 0.0, 0.0, 0.12999999523162842, 0.3333333432674408, 0.0, 0.5, 0.3333333134651184, 0.166666641831398, 0.2800000011920929, 0.0, 0.550000011920929, 0.0, 0.0, 0.7400000095367432, 0.28999999165534973], Current Time: [134.0, 0.0, 0.0, 172.0, 29.0, 0.0, 0.0, 144.0, 201.0, 146.0, 0.0, 0.0, 176.0, 17.0, 159.0, 48.0, 217.0, 105.0, 95.0, 0.0, 88.0, 0.0, 103.0, 139.0, 65.0]\n",
      "Step 100, Actions: tensor([95, 37, 24,  0, 50, 41, 46, 60,  0, 66, 39, 12, 82, 67,  0, 94, 95, 53,\n",
      "        71, 34, 52, 38,  0, 80, 32]), Used Capacity: [0.0, 0.33000001311302185, 0.5933333039283752, -0.0, 0.5400000214576721, 0.596666693687439, 0.39666667580604553, 0.0, 0.0, 0.0, 0.4000000059604645, 0.13333334028720856, 0.0, 0.1666666716337204, 0.0, 0.3333333134651184, 0.166666641831398, -2.9802322387695312e-08, 0.17000000178813934, 0.07333333045244217, 0.0, 0.5799999833106995, 0.0, 0.13999998569488525, 0.4599999785423279], Current Time: [164.0, 45.0, 37.0, 0.0, 81.0, 17.0, 32.0, 208.0, 0.0, 157.0, 42.0, 27.0, 218.0, 34.0, 0.0, 57.0, 226.0, 117.0, 112.0, 75.0, 115.0, 262.0, 0.0, 151.0, 85.0]\n",
      "Step 101, Actions: tensor([ 0, 87, 45,  1, 77, 91, 96,  0, 39,  0, 89, 15,  0, 72, 21, 70, 61,  0,\n",
      "        85,  9, 16, 88, 25, 95, 67]), Used Capacity: [0.0, 0.0, 0.6899999380111694, 0.2199999988079071, 0.33000004291534424, 0.0, 0.0, 0.0, 0.27000001072883606, 0.0, 0.0, 0.5766666531562805, 0.0, 0.0, 0.1666666716337204, 0.166666641831398, -2.9802322387695312e-08, -0.0, 0.0, 0.6033332943916321, 0.12999999523162842, 0.0, 0.07999999821186066, -1.4901161193847656e-08, 0.16999998688697815], Current Time: [0.0, 65.0, 68.0, 60.0, 112.0, 129.0, 67.0, 0.0, 22.0, 0.0, 62.0, 53.0, 0.0, 40.0, 24.0, 68.0, 255.0, 0.0, 145.0, 99.0, 164.0, 300.0, 77.0, 165.0, 103.0]\n",
      "Step 102, Actions: tensor([15, 12, 95, 51, 40, 37,  0, 20, 37, 17, 40, 62, 25, 26, 31, 55,  0, 30,\n",
      "         0, 59, 66,  0, 75, 37, 82]), Used Capacity: [0.2933333218097687, 0.14000000059604645, 0.5933332443237305, 0.0, 0.690000057220459, 0.3033333420753479, 0.0, 0.5299999713897705, 0.4100000262260437, 0.5166666507720947, 0.5, 0.44333332777023315, 0.5199999809265137, 0.3333333432674408, 0.3333333432674408, -2.9802322387695312e-08, -0.0, 0.1666666716337204, 0.0, 0.07333332300186157, 0.0, 0.0, 0.0, 0.2799999713897705, -1.4901161193847656e-08], Current Time: [10.0, 89.0, 94.0, 96.0, 138.0, 136.0, 0.0, 49.0, 58.0, 32.0, 158.0, 105.0, 115.0, 51.0, 42.0, 81.0, 0.0, 186.0, 0.0, 121.0, 190.0, 0.0, 92.0, 181.0, 122.0]\n",
      "Step 103, Actions: tensor([29, 62, 74, 35, 90, 87, 14, 29, 87, 41, 90, 65, 75, 76, 81,  0, 39, 80,\n",
      "         4, 84,  0, 41, 50, 40, 25]), Used Capacity: [0.5333333015441895, 0.0, -5.960464477539063e-08, 0.5699999928474426, 0.33000004291534424, 0.0, 0.1899999976158142, 0.7199999690055847, 0.27000004053115845, 0.7933332920074463, 0.0, 0.0, 0.0, 0.0, 0.1666666716337204, -0.0, 0.6666666865348816, 0.0, 0.3499999940395355, -7.450580596923828e-09, 0.0, 0.4399999976158142, 0.5199999809265137, 0.6100000143051147, 0.3100000023841858], Current Time: [28.0, 108.0, 109.0, 167.0, 169.0, 160.0, 55.0, 60.0, 70.0, 40.0, 176.0, 145.0, 168.0, 62.0, 48.0, 0.0, 14.0, 203.0, 54.0, 159.0, 0.0, 57.0, 122.0, 198.0, 140.0]\n",
      "Step 104, Actions: tensor([ 79,  45,   0,  85, 100,   1,  64,  79,  89,  67,   0,   0,   0,   0,\n",
      "         71,  13,  89,   0,  54,   0,   7,  91, 100,  87,  75]), Used Capacity: [0.2933332920074463, 0.36000001430511475, -0.0, 0.0, 2.9802322387695312e-08, 0.5333333611488342, 0.0, 0.5299999713897705, 2.9802322387695312e-08, 0.27666664123535156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1666666716337204, 0.0, 0.0, 0.0, -0.0, 0.41999998688697815, 0.0, 0.0, 0.33000001311302185, 0.0], Current Time: [54.0, 159.0, 0.0, 190.0, 196.0, 179.0, 93.0, 97.0, 111.0, 52.0, 0.0, 0.0, 0.0, 0.0, 63.0, 22.0, 38.0, 0.0, 111.0, 0.0, 18.0, 104.0, 152.0, 215.0, 158.0]\n",
      "Step 105, Actions: tensor([34, 95, 47,  0,  0, 51,  0, 70,  5, 40, 23,  4, 49, 37,  0, 33, 24, 20,\n",
      "         0, 30, 57,  6,  0, 90, 14]), Used Capacity: [0.8833332657814026, 0.0, 0.20666666328907013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5900000333786011, 0.7699999809265137, 0.17000000178813934, 0.1366666704416275, 0.3799999952316284, 0.1666666716337204, 0.0, 0.3333333432674408, 1.0, 0.8333333134651184, 0.0, 0.18000000715255737, 0.0, 0.36000001430511475, 0.0, 0.0, 0.20999999344348907], Current Time: [83.0, 181.0, 8.0, 0.0, 0.0, 194.0, 0.0, 135.0, 151.0, 65.0, 29.0, 49.0, 137.0, 15.0, 0.0, 40.0, 52.0, 17.0, 0.0, 34.0, 45.0, 127.0, 0.0, 273.0, 235.0]\n",
      "Step 106, Actions: tensor([65,  0, 30,  6,  3,  0, 49,  0, 55, 90, 73, 54, 99, 87, 39, 63, 74, 70,\n",
      "        32, 80, 23, 56,  3,  5, 64]), Used Capacity: [0.5899999141693115, 0.0, 0.7166666388511658, 0.44999998807907104, 0.5699999928474426, 0.0, 0.47333332896232605, 0.0, 5.960464477539063e-08, 0.27666664123535156, 0.0, 0.0, 0.0, 0.0, 0.1666666716337204, 0.1666666716337204, 0.0, 0.0, 0.20000000298023224, 0.0, 0.4399999976158142, 0.0, 0.22333332896232605, 0.4699999988079071, 0.0], Current Time: [110.0, 0.0, 25.0, 21.0, 19.0, 0.0, 38.0, 0.0, 177.0, 74.0, 52.0, 83.0, 178.0, 38.0, 31.0, 55.0, 65.0, 34.0, 39.0, 76.0, 78.0, 158.0, 24.0, 296.0, 271.0]\n",
      "Step 107, Actions: tensor([84, 18,  4, 56, 53, 31, 99, 11,  0, 91,  1,  0,  0,  0, 89, 83,  0, 18,\n",
      "        82,  0, 73, 16, 53, 55,  0]), Used Capacity: [-5.960464477539063e-08, 0.550000011920929, 0.8233333230018616, 0.0, 0.0, 0.5099999904632568, 0.0, 0.1599999964237213, 0.0, -2.9802322387695312e-08, 0.10000000149011612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1666666716337204, 0.0, 0.0, 0.0, 0.2800000011920929, 0.0, 0.0, 0.0], Current Time: [132.0, 50.0, 53.0, 41.0, 43.0, 28.0, 88.0, 55.0, 0.0, 83.0, 106.0, 0.0, 0.0, 0.0, 70.0, 70.0, 0.0, 44.0, 59.0, 0.0, 98.0, 190.0, 34.0, 315.0, 0.0]\n",
      "Step 108, Actions: tensor([ 0, 20, 80, 28, 24, 81,  0, 61,  9, 50, 51, 41,  8, 39,  0,  0,  0,  4,\n",
      "         8, 33,  0, 66,  0,  0, 34]), Used Capacity: [-0.0, 0.9399999976158142, 0.31333333253860474, 0.5699999928474426, 0.5699999928474426, 0.0, 0.0, 0.0, 0.5400000214576721, 0.29999998211860657, 0.0, 0.2933333218097687, 0.20000000298023224, 0.1666666716337204, 0.0, 0.0, 0.0, 0.3333333432674408, 0.23999999463558197, 0.20666666328907013, 0.0, 0.0, 0.0, 0.0, 0.3799999952316284], Current Time: [0.0, 85.0, 76.0, 80.0, 161.0, 46.0, 0.0, 76.0, 22.0, 290.0, 151.0, 89.0, 36.0, 36.0, 0.0, 0.0, 0.0, 55.0, 76.0, 33.0, 0.0, 230.0, 0.0, 0.0, 226.0]\n",
      "Step 109, Actions: tensor([ 32,  70,  97,  78,  74,   0,  47,   7,  59, 100,   0,  91,  58,  89,\n",
      "         44,   1,   0,  68,  58,  83,  39,   0,  20,   4,  84]), Used Capacity: [0.5866666436195374, 0.550000011920929, 0.1066666692495346, 0.0, 0.0, 0.0, 0.28999999165534973, 0.23000000417232513, 0.0, -2.9802322387695312e-08, 0.0, 0.0, 0.0, 0.0, 0.1666666716337204, 0.1666666716337204, 0.0, 0.1666666716337204, 0.0, 0.0, 0.20666666328907013, 0.0, 0.5333333611488342, 0.30000001192092896, 0.0], Current Time: [24.0, 105.0, 106.0, 111.0, 199.0, 0.0, 62.0, 92.0, 44.0, 305.0, 0.0, 146.0, 87.0, 60.0, 45.0, 23.0, 0.0, 65.0, 100.0, 77.0, 22.0, 0.0, 18.0, 23.0, 250.0]\n",
      "Step 110, Actions: tensor([82, 68, 54,  0,  0,  0, 97,  1, 44,  0, 26,  0, 47,  0, 16, 51,  0, 54,\n",
      "         0,  0, 89, 44, 70, 54,  0]), Used Capacity: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49000000953674316, 0.28999999165534973, -0.0, 0.12999999523162842, 0.0, 0.4099999964237213, 0.0, 0.3333333432674408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000000149011612, 0.0, 0.0, 0.0], Current Time: [35.0, 142.0, 136.0, 0.0, 0.0, 0.0, 96.0, 110.0, 66.0, 0.0, 68.0, 0.0, 123.0, 0.0, 56.0, 52.0, 0.0, 69.0, 0.0, 0.0, 43.0, 35.0, 32.0, 156.0, 0.0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter logits (Tensor of shape (25, 101)) of distribution Categorical(logits: torch.Size([25, 101])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        ...,\n        [-0.3666,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [   -inf, -1.0355, -1.3820,  ...,    -inf,    -inf,    -inf]])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m masked_logits = logits.masked_fill(mask, \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-inf\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# STEP 3: Sample action using Categorical distribution\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m dist = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdistributions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmasked_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# print(dist.logits)\u001b[39;00m\n\u001b[32m     23\u001b[39m actions = dist.sample()  \u001b[38;5;66;03m# shape: (B,), each in [0, N-1]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributions\\categorical.py:73\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, probs, logits, validate_args)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m._num_events = \u001b[38;5;28mself\u001b[39m._param.size()[-\u001b[32m1\u001b[39m]\n\u001b[32m     70\u001b[39m batch_shape = (\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mself\u001b[39m._param.size()[:-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._param.ndimension() > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch.Size()\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributions\\distribution.py:72\u001b[39m, in \u001b[36mDistribution.__init__\u001b[39m\u001b[34m(self, batch_shape, event_shape, validate_args)\u001b[39m\n\u001b[32m     70\u001b[39m         valid = constraint.check(value)\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._is_all_true(valid):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     73\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m             )\n\u001b[32m     79\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mValueError\u001b[39m: Expected parameter logits (Tensor of shape (25, 101)) of distribution Categorical(logits: torch.Size([25, 101])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        ...,\n        [-0.3666,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [ 0.0000,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n        [   -inf, -1.0355, -1.3820,  ...,    -inf,    -inf,    -inf]])"
     ]
    }
   ],
   "source": [
    "#Simulate environment\n",
    "\n",
    "batch_instance = batchify(instances)\n",
    "state = StateCPDPTW.initialize(batch_instance)\n",
    "B = state.demand.size(0)\n",
    "N = state.demand.size(-1)\n",
    "step = 0\n",
    "all_actions = []         # to store actions at each step\n",
    "all_used_capacity = []   # optional\n",
    "\n",
    "while not state.all_finished() and step < 200:\n",
    "    # STEP 1: Random logits for actions (could come from a model)\n",
    "    logits = torch.randn(B, N)\n",
    "\n",
    "    mask = state.get_mask().squeeze(1)\n",
    "\n",
    "    # STEP 2: Apply mask â†’ invalid actions should never be selected\n",
    "    masked_logits = logits.masked_fill(mask, float('-inf'))\n",
    "\n",
    "    # STEP 3: Sample action using Categorical distribution\n",
    "    dist = torch.distributions.Categorical(logits=masked_logits)\n",
    "    # print(dist.logits)\n",
    "    actions = dist.sample()  # shape: (B,), each in [0, N-1]\n",
    "\n",
    "    # STEP 4: Update environment â€” you define this logic\n",
    "    # Example: increase state by action ID\n",
    "    state = state.update(selected=actions)\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    all_actions.append(actions)\n",
    "    all_used_capacity.append(state.used_capacity.squeeze(1).tolist())\n",
    "\n",
    "    print(f\"Step {step}, Actions: {actions}, Used Capacity: {state.used_capacity.squeeze(1).tolist()}, Current Time: {state.current_time.squeeze(1).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79ad8198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_actions_stack = torch.stack(all_actions, dim=1)  # shape: (B, num_steps)\n",
    "torch.unique(all_actions_stack[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3adbcbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPDPTW(object):\n",
    "\n",
    "    VEHICLE_CAPACITY = 1.0\n",
    "\n",
    "    @staticmethod\n",
    "    def get_costs(dataset, pi):\n",
    "        batch_size, graph_size = dataset['demand'].size()\n",
    "\n",
    "        sorted_pi = pi.data.sort(1)[0]\n",
    "\n",
    "        demand_with_depot = torch.cat(\n",
    "            (\n",
    "                torch.full_like(dataset['demand'][:, :1], 0),\n",
    "                dataset['demand'][:, 1:]\n",
    "            ), dim = 1\n",
    "        )\n",
    "        d = demand_with_depot.gather(1, pi)\n",
    "\n",
    "        used_cap = torch.zeros_like(dataset['demand'][:, 0])\n",
    "        for i in range (pi.size(1)):\n",
    "            used_cap += d[:, i]\n",
    "            used_cap[used_cap < 0] = 0\n",
    "\n",
    "        loc_with_depot = torch.cat((dataset['coords'][:, :1], dataset['coords'][:, 1:]), dim=1)\n",
    "        d = loc_with_depot.gather(1, pi[..., None].expand(*pi.size(), loc_with_depot.size(-1)))\n",
    "\n",
    "        return (\n",
    "            (d[:, 1:] - d[:, :-1]).norm(p=2, dim=2).sum(1)\n",
    "            + (d[:, 0] - dataset['coords'][:, 0]).norm(p=2, dim=1)\n",
    "            + (d[:, -1] - dataset['coords'][:, 0]).norm(p=2, dim=1)\n",
    "        ), None\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_dataset(*args, **kwargs):\n",
    "        return CPDPTWDataset(*args, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_state(*args, **kwargs):\n",
    "        return StateCPDPTW.initialize(*args, **kwargs)\n",
    "\n",
    "class CPDPTWDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        file_paths = glob.glob(os.path.join(data_path,'*.txt'))\n",
    "        for fp in file_paths:\n",
    "            instance = read_pdptw_file(fp)\n",
    "            self.data.append(instance)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def read_pdptw_file(filepath):\n",
    "        data = {\n",
    "            \"metadata\": {},\n",
    "            \"nodes\": [],\n",
    "            \"edges\": []\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        section = \"metadata\"\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Section switches\n",
    "            if line == \"NODES\":\n",
    "                section = \"nodes\"\n",
    "                continue\n",
    "            elif line == \"EDGES\":\n",
    "                section = \"edges\"\n",
    "                continue\n",
    "            elif line == \"EOF\":\n",
    "                break\n",
    "\n",
    "            if section == \"metadata\":\n",
    "                if \":\" in line:\n",
    "                    key, value = line.split(\":\", 1)\n",
    "                    data[\"metadata\"][key.strip()] = value.strip()\n",
    "\n",
    "            elif section == \"nodes\":\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 8:\n",
    "                    node = {\n",
    "                        \"id\": int(parts[0]),\n",
    "                        \"x\": float(parts[1]),\n",
    "                        \"y\": float(parts[2]),\n",
    "                        \"demand\": int(parts[3]),\n",
    "                        \"ready_time\": int(parts[4]),\n",
    "                        \"due_time\": int(parts[5]),\n",
    "                        \"service_time\": int(parts[6]),\n",
    "                        \"pickup_or_delivery\": 0 if (int(parts[7]) == 0 and int(parts[8]) == 0) else (-1 if int(parts[7]) > 0 else 1),  # 0 = depot, 1 = pickup, -1 = delivery,...\n",
    "                        \"pair_id\": int(parts[7]) if int(parts[7]) > 0 else int(parts[8])\n",
    "                    }\n",
    "                    data[\"nodes\"].append(node)\n",
    "\n",
    "            elif section == \"edges\":\n",
    "                weights = list(map(int, line.split()))\n",
    "                data[\"edges\"].append(weights)\n",
    "\n",
    "        nodes = []\n",
    "\n",
    "        for node_data in data[\"nodes\"]:\n",
    "            node = VRPNode(\n",
    "                idx=node_data[\"id\"],\n",
    "                x=node_data[\"x\"],\n",
    "                y=node_data[\"y\"],\n",
    "                demand=node_data[\"demand\"]/int(data['metadata'].get(\"CAPACITY\", 1)),\n",
    "                a=node_data[\"ready_time\"],\n",
    "                b=node_data[\"due_time\"],\n",
    "                s=node_data[\"service_time\"],\n",
    "                role=node_data[\"pickup_or_delivery\"],\n",
    "                pair=node_data[\"pair_id\"]\n",
    "            )\n",
    "            nodes.append(node)\n",
    "\n",
    "        capacity = int(data[\"metadata\"].get(\"CAPACITY\", 0))\n",
    "        K = int(data[\"metadata\"].get(\"NUM_VEHICLES\", 1e10))\n",
    "        dmat = data[\"edges\"]\n",
    "        instance = VRPInstance(nodes, capacity, K, dmat)\n",
    "\n",
    "        return instance\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        instance = self.data[idx]\n",
    "        return instance.build_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb9f27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:/OneDrive - Hanoi University of Science and Technology/Projects/Project 1/Data/Sartori&Buriol/Instances/n100/'\n",
    "dataset = CPDPTWDataset(data_path)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c49682b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import math\n",
    "from typing import NamedTuple\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_heads,\n",
    "            input_dim,\n",
    "            embed_dim,\n",
    "            val_dim=None,\n",
    "            key_dim=None\n",
    "    ):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        if val_dim is None:\n",
    "            val_dim = embed_dim // num_heads\n",
    "        if key_dim is None:\n",
    "            key_dim = val_dim\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.val_dim = val_dim\n",
    "        self.key_dim = key_dim\n",
    "\n",
    "        self.norm_factor = 1 / math.sqrt(key_dim)  # See Attention is all you need\n",
    "\n",
    "        self.W_query = nn.Parameter(torch.Tensor(num_heads, input_dim, key_dim))\n",
    "        self.W_key = nn.Parameter(torch.Tensor(num_heads, input_dim, key_dim))\n",
    "        self.W_value = nn.Parameter(torch.Tensor(num_heads, input_dim, val_dim))\n",
    "\n",
    "        self.W_out = nn.Parameter(torch.Tensor(num_heads, val_dim, embed_dim))\n",
    "\n",
    "        self.init_parameters()\n",
    "    \n",
    "    def init_parameters(self):\n",
    "\n",
    "        for param in self.parameters():\n",
    "            stdv = 1. / math.sqrt(param.size(-1))\n",
    "            param.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.view(batch_size, -1, self.num_heads, x.size(-1) // self.num_heads)\n",
    "        return x.permute(2, 0, 1, 3)  # (num_heads, batch_size, seq_len, dim_per_head)\n",
    "\n",
    "    def forward(self, q, h=None, mask=None):\n",
    "\n",
    "        if h is None:\n",
    "            h = q\n",
    "        \n",
    "        batch_size, graph_size, input_dim = h.shape\n",
    "        n_query = q.shape[1]\n",
    "\n",
    "        hflat = h.contiguous().view(-1, input_dim)\n",
    "        qflat = q.contiguous().view(-1, input_dim)\n",
    "\n",
    "        Q = torch.matmul(qflat, self.W_query)\n",
    "        K = torch.matmul(hflat, self.W_key)\n",
    "        V = torch.matmul(hflat, self.W_value)\n",
    "\n",
    "        Q = self.split_heads(Q, batch_size)\n",
    "        K = self.split_heads(K, batch_size)\n",
    "        V = self.split_heads(V, batch_size)\n",
    "\n",
    "        compatibility = self.norm_factor * torch.matmul(Q, K.transpose(2, 3))\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.view(1, batch_size, n_query, graph_size).expand_as(compatibility)\n",
    "            compatibility[mask] = -np.inf\n",
    "\n",
    "        attn = torch.softmax(compatibility, dim=-1)\n",
    "\n",
    "        if mask is not None:\n",
    "            attnc = attn.clone()\n",
    "            attnc[mask] = 0\n",
    "            attn = attnc\n",
    "        \n",
    "        heads = torch.matmul(attn, V)\n",
    "\n",
    "        out = torch.mm(\n",
    "            heads.permute(1, 2, 0, 3).contiguous().view(-1, self.num_heads * self.val_dim),\n",
    "            self.W_out.view(-1, self.embed_dim)\n",
    "        ).view(batch_size, n_query, self.embed_dim)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ce927c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization(nn.Module):\n",
    "    def __init__(self, embed_dim, normalization='batch'):\n",
    "        super(Normalization, self).__init__()\n",
    "\n",
    "        if normalization == 'batch':\n",
    "            self.norm = nn.BatchNorm1d(embed_dim, affine=True)\n",
    "        elif normalization == 'layer':\n",
    "            self.norm = nn.InstanceNorm1d(embed_dim, affine=True)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported normalization type: {}\".format(normalization))\n",
    "\n",
    "    def init_parameters(self):\n",
    "\n",
    "        for name, param in self.named_parameters():\n",
    "            stdv = 1. / math.sqrt(param.size(-1))\n",
    "            param.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(self.norm, nn.BatchNorm1d):\n",
    "            return self.norm(x.view(-1, x.shape[-1])).view(*x.shape)\n",
    "        elif isinstance(self.norm, nn.InstanceNorm1d):\n",
    "            return self.norm(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported normalization type: {}\".format(type(self.norm)))\n",
    "        \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, ff_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "122a6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads,\n",
    "        embed_dim,\n",
    "        ff_dim=512,\n",
    "        normalization='batch'\n",
    "    ):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            input_dim=embed_dim,\n",
    "            embed_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        self.ff = FeedForward(embed_dim=embed_dim, ff_dim=ff_dim)\n",
    "\n",
    "        self.norm1 = Normalization(embed_dim=embed_dim, normalization=normalization)\n",
    "        self.norm2 = Normalization(embed_dim=embed_dim, normalization=normalization)\n",
    "        \n",
    "        # self.act1 = nn.Tanh()\n",
    "        # self.act2 = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        mha_out = self.mha(x, h=x, mask=mask)\n",
    "        x = x + mha_out\n",
    "        x = self.norm1(x)\n",
    "        # x = self.act1(x)\n",
    "\n",
    "        ff_out = self.ff(x)\n",
    "        x = x + ff_out\n",
    "        x = self.norm2(x)\n",
    "        # x = self.act2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8de3e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "mha_layer = MultiHeadAttentionLayer(\n",
    "    num_heads=8,\n",
    "    embed_dim=128,\n",
    "    ff_dim=512,\n",
    "    normalization='batch'\n",
    ")\n",
    "x = torch.randn(32, 10, 128)\n",
    "y = mha_layer(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e4d3a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAttentionEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_heads,\n",
    "                 embed_dim,\n",
    "                 num_layers,\n",
    "                 node_dim=None,\n",
    "                 normalization='batch',\n",
    "                 ff_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init_embed = nn.Linear(node_dim, embed_dim) if node_dim is not None else None\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            MultiHeadAttentionLayer(\n",
    "                num_heads=num_heads,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                normalization=normalization\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        h = self.init_embed(x) if self.init_embed is not None else x\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, mask=mask)\n",
    "        \n",
    "        return h, h.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a3ea608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 128]) torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "encoder = GraphAttentionEncoder(\n",
    "    num_heads=8,\n",
    "    embed_dim=128,\n",
    "    num_layers=3,\n",
    "    node_dim=2,\n",
    "    normalization='batch',\n",
    "    ff_dim=512\n",
    ")\n",
    "sample = torch.randn(32, 10, 2)\n",
    "out_node, out_graph = encoder(sample)\n",
    "print(out_node.shape, out_graph.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2cc79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModelFixed(NamedTuple):\n",
    "    \n",
    "    node_embeddings: torch.Tensor\n",
    "    context_node_projected: torch.Tensor\n",
    "    glimpse_key: torch.Tensor\n",
    "    glimpse_val: torch.Tensor\n",
    "    logit_key: torch.Tensor\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        assert torch.is_tensor(key) or isinstance(key, slice)\n",
    "        return AttentionModelFixed(\n",
    "            node_embeddings=self.node_embeddings[key],\n",
    "            context_node_projected=self.context_node_projected[key],\n",
    "            glimpse_key=self.glimpse_key[:, key],  # dim 0 are the heads\n",
    "            glimpse_val=self.glimpse_val[:, key],  # dim 0 are the heads\n",
    "            logit_key=self.logit_key[key]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97ec9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed_dim,\n",
    "                 hidden_dim,\n",
    "                 problem,\n",
    "                 n_encode_layers=2,\n",
    "                 tanh_clipping=10.,\n",
    "                 mask_inner=True,\n",
    "                 mask_logits=True,\n",
    "                 normalization='batch',\n",
    "                 n_heads=8,\n",
    "                 checkpoint_encoder=False,\n",
    "                 shrink_size=None):\n",
    "        super(AttentionModel, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_encode_layers = n_encode_layers\n",
    "        self.tanh_clipping = tanh_clipping\n",
    "        self.decode_type = None\n",
    "        self.temp = 1.0\n",
    "        self.mask_inner = mask_inner\n",
    "        self.mask_logits = mask_logits\n",
    "        self.n_heads = n_heads\n",
    "        self.checkpoint_encoder = checkpoint_encoder\n",
    "        self.shrink_size = shrink_size\n",
    "        self.problem = problem\n",
    "\n",
    "        step_context_dim = embed_dim + 1\n",
    "        node_dim = 3\n",
    "\n",
    "        self.init_embed_depot = nn.Linear(2, embed_dim)\n",
    "        self.init_embed = nn.Linear(node_dim, embed_dim)\n",
    "\n",
    "        self.embedder = GraphAttentionEncoder(\n",
    "            num_heads=n_heads,\n",
    "            embed_dim=embed_dim,\n",
    "            num_layers=n_encode_layers,\n",
    "            # node_dim=node_dim,\n",
    "            normalization=normalization\n",
    "        )\n",
    "\n",
    "        self.project_node_embeddings = nn.Linear(embed_dim, 3 * embed_dim, bias=False)\n",
    "        self.project_fixed_context = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "        self.project_step_context = nn.Linear(step_context_dim, embed_dim, bias=False)\n",
    "\n",
    "        self.project_out = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "    \n",
    "    def set_decode_type(self, decode_type, temp=None):\n",
    "        self.decode_type = decode_type\n",
    "        if temp is not None:\n",
    "            self.temp = temp\n",
    "        \n",
    "    def forward(self, input, return_pi=False):\n",
    "\n",
    "        if self.checkpoint_encoder and self.training:\n",
    "            embeddings, _ = checkpoint(self.embedder, self._init_embed(input))\n",
    "        else:\n",
    "            embeddings, _ = self.embedder(self._init_embed(input))\n",
    "        \n",
    "        _log_p, pi = self._inner(input, embeddings)\n",
    "\n",
    "        cost, mask = self.problem.get_costs(input, pi)\n",
    "\n",
    "        ll = self._calc_log_likelihood(_log_p, pi, mask)\n",
    "        if return_pi:\n",
    "            return cost, ll, pi\n",
    "        else:\n",
    "            return cost, ll\n",
    "    \n",
    "    def _calc_log_likelihood(self, _log_p, a, mask):\n",
    "\n",
    "        log_p = _log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        if mask is not None:\n",
    "            log_p[mask] = 0\n",
    "        \n",
    "        return log_p.sum(1)\n",
    "\n",
    "    def _init_embed(self, input):\n",
    "\n",
    "        return torch.cat(\n",
    "            (\n",
    "                self.init_embed_depot(input['coords'][:, :1, 0:2]),\n",
    "                self.init_embed(torch.cat(\n",
    "                    (\n",
    "                        input['coords'][:, 1:, :],\n",
    "                        input['demand'][:, 1:, None],\n",
    "                    ),\n",
    "                    dim=-1\n",
    "                ))\n",
    "            ),\n",
    "            dim=1\n",
    "        )\n",
    "    \n",
    "    def _inner(self, input, embeddings):\n",
    "\n",
    "        outputs = []\n",
    "        sequences = []\n",
    "\n",
    "        state = self.problem.make_state(input)\n",
    "\n",
    "        fixed = self._precompute(embeddings)\n",
    "\n",
    "        batch_size = embeddings.size(0)\n",
    "\n",
    "        i = 0\n",
    "        while not (self.shrink_size is None and state.all_finished()):\n",
    "\n",
    "            if self.shrink_size is not None:\n",
    "                unfinished = torch.nonzero(state.get_finished() == 0)\n",
    "                if len(unfinished) == 0:\n",
    "                    break\n",
    "                unfinished = unfinished[:, 0]\n",
    "\n",
    "                if 16 <= len(unfinished) <= state.ids.size(0) - self.shrink_size:\n",
    "                    state = state[unfinished]\n",
    "                    fixed = fixed[unfinished]\n",
    "            \n",
    "            log_p, mask = self._get_log_p(fixed, state)\n",
    "\n",
    "            selected = self._select_node(log_p.exp()[:, 0, :], mask[:, 0, :])\n",
    "\n",
    "            state = state.update(selected)\n",
    "\n",
    "            if self.shrink_size is not None and state.ids.size(0) < batch_size:\n",
    "                log_p_, selected_ = log_p, selected\n",
    "                log_p = log_p_.new_zeros(batch_size, *log_p_.size()[1:])\n",
    "                selected = selected_.new_zeros(batch_size)\n",
    "\n",
    "                log_p[state.ids[:, 0]] = log_p_\n",
    "                selected[state.ids[:, 0]] = selected_\n",
    "            \n",
    "            outputs.append(log_p[:, 0, :])\n",
    "            sequences.append(selected)\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        return torch.stack(outputs, 1), torch.stack(sequences, 1)\n",
    "    \n",
    "    def _select_node(self, probs, mask):\n",
    "\n",
    "        if self.decode_type == \"greedy\":\n",
    "            _, selected = probs.max(1)\n",
    "\n",
    "        elif self.decode_type == \"sampling\":\n",
    "            selected = probs.multinomial(1).squeeze(1)\n",
    "\n",
    "            while mask.gather(1, selected.unsqueeze(-1)).data.any():\n",
    "                print('Sampled bad values, resampling!')\n",
    "                selected = probs.multinomial(1).squeeze(1)\n",
    "\n",
    "        return selected\n",
    "\n",
    "    def _precompute(self, embeddings, num_steps=1):\n",
    "\n",
    "        graph_embed = embeddings.mean(1)\n",
    "        fixed_context = self.project_fixed_context(graph_embed)[:, None, :]\n",
    "\n",
    "        glimpse_key_fixed, glimpse_val_fixed, logit_key_fixed = \\\n",
    "            self.project_node_embeddings(embeddings[:, None, :, :]).chunk(3, dim=-1)\n",
    "\n",
    "        fixed_attention_node_data = (\n",
    "            self._make_heads(glimpse_key_fixed, num_steps),\n",
    "            self._make_heads(glimpse_val_fixed, num_steps),\n",
    "            logit_key_fixed.contiguous()\n",
    "        )\n",
    "        return AttentionModelFixed(embeddings, fixed_context, *fixed_attention_node_data)\n",
    "    \n",
    "    def _get_parallel_step_context(self, embeddings, state, from_depot=False):\n",
    "\n",
    "        current_node = state.get_current_node()\n",
    "        batch_size, num_steps = current_node.size()\n",
    "\n",
    "        if from_depot:\n",
    "            return torch.cat(\n",
    "                (\n",
    "                    embeddings[:, 0:1, :].expand(batch_size, num_steps, embeddings.size(-1)),\n",
    "                    self.problem.VEHICLE_CAPACITY - torch.zeros_like(state.used_capacity[:, :, None])\n",
    "                ),\n",
    "                dim=-1\n",
    "            )\n",
    "        else:\n",
    "            return torch.cat(\n",
    "                (\n",
    "                    torch.gather(\n",
    "                        embeddings,\n",
    "                        1,\n",
    "                        current_node.contiguous().view(batch_size, num_steps, 1).expand(batch_size, num_steps, embeddings.size(-1))\n",
    "                    ).view(batch_size, num_steps, embeddings.size(-1)),\n",
    "                    self.problem.VEHICLE_CAPACITY - state.used_capacity[:, :, None]\n",
    "                ),\n",
    "                -1\n",
    "            )\n",
    "\n",
    "    def _get_log_p_topk(self, fixed, state, k=None, normalize=True):\n",
    "        log_p, _ = self._get_log_p(fixed, state, normalize=normalize)\n",
    "\n",
    "        if k is not None and k < log_p.size(-1):\n",
    "            return log_p.topk(k, -1)\n",
    "\n",
    "        return (\n",
    "            log_p,\n",
    "            torch.arange(log_p.size(-1), device=log_p.device, dtype=torch.int64).repeat(log_p.size(0), 1)[:, None, :]\n",
    "        )\n",
    "\n",
    "    def _get_log_p(self, fixed, state, normalize=True):\n",
    "\n",
    "        query = fixed.context_node_projected + \\\n",
    "                self.project_step_context(self._get_parallel_step_context(fixed.node_embeddings, state))\n",
    "\n",
    "        glimpse_K, glimpse_V, logit_K = self._get_attention_node_data(fixed, state)\n",
    "\n",
    "        mask = state.get_mask()\n",
    "\n",
    "        log_p, glimpse = self._one_to_many_logits(query, glimpse_K, glimpse_V, logit_K, mask)\n",
    "\n",
    "        if normalize:\n",
    "            log_p = torch.log_softmax(log_p / self.temp, dim=-1)\n",
    "\n",
    "        assert not torch.isnan(log_p).any()\n",
    "\n",
    "        return log_p, mask\n",
    "    \n",
    "    def _one_to_many_logits(self, query, glimpse_K, glimpse_V, logit_K, mask):\n",
    "\n",
    "        batch_size, num_steps, embed_dim = query.size()\n",
    "        key_size = val_size = embed_dim // self.n_heads\n",
    "\n",
    "        # Compute the glimpse, rearrange dimensions so the dimensions are (n_heads, batch_size, num_steps, 1, key_size)\n",
    "        glimpse_Q = query.view(batch_size, num_steps, self.n_heads, 1, key_size).permute(2, 0, 1, 3, 4)\n",
    "\n",
    "        # Batch matrix multiplication to compute compatibilities (n_heads, batch_size, num_steps, graph_size)\n",
    "        compatibility = torch.matmul(glimpse_Q, glimpse_K.transpose(-2, -1)) / math.sqrt(glimpse_Q.size(-1))\n",
    "        if self.mask_inner:\n",
    "            assert self.mask_logits, \"Cannot mask inner without masking logits\"\n",
    "            compatibility[mask[None, :, :, None, :].expand_as(compatibility)] = -math.inf\n",
    "\n",
    "        # Batch matrix multiplication to compute heads (n_heads, batch_size, num_steps, val_size)\n",
    "        heads = torch.matmul(torch.softmax(compatibility, dim=-1), glimpse_V)\n",
    "\n",
    "        # Project to get glimpse/updated context node embedding (batch_size, num_steps, embedding_dim)\n",
    "        glimpse = self.project_out(\n",
    "            heads.permute(1, 2, 3, 0, 4).contiguous().view(-1, num_steps, 1, self.n_heads * val_size))\n",
    "\n",
    "        # Now projecting the glimpse is not needed since this can be absorbed into project_out\n",
    "        # final_Q = self.project_glimpse(glimpse)\n",
    "        final_Q = glimpse\n",
    "        # Batch matrix multiplication to compute logits (batch_size, num_steps, graph_size)\n",
    "        # logits = 'compatibility'\n",
    "        logits = torch.matmul(final_Q, logit_K.transpose(-2, -1)).squeeze(-2) / math.sqrt(final_Q.size(-1))\n",
    "\n",
    "        # From the logits compute the probabilities by clipping, masking and softmax\n",
    "        if self.tanh_clipping > 0:\n",
    "            logits = torch.tanh(logits) * self.tanh_clipping\n",
    "        if self.mask_logits:\n",
    "            logits[mask] = -math.inf\n",
    "\n",
    "        return logits, glimpse.squeeze(-2)\n",
    "\n",
    "    def _get_attention_node_data(self, fixed, state):\n",
    "\n",
    "        return fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key\n",
    "\n",
    "    def _make_heads(self, v, num_steps=None):\n",
    "        assert num_steps is None or v.size(1) == 1 or v.size(1) == num_steps\n",
    "\n",
    "        return (\n",
    "            v.contiguous().view(v.size(0), v.size(1), v.size(2), self.n_heads, -1)\n",
    "            .expand(v.size(0), v.size(1) if num_steps is None else num_steps, v.size(2), self.n_heads, -1)\n",
    "            .permute(3, 0, 1, 2, 4)  # (n_heads, batch_size, num_steps, graph_size, head_dim)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "194cddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "def set_decode_type(model, decode_type):\n",
    "    if isinstance(model, DataParallel):\n",
    "        model = model.module\n",
    "    model.set_decode_type(decode_type)\n",
    "\n",
    "def get_inner_model(model):\n",
    "    return model.module if isinstance(model, DataParallel) else model\n",
    "\n",
    "def validate(model, dataset, opts):\n",
    "    # Validate\n",
    "    print('Validating...')\n",
    "    cost = rollout(model, dataset, opts)\n",
    "    avg_cost = cost.mean()\n",
    "    print('Validation overall avg_cost: {} +- {}'.format(\n",
    "        avg_cost, torch.std(cost) / math.sqrt(len(cost))))\n",
    "\n",
    "    return avg_cost\n",
    "\n",
    "def move_to(var, device):\n",
    "    if isinstance(var, dict):\n",
    "        return {k: move_to(v, device) for k, v in var.items()}\n",
    "    return var.to(device)\n",
    "\n",
    "def rollout(model, dataset, opts):\n",
    "    # Put in greedy evaluation mode!\n",
    "    set_decode_type(model, \"greedy\")\n",
    "    model.eval()\n",
    "\n",
    "    def eval_model_bat(bat):\n",
    "        with torch.no_grad():\n",
    "            cost, _ = model(move_to(bat, opts.device))\n",
    "        return cost.data.cpu()\n",
    "\n",
    "    return torch.cat([\n",
    "        eval_model_bat(bat)\n",
    "        for bat\n",
    "        in tqdm(DataLoader(dataset, batch_size=opts.eval_batch_size), disable=opts.no_progress_bar)\n",
    "    ], 0)\n",
    "\n",
    "def clip_grad_norms(param_groups, max_norm=math.inf):\n",
    "    \"\"\"\n",
    "    Clips the norms for all param groups to max_norm and returns gradient norms before clipping\n",
    "    :param optimizer:\n",
    "    :param max_norm:\n",
    "    :param gradient_norms_log:\n",
    "    :return: grad_norms, clipped_grad_norms: list with (clipped) gradient norms per group\n",
    "    \"\"\"\n",
    "    grad_norms = [\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            group['params'],\n",
    "            max_norm if max_norm > 0 else math.inf,  # Inf so no clipping but still call to calc\n",
    "            norm_type=2\n",
    "        )\n",
    "        for group in param_groups\n",
    "    ]\n",
    "    grad_norms_clipped = [min(g_norm, max_norm) for g_norm in grad_norms] if max_norm > 0 else grad_norms\n",
    "    return grad_norms, grad_norms_clipped\n",
    "\n",
    "def train_epoch(model, optimizer, baseline, lr_scheduler, epoch, val_dataset, problem, tb_logger, opts):\n",
    "    print(\"Start train epoch {}, lr={} for run {}\".format(epoch, optimizer.param_groups[0]['lr'], opts.run_name))\n",
    "    step = epoch * (opts.epoch_size // opts.batch_size)\n",
    "    start_time = time.time()\n",
    "\n",
    "    if not opts.no_tensorboard:\n",
    "        tb_logger.log_value('learnrate_pg0', optimizer.param_groups[0]['lr'], step)\n",
    "\n",
    "    # Generate new training data for each epoch\n",
    "    training_dataset = baseline.wrap_dataset(problem.make_dataset(opts.data_path))\n",
    "    training_dataloader = DataLoader(training_dataset, batch_size=opts.batch_size, num_workers=opts.num_workers)\n",
    "\n",
    "    # Put model in train mode!\n",
    "    model.train()\n",
    "    set_decode_type(model, \"sampling\")\n",
    "\n",
    "    for batch_id, batch in enumerate(tqdm(training_dataloader, disable=opts.no_progress_bar)):\n",
    "        train_batch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            baseline,\n",
    "            epoch,\n",
    "            batch_id,\n",
    "            step,\n",
    "            batch,\n",
    "            tb_logger,\n",
    "            opts\n",
    "        )\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    epoch_duration = time.time() - start_time\n",
    "    print(\"Finished epoch {}, took {} s\".format(epoch, time.strftime('%H:%M:%S', time.gmtime(epoch_duration))))\n",
    "\n",
    "    if (opts.checkpoint_epochs != 0 and epoch % opts.checkpoint_epochs == 0) or epoch == opts.n_epochs - 1:\n",
    "        print('Saving model and state...')\n",
    "        torch.save(\n",
    "            {\n",
    "                'model': get_inner_model(model).state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'rng_state': torch.get_rng_state(),\n",
    "                'cuda_rng_state': torch.cuda.get_rng_state_all(),\n",
    "                'baseline': baseline.state_dict()\n",
    "            },\n",
    "            os.path.join(opts.save_dir, 'epoch-{}.pt'.format(epoch))\n",
    "        )\n",
    "\n",
    "    avg_reward = validate(model, val_dataset, opts)\n",
    "\n",
    "    if not opts.no_tensorboard:\n",
    "        tb_logger.log_value('val_avg_reward', avg_reward, step)\n",
    "\n",
    "    baseline.epoch_callback(model, epoch)\n",
    "\n",
    "    # lr_scheduler should be called at end of epoch\n",
    "    lr_scheduler.step()\n",
    "\n",
    "def log_values(cost, grad_norms, epoch, batch_id, step,\n",
    "               log_likelihood, reinforce_loss, bl_loss, tb_logger, opts):\n",
    "    avg_cost = cost.mean().item()\n",
    "    grad_norms, grad_norms_clipped = grad_norms\n",
    "\n",
    "    # Log values to screen\n",
    "    print('epoch: {}, train_batch_id: {}, avg_cost: {}'.format(epoch, batch_id, avg_cost))\n",
    "\n",
    "    print('grad_norm: {}, clipped: {}'.format(grad_norms[0], grad_norms_clipped[0]))\n",
    "\n",
    "    # Log values to tensorboard\n",
    "    if not opts.no_tensorboard:\n",
    "        tb_logger.log_value('avg_cost', avg_cost, step)\n",
    "\n",
    "        tb_logger.log_value('actor_loss', reinforce_loss.item(), step)\n",
    "        tb_logger.log_value('nll', -log_likelihood.mean().item(), step)\n",
    "\n",
    "        tb_logger.log_value('grad_norm', grad_norms[0], step)\n",
    "        tb_logger.log_value('grad_norm_clipped', grad_norms_clipped[0], step)\n",
    "\n",
    "        if opts.baseline == 'critic':\n",
    "            tb_logger.log_value('critic_loss', bl_loss.item(), step)\n",
    "            tb_logger.log_value('critic_grad_norm', grad_norms[1], step)\n",
    "            tb_logger.log_value('critic_grad_norm_clipped', grad_norms_clipped[1], step)\n",
    "\n",
    "\n",
    "def train_batch(\n",
    "        model,\n",
    "        optimizer,\n",
    "        baseline,\n",
    "        epoch,\n",
    "        batch_id,\n",
    "        step,\n",
    "        batch,\n",
    "        tb_logger,\n",
    "        opts\n",
    "):\n",
    "    x, bl_val = baseline.unwrap_batch(batch)\n",
    "    x = move_to(x, opts.device)\n",
    "    bl_val = move_to(bl_val, opts.device) if bl_val is not None else None\n",
    "\n",
    "    # Evaluate model, get costs and log probabilities\n",
    "    cost, log_likelihood = model(x)\n",
    "\n",
    "    # Evaluate baseline, get baseline loss if any (only for critic)\n",
    "    bl_val, bl_loss = baseline.eval(x, cost) if bl_val is None else (bl_val, 0)\n",
    "\n",
    "    # Calculate loss\n",
    "    reinforce_loss = ((cost - bl_val) * log_likelihood).mean()\n",
    "    loss = reinforce_loss + bl_loss\n",
    "\n",
    "    # Perform backward pass and optimization step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # Clip gradient norms and get (clipped) gradient norms for logging\n",
    "    grad_norms = clip_grad_norms(optimizer.param_groups, opts.max_grad_norm)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    if step % int(opts.log_step) == 0:\n",
    "        log_values(cost, grad_norms, epoch, batch_id, step,\n",
    "                   log_likelihood, reinforce_loss, bl_loss, tb_logger, opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da7a2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import copy\n",
    "\n",
    "class Baseline(object):\n",
    "\n",
    "    def wrap_dataset(self, dataset):\n",
    "        return dataset\n",
    "\n",
    "    def unwrap_batch(self, batch):\n",
    "        return batch, None\n",
    "\n",
    "    def eval(self, x, c):\n",
    "        raise NotImplementedError(\"Override this method\")\n",
    "\n",
    "    def get_learnable_parameters(self):\n",
    "        return []\n",
    "\n",
    "    def epoch_callback(self, model, epoch):\n",
    "        pass\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        pass\n",
    "\n",
    "class RolloutBaseline(Baseline):\n",
    "\n",
    "    def __init__(self, model, problem, opts, epoch=0):\n",
    "        super(Baseline, self).__init__()\n",
    "\n",
    "        self.problem = problem\n",
    "        self.opts = opts\n",
    "\n",
    "        self._update_model(model, epoch)\n",
    "\n",
    "    def _update_model(self, model, epoch, dataset=None):\n",
    "        self.model = copy.deepcopy(model)\n",
    "        # Always generate baseline dataset when updating model to prevent overfitting to the baseline dataset\n",
    "\n",
    "        if dataset is not None:\n",
    "            if len(dataset) != self.opts.val_size:\n",
    "                print(\"Warning: not using saved baseline dataset since val_size does not match\")\n",
    "                dataset = None\n",
    "            elif (dataset[0] if self.problem.NAME == 'tsp' else dataset[0]['loc']).size(0) != self.opts.graph_size:\n",
    "                print(\"Warning: not using saved baseline dataset since graph_size does not match\")\n",
    "                dataset = None\n",
    "\n",
    "        if dataset is None:\n",
    "            self.dataset = self.problem.make_dataset(self.opts.data_path)\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "        print(\"Evaluating baseline model on evaluation dataset\")\n",
    "        self.bl_vals = rollout(self.model, self.dataset, self.opts).cpu().numpy()\n",
    "        self.mean = self.bl_vals.mean()\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def wrap_dataset(self, dataset):\n",
    "        print(\"Evaluating baseline on dataset...\")\n",
    "        # Need to convert baseline to 2D to prevent converting to double, see\n",
    "        # https://discuss.pytorch.org/t/dataloader-gives-double-instead-of-float/717/3\n",
    "        return BaselineDataset(dataset, rollout(self.model, dataset, self.opts).view(-1, 1))\n",
    "\n",
    "    def unwrap_batch(self, batch):\n",
    "        return batch['data'], batch['baseline'].view(-1)  # Flatten result to undo wrapping as 2D\n",
    "\n",
    "    def eval(self, x, c):\n",
    "        # Use volatile mode for efficient inference (single batch so we do not use rollout function)\n",
    "        with torch.no_grad():\n",
    "            v, _ = self.model(x)\n",
    "\n",
    "        # There is no loss\n",
    "        return v, 0\n",
    "\n",
    "    def epoch_callback(self, model, epoch):\n",
    "        \"\"\"\n",
    "        Challenges the current baseline with the model and replaces the baseline model if it is improved.\n",
    "        :param model: The model to challenge the baseline by\n",
    "        :param epoch: The current epoch\n",
    "        \"\"\"\n",
    "        print(\"Evaluating candidate model on evaluation dataset\")\n",
    "        candidate_vals = rollout(model, self.dataset, self.opts).cpu().numpy()\n",
    "\n",
    "        candidate_mean = candidate_vals.mean()\n",
    "\n",
    "        print(\"Epoch {} candidate mean {}, baseline epoch {} mean {}, difference {}\".format(\n",
    "            epoch, candidate_mean, self.epoch, self.mean, candidate_mean - self.mean))\n",
    "        if candidate_mean - self.mean < 0:\n",
    "            # Calc p value\n",
    "            t, p = ttest_rel(candidate_vals, self.bl_vals)\n",
    "\n",
    "            p_val = p / 2  # one-sided\n",
    "            assert t < 0, \"T-statistic should be negative\"\n",
    "            print(\"p-value: {}\".format(p_val))\n",
    "            if p_val < self.opts.bl_alpha:\n",
    "                print('Update baseline')\n",
    "                self._update_model(model, epoch)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            'model': self.model,\n",
    "            'dataset': self.dataset,\n",
    "            'epoch': self.epoch\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        # We make it such that it works whether model was saved as data parallel or not\n",
    "        load_model = copy.deepcopy(self.model)\n",
    "        get_inner_model(load_model).load_state_dict(get_inner_model(state_dict['model']).state_dict())\n",
    "        self._update_model(load_model, state_dict['epoch'], state_dict['dataset'])\n",
    "\n",
    "class BaselineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset=None, baseline=None):\n",
    "        super(BaselineDataset, self).__init__()\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.baseline = baseline\n",
    "        assert (len(self.dataset) == len(self.baseline))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'data': self.dataset[item],\n",
    "            'baseline': self.baseline[item]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "746e4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = CPDPTW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17c4c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionModel(\n",
    "    embed_dim=128,\n",
    "    hidden_dim=128,\n",
    "    problem=problem,\n",
    "    n_encode_layers=3,\n",
    "    tanh_clipping=10.,\n",
    "    mask_inner=True,\n",
    "    mask_logits=True,\n",
    "    normalization='batch',\n",
    "    n_heads=8,\n",
    "    checkpoint_encoder=False,\n",
    "    shrink_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "694beadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--problem', default='cvrp', help=\"The problem to solve, default 'cvrp'\")\n",
    "parser.add_argument('--graph_size', type=int, default=100, help=\"The size of the problem graph\")\n",
    "parser.add_argument('--batch_size', type=int, default=512, help='Number of instances per batch during training')\n",
    "parser.add_argument('--epoch_size', type=int, default=1280000, help='Number of instances per epoch during training')\n",
    "parser.add_argument('--val_size', type=int, default=10000,\n",
    "                    help='Number of instances used for reporting validation performance')\n",
    "parser.add_argument('--val_dataset', type=str, default=None, help='Dataset file to use for validation')\n",
    "parser.add_argument('--data_path', type=str, default=None, help='Path to data file to use for training')\n",
    "# Model\n",
    "parser.add_argument('--model', default='attention', help=\"Model, 'attention' (default) or 'pointer'\")\n",
    "parser.add_argument('--embedding_dim', type=int, default=128, help='Dimension of input embedding')\n",
    "parser.add_argument('--hidden_dim', type=int, default=128, help='Dimension of hidden layers in Enc/Dec')\n",
    "parser.add_argument('--n_encode_layers', type=int, default=3,\n",
    "                    help='Number of layers in the encoder/critic network')\n",
    "parser.add_argument('--tanh_clipping', type=float, default=10.,\n",
    "                    help='Clip the parameters to within +- this value using tanh. '\n",
    "                            'Set to 0 to not perform any clipping.')\n",
    "parser.add_argument('--normalization', default='batch', help=\"Normalization type, 'batch' (default) or 'instance'\")\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='Number of data loading workers')\n",
    "# Training\n",
    "parser.add_argument('--lr_model', type=float, default=1e-4, help=\"Set the learning rate for the actor network\")\n",
    "parser.add_argument('--lr_critic', type=float, default=1e-4, help=\"Set the learning rate for the critic network\")\n",
    "parser.add_argument('--lr_decay', type=float, default=1.0, help='Learning rate decay per epoch')\n",
    "parser.add_argument('--eval_only', action='store_true', help='Set this value to only evaluate model')\n",
    "parser.add_argument('--n_epochs', type=int, default=10, help='The number of epochs to train')\n",
    "parser.add_argument('--seed', type=int, default=1234, help='Random seed to use')\n",
    "parser.add_argument('--max_grad_norm', type=float, default=1.0,\n",
    "                    help='Maximum L2 norm for gradient clipping, default 1.0 (0 to disable clipping)')\n",
    "parser.add_argument('--no_cuda', action='store_true', help='Disable CUDA')\n",
    "parser.add_argument('--exp_beta', type=float, default=0.8,\n",
    "                    help='Exponential moving average baseline decay (default 0.8)')\n",
    "parser.add_argument('--baseline', default=None,\n",
    "                    help=\"Baseline to use: 'rollout', 'critic' or 'exponential'. Defaults to no baseline.\")\n",
    "parser.add_argument('--bl_alpha', type=float, default=0.05,\n",
    "                    help='Significance in the t-test for updating rollout baseline')\n",
    "parser.add_argument('--bl_warmup_epochs', type=int, default=None,\n",
    "                    help='Number of epochs to warmup the baseline, default None means 1 for rollout (exponential '\n",
    "                            'used for warmup phase), 0 otherwise. Can only be used with rollout baseline.')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=1024,\n",
    "                    help=\"Batch size to use during (baseline) evaluation\")\n",
    "parser.add_argument('--checkpoint_encoder', action='store_true',\n",
    "                    help='Set to decrease memory usage by checkpointing encoder')\n",
    "parser.add_argument('--shrink_size', type=int, default=None,\n",
    "                    help='Shrink the batch size if at least this many instances in the batch are finished'\n",
    "                            ' to save memory (default None means no shrinking)')\n",
    "parser.add_argument('--data_distribution', type=str, default=None,\n",
    "                    help='Data distribution to use during training, defaults and options depend on problem.')\n",
    "\n",
    "# Misc\n",
    "parser.add_argument('--log_step', type=int, default=50, help='Log info every log_step steps')\n",
    "parser.add_argument('--log_dir', default='logs', help='Directory to write TensorBoard information to')\n",
    "parser.add_argument('--run_name', default='run', help='Name to identify the run')\n",
    "parser.add_argument('--output_dir', default='outputs', help='Directory to write output models to')\n",
    "parser.add_argument('--epoch_start', type=int, default=0,\n",
    "                    help='Start at epoch # (relevant for learning rate decay)')\n",
    "parser.add_argument('--checkpoint_epochs', type=int, default=1,\n",
    "                    help='Save checkpoint every n epochs (default 1), 0 to save no checkpoints')\n",
    "parser.add_argument('--load_path', help='Path to load model parameters and optimizer state from')\n",
    "parser.add_argument('--resume', help='Resume from previous checkpoint file')\n",
    "parser.add_argument('--no_tensorboard', action='store_true', help='Disable logging TensorBoard files')\n",
    "parser.add_argument('--no_progress_bar', action='store_true', help='Disable progress bar')\n",
    "\n",
    "opts, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8bb1b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.save_dir = os.path.join(\n",
    "        opts.output_dir,\n",
    "        \"{}_{}\".format(opts.problem, opts.graph_size),\n",
    "        opts.run_name\n",
    "    )\n",
    "\n",
    "if not os.path.exists(opts.save_dir):\n",
    "    os.makedirs(opts.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07650200",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "from tensorboard_logger import Logger as TbLogger\n",
    "\n",
    "tb_logger = None\n",
    "if not opts.no_tensorboard:\n",
    "    tb_logger = TbLogger(os.path.join(opts.log_dir, \"{}_{}\".format(opts.problem, opts.graph_size), opts.run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0261ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts.data_path = 'D:/OneDrive - Hanoi University of Science and Technology/Projects/Project 1/Data/Sartori&Buriol/Instances/n100'\n",
    "opts.device = torch.device(\"cuda\" if not opts.no_cuda and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "714a8fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [01:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m baseline = \u001b[43mRolloutBaseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mRolloutBaseline.__init__\u001b[39m\u001b[34m(self, model, problem, opts, epoch)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mself\u001b[39m.problem = problem\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.opts = opts\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mRolloutBaseline._update_model\u001b[39m\u001b[34m(self, model, epoch, dataset)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m.dataset = dataset\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating baseline model on evaluation dataset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28mself\u001b[39m.bl_vals = \u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m.cpu().numpy()\n\u001b[32m     55\u001b[39m \u001b[38;5;28mself\u001b[39m.mean = \u001b[38;5;28mself\u001b[39m.bl_vals.mean()\n\u001b[32m     56\u001b[39m \u001b[38;5;28mself\u001b[39m.epoch = epoch\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mrollout\u001b[39m\u001b[34m(model, dataset, opts)\u001b[39m\n\u001b[32m     40\u001b[39m         cost, _ = model(move_to(bat, opts.device))\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cost.data.cpu()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat([\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[43meval_model_bat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m bat\n\u001b[32m     46\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m tqdm(DataLoader(dataset, batch_size=opts.eval_batch_size), disable=opts.no_progress_bar)\n\u001b[32m     47\u001b[39m ], \u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mrollout.<locals>.eval_model_bat\u001b[39m\u001b[34m(bat)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_model_bat\u001b[39m(bat):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         cost, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmove_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cost.data.cpu()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mAttentionModel.forward\u001b[39m\u001b[34m(self, input, return_pi)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     60\u001b[39m     embeddings, _ = \u001b[38;5;28mself\u001b[39m.embedder(\u001b[38;5;28mself\u001b[39m._init_embed(\u001b[38;5;28minput\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m _log_p, pi = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m cost, mask = \u001b[38;5;28mself\u001b[39m.problem.get_costs(\u001b[38;5;28minput\u001b[39m, pi)\n\u001b[32m     66\u001b[39m ll = \u001b[38;5;28mself\u001b[39m._calc_log_likelihood(_log_p, pi, mask)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mAttentionModel._inner\u001b[39m\u001b[34m(self, input, embeddings)\u001b[39m\n\u001b[32m    118\u001b[39m         state = state[unfinished]\n\u001b[32m    119\u001b[39m         fixed = fixed[unfinished]\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m log_p, mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_log_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m selected = \u001b[38;5;28mself\u001b[39m._select_node(log_p.exp()[:, \u001b[32m0\u001b[39m, :], mask[:, \u001b[32m0\u001b[39m, :])\n\u001b[32m    125\u001b[39m state = state.update(selected)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 222\u001b[39m, in \u001b[36mAttentionModel._get_log_p\u001b[39m\u001b[34m(self, fixed, state, normalize)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[32m    220\u001b[39m     log_p = torch.log_softmax(log_p / \u001b[38;5;28mself\u001b[39m.temp, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.isnan(log_p).any()\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m log_p, mask\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "baseline = RolloutBaseline(model, problem, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcac8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "        [{'params': model.parameters(), 'lr': opts.lr_model}]\n",
    "        + (\n",
    "            [{'params': baseline.get_learnable_parameters(), 'lr': opts.lr_critic}]\n",
    "            if len(baseline.get_learnable_parameters()) > 0\n",
    "            else []\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79a38593",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: opts.lr_decay ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09b4a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = problem.make_dataset(opts.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5fd590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train epoch 0, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.07s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_batch_id: 0, avg_cost: 8.995885848999023\n",
      "grad_norm: 447.7751770019531, clipped: 1.0\n",
      "Finished epoch 0, took 00:00:19 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.911255836486816 +- 0.9093583226203918\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 candidate mean 8.911255836486816, baseline epoch 0 mean 8.850387573242188, difference 0.060868263244628906\n",
      "Start train epoch 1, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.06s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_batch_id: 0, avg_cost: 9.065946578979492\n",
      "grad_norm: 218.26258850097656, clipped: 1.0\n",
      "Finished epoch 1, took 00:00:19 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.857662200927734 +- 0.9254476428031921\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 candidate mean 8.857662200927734, baseline epoch 0 mean 8.850387573242188, difference 0.007274627685546875\n",
      "Start train epoch 2, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train_batch_id: 0, avg_cost: 8.871148109436035\n",
      "grad_norm: 83.254638671875, clipped: 1.0\n",
      "Finished epoch 2, took 00:00:18 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.752636909484863 +- 0.9245193600654602\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 candidate mean 8.752636909484863, baseline epoch 0 mean 8.850387573242188, difference -0.09775066375732422\n",
      "p-value: 0.3506998689033214\n",
      "Start train epoch 3, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.19s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train_batch_id: 0, avg_cost: 8.91286849975586\n",
      "grad_norm: 69.4299545288086, clipped: 1.0\n",
      "Finished epoch 3, took 00:00:18 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 9.016470909118652 +- 0.9352046251296997\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 candidate mean 9.016471862792969, baseline epoch 0 mean 8.850387573242188, difference 0.16608428955078125\n",
      "Start train epoch 4, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.32s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train_batch_id: 0, avg_cost: 8.935649871826172\n",
      "grad_norm: 73.23657989501953, clipped: 1.0\n",
      "Finished epoch 4, took 00:00:17 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 9.004596710205078 +- 0.9468757510185242\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 candidate mean 9.004596710205078, baseline epoch 0 mean 8.850387573242188, difference 0.15420913696289062\n",
      "Start train epoch 5, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.85s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train_batch_id: 0, avg_cost: 8.856738090515137\n",
      "grad_norm: 65.8165054321289, clipped: 1.0\n",
      "Finished epoch 5, took 00:00:18 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.77841567993164 +- 0.8998194932937622\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 candidate mean 8.778414726257324, baseline epoch 0 mean 8.850387573242188, difference -0.07197284698486328\n",
      "p-value: 0.38910680996972424\n",
      "Start train epoch 6, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.80s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train_batch_id: 0, avg_cost: 8.885079383850098\n",
      "grad_norm: 66.68806457519531, clipped: 1.0\n",
      "Finished epoch 6, took 00:00:19 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.732073783874512 +- 0.9079993963241577\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 candidate mean 8.732073783874512, baseline epoch 0 mean 8.850387573242188, difference -0.11831378936767578\n",
      "p-value: 0.3102144704702242\n",
      "Start train epoch 7, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.33s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, train_batch_id: 0, avg_cost: 8.930704116821289\n",
      "grad_norm: 62.289859771728516, clipped: 1.0\n",
      "Finished epoch 7, took 00:00:19 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.508769989013672 +- 0.8822417259216309\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 candidate mean 8.508769035339355, baseline epoch 0 mean 8.850387573242188, difference -0.34161853790283203\n",
      "p-value: 0.07518459385571784\n",
      "Start train epoch 8, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.39s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train_batch_id: 0, avg_cost: 8.810266494750977\n",
      "grad_norm: 56.64892578125, clipped: 1.0\n",
      "Finished epoch 8, took 00:00:19 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.665833473205566 +- 0.9141497611999512\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 candidate mean 8.665833473205566, baseline epoch 0 mean 8.850387573242188, difference -0.1845541000366211\n",
      "p-value: 0.17983289605669572\n",
      "Start train epoch 9, lr=0.0001 for run run\n",
      "Evaluating baseline on dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.78s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train_batch_id: 0, avg_cost: 9.005243301391602\n",
      "grad_norm: 43.23209762573242, clipped: 1.0\n",
      "Finished epoch 9, took 00:00:20 s\n",
      "Saving model and state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation overall avg_cost: 8.744903564453125 +- 0.9270346760749817\n",
      "Evaluating candidate model on evaluation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 candidate mean 8.744903564453125, baseline epoch 0 mean 8.850387573242188, difference -0.1054840087890625\n",
      "p-value: 0.2908116412487632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if opts.eval_only:\n",
    "    validate(model, val_dataset, opts)\n",
    "else:\n",
    "    for epoch in range(opts.epoch_start, opts.epoch_start + opts.n_epochs):\n",
    "        train_epoch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            baseline,\n",
    "            lr_scheduler,\n",
    "            epoch,\n",
    "            val_dataset,\n",
    "            problem,\n",
    "            tb_logger,\n",
    "            opts\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8590f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Code inspired by Google OR Tools plot:\n",
    "# https://github.com/google/or-tools/blob/fb12c5ded7423d524fc6c95656a9bdc290a81d4d/examples/python/cvrptw_plot.py\n",
    "\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "  \"\"\"\n",
    "    Create an N-bin discrete colormap from the specified input map\n",
    "    \"\"\"\n",
    "  # Note that if base_cmap is a string or None, you can simply do\n",
    "  #    return plt.cm.get_cmap(base_cmap, N)\n",
    "  # The following works for string, None, or a colormap instance:\n",
    "\n",
    "  base = plt.cm.get_cmap(base_cmap)\n",
    "  color_list = base(np.linspace(0, 1, N))\n",
    "  cmap_name = base.name + str(N)\n",
    "  return base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "def plot_vehicle_routes(data, route, ax1, markersize=5, visualize_demands=False, demand_scale=1, round_demand=False):\n",
    "    \"\"\"\n",
    "    Plot the vehicle routes on matplotlib axis ax1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # route is one sequence, separating different routes with 0 (depot)\n",
    "    routes = [r[r!=0] for r in np.split(route.cpu().numpy(), np.where(route==0)[0]) if (r != 0).any()]\n",
    "    depot = data['coords'][0, :].cpu().numpy()\n",
    "    locs = data['coords'][1:, :].cpu().numpy()\n",
    "    demands = data['demand'].cpu().numpy() * demand_scale\n",
    "    capacity = demand_scale # Capacity is always 1\n",
    "    \n",
    "    x_dep, y_dep = depot\n",
    "    ax1.plot(x_dep, y_dep, 'sk', markersize=markersize*4)\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    legend = ax1.legend(loc='upper center')\n",
    "    \n",
    "    cmap = discrete_cmap(len(routes) + 2, 'nipy_spectral')\n",
    "    dem_rects = []\n",
    "    used_rects = []\n",
    "    cap_rects = []\n",
    "    qvs = []\n",
    "    total_dist = 0\n",
    "    for veh_number, r in enumerate(routes):\n",
    "        color = cmap(len(routes) - veh_number) # Invert to have in rainbow order\n",
    "        \n",
    "        route_demands = demands[r - 1]\n",
    "        coords = locs[r - 1, :]\n",
    "        xs, ys = coords.transpose()\n",
    "\n",
    "        total_route_demand = sum(route_demands)\n",
    "        assert total_route_demand <= capacity\n",
    "        if not visualize_demands:\n",
    "            ax1.plot(xs, ys, 'o', mfc=color, markersize=markersize, markeredgewidth=0.0)\n",
    "        \n",
    "        dist = 0\n",
    "        x_prev, y_prev = x_dep, y_dep\n",
    "        cum_demand = 0\n",
    "        for (x, y), d in zip(coords, route_demands):\n",
    "            dist += np.sqrt((x - x_prev) ** 2 + (y - y_prev) ** 2)\n",
    "            \n",
    "            cap_rects.append(Rectangle((x, y), 0.01, 0.1))\n",
    "            used_rects.append(Rectangle((x, y), 0.01, 0.1 * total_route_demand / capacity))\n",
    "            dem_rects.append(Rectangle((x, y + 0.1 * cum_demand / capacity), 0.01, 0.1 * d / capacity))\n",
    "            \n",
    "            x_prev, y_prev = x, y\n",
    "            cum_demand += d\n",
    "            \n",
    "        dist += np.sqrt((x_dep - x_prev) ** 2 + (y_dep - y_prev) ** 2)\n",
    "        total_dist += dist\n",
    "        qv = ax1.quiver(\n",
    "            xs[:-1],\n",
    "            ys[:-1],\n",
    "            xs[1:] - xs[:-1],\n",
    "            ys[1:] - ys[:-1],\n",
    "            scale_units='xy',\n",
    "            angles='xy',\n",
    "            scale=1,\n",
    "            color=color,\n",
    "            label='R{}, # {}, c {} / {}, d {:.2f}'.format(\n",
    "                veh_number, \n",
    "                len(r), \n",
    "                int(total_route_demand) if round_demand else total_route_demand, \n",
    "                int(capacity) if round_demand else capacity,\n",
    "                dist\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        qvs.append(qv)\n",
    "        \n",
    "    ax1.set_title('{} routes, total distance {:.2f}'.format(len(routes), total_dist))\n",
    "    ax1.legend(handles=qvs)\n",
    "    \n",
    "    pc_cap = PatchCollection(cap_rects, facecolor='whitesmoke', alpha=1.0, edgecolor='lightgray')\n",
    "    pc_used = PatchCollection(used_rects, facecolor='lightgray', alpha=1.0, edgecolor='lightgray')\n",
    "    pc_dem = PatchCollection(dem_rects, facecolor='black', alpha=1.0, edgecolor='black')\n",
    "    \n",
    "    if visualize_demands:\n",
    "        ax1.add_collection(pc_cap)\n",
    "        ax1.add_collection(pc_used)\n",
    "        ax1.add_collection(pc_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "616c3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "\n",
    "# Run the model\n",
    "model.eval()\n",
    "model.set_decode_type('greedy')\n",
    "with torch.no_grad():\n",
    "    length, log_p, pi = model(batch, return_pi=True)\n",
    "tours = pi\n",
    "\n",
    "# # Plot the results\n",
    "# for i, (data, tour) in enumerate(zip(dataset, tours)):\n",
    "#     fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#     plot_vehicle_routes(data, tour, ax, visualize_demands=False, demand_scale=50, round_demand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "96cbbc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[37, 29, 36,  ...,  0,  0,  0],\n",
       "        [12,  9, 59,  ...,  0, 15, 65],\n",
       "        [37, 11,  3,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [14, 30, 11,  ...,  0,  0,  0],\n",
       "        [23, 39, 13,  ...,  0,  0,  0],\n",
       "        [34, 16, 15,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab17fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateCVRP(NamedTuple):\n",
    "    # Fixed input\n",
    "    coords: torch.Tensor  # Depot + loc\n",
    "    demand: torch.Tensor\n",
    "\n",
    "    # If this state contains multiple copies (i.e. beam search) for the same instance, then for memory efficiency\n",
    "    # the coords and demands tensors are not kept multiple times, so we need to use the ids to index the correct rows.\n",
    "    ids: torch.Tensor  # Keeps track of original fixed data index of rows\n",
    "\n",
    "    # State\n",
    "    prev_a: torch.Tensor\n",
    "    used_capacity: torch.Tensor\n",
    "    visited_: torch.Tensor  # Keeps track of nodes that have been visited\n",
    "    lengths: torch.Tensor\n",
    "    cur_coord: torch.Tensor\n",
    "    i: torch.Tensor  # Keeps track of step\n",
    "\n",
    "    VEHICLE_CAPACITY = 1.0  # Hardcoded\n",
    "\n",
    "    @property\n",
    "    def visited(self):\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            return self.visited_\n",
    "        else:\n",
    "            return mask_long2bool(self.visited_, n=self.demand.size(-1))\n",
    "\n",
    "    @property\n",
    "    def dist(self):\n",
    "        return (self.coords[:, :, None, :] - self.coords[:, None, :, :]).norm(p=2, dim=-1)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        assert torch.is_tensor(key) or isinstance(key, slice)  # If tensor, idx all tensors by this tensor:\n",
    "        return self._replace(\n",
    "            ids=self.ids[key],\n",
    "            prev_a=self.prev_a[key],\n",
    "            used_capacity=self.used_capacity[key],\n",
    "            visited_=self.visited_[key],\n",
    "            lengths=self.lengths[key],\n",
    "            cur_coord=self.cur_coord[key],\n",
    "        )\n",
    "\n",
    "    # Warning: cannot override len of NamedTuple, len should be number of fields, not batch size\n",
    "    # def __len__(self):\n",
    "    #     return len(self.used_capacity)\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize(input, visited_dtype=torch.uint8):\n",
    "\n",
    "        depot = input['depot']\n",
    "        loc = input['loc']\n",
    "        demand = input['demand']\n",
    "\n",
    "        batch_size, n_loc, _ = loc.size()\n",
    "        return StateCVRP(\n",
    "            coords=torch.cat((depot[:, None, :], loc), -2),\n",
    "            demand=demand,\n",
    "            ids=torch.arange(batch_size, dtype=torch.int64, device=loc.device)[:, None],  # Add steps dimension\n",
    "            prev_a=torch.zeros(batch_size, 1, dtype=torch.long, device=loc.device),\n",
    "            used_capacity=demand.new_zeros(batch_size, 1),\n",
    "            visited_=(  # Visited as mask is easier to understand, as long more memory efficient\n",
    "                # Keep visited_ with depot so we can scatter efficiently\n",
    "                torch.zeros(\n",
    "                    batch_size, 1, n_loc + 1,\n",
    "                    dtype=torch.uint8, device=loc.device\n",
    "                )\n",
    "                if visited_dtype == torch.uint8\n",
    "                else torch.zeros(batch_size, 1, (n_loc + 63) // 64, dtype=torch.int64, device=loc.device)  # Ceil\n",
    "            ),\n",
    "            lengths=torch.zeros(batch_size, 1, device=loc.device),\n",
    "            cur_coord=input['depot'][:, None, :],  # Add step dimension\n",
    "            i=torch.zeros(1, dtype=torch.int64, device=loc.device)  # Vector with length num_steps\n",
    "        )\n",
    "\n",
    "    def get_final_cost(self):\n",
    "\n",
    "        assert self.all_finished()\n",
    "\n",
    "        return self.lengths + (self.coords[self.ids, 0, :] - self.cur_coord).norm(p=2, dim=-1)\n",
    "\n",
    "    def update(self, selected):\n",
    "\n",
    "        assert self.i.size(0) == 1, \"Can only update if state represents single step\"\n",
    "\n",
    "        # Update the state\n",
    "        selected = selected[:, None]  # Add dimension for step\n",
    "        prev_a = selected\n",
    "        n_loc = self.demand.size(-1)  # Excludes depot\n",
    "\n",
    "        # Add the length\n",
    "        cur_coord = self.coords[self.ids, selected]\n",
    "        # cur_coord = self.coords.gather(\n",
    "        #     1,\n",
    "        #     selected[:, None].expand(selected.size(0), 1, self.coords.size(-1))\n",
    "        # )[:, 0, :]\n",
    "        lengths = self.lengths + (cur_coord - self.cur_coord).norm(p=2, dim=-1)  # (batch_dim, 1)\n",
    "\n",
    "        # Not selected_demand is demand of first node (by clamp) so incorrect for nodes that visit depot!\n",
    "        #selected_demand = self.demand.gather(-1, torch.clamp(prev_a - 1, 0, n_loc - 1))\n",
    "        selected_demand = self.demand[self.ids, torch.clamp(prev_a - 1, 0, n_loc - 1)]\n",
    "\n",
    "        # Increase capacity if depot is not visited, otherwise set to 0\n",
    "        #used_capacity = torch.where(selected == 0, 0, self.used_capacity + selected_demand)\n",
    "        used_capacity = (self.used_capacity + selected_demand) * (prev_a != 0).float()\n",
    "\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            # Note: here we do not subtract one as we have to scatter so the first column allows scattering depot\n",
    "            # Add one dimension since we write a single value\n",
    "            visited_ = self.visited_.scatter(-1, prev_a[:, :, None], 1)\n",
    "        else:\n",
    "            # This works, will not set anything if prev_a -1 == -1 (depot)\n",
    "            visited_ = mask_long_scatter(self.visited_, prev_a - 1)\n",
    "\n",
    "        return self._replace(\n",
    "            prev_a=prev_a, used_capacity=used_capacity, visited_=visited_,\n",
    "            lengths=lengths, cur_coord=cur_coord, i=self.i + 1\n",
    "        )\n",
    "\n",
    "    def all_finished(self):\n",
    "        return self.i.item() >= self.demand.size(-1) and self.visited.all()\n",
    "\n",
    "    def get_finished(self):\n",
    "        return self.visited.sum(-1) == self.visited.size(-1)\n",
    "\n",
    "    def get_current_node(self):\n",
    "        return self.prev_a\n",
    "\n",
    "    def get_mask(self):\n",
    "        \"\"\"\n",
    "        Gets a (batch_size, n_loc + 1) mask with the feasible actions (0 = depot), depends on already visited and\n",
    "        remaining capacity. 0 = feasible, 1 = infeasible\n",
    "        Forbids to visit depot twice in a row, unless all nodes have been visited\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if self.visited_.dtype == torch.uint8:\n",
    "            visited_loc = self.visited_[:, :, 1:]\n",
    "        else:\n",
    "            visited_loc = mask_long2bool(self.visited_, n=self.demand.size(-1))\n",
    "\n",
    "        # For demand steps_dim is inserted by indexing with id, for used_capacity insert node dim for broadcasting\n",
    "        exceeds_cap = (self.demand[self.ids, :] + self.used_capacity[:, :, None] > self.VEHICLE_CAPACITY)\n",
    "        # Nodes that cannot be visited are already visited or too much demand to be served now\n",
    "        mask_loc = visited_loc.to(exceeds_cap.dtype) | exceeds_cap\n",
    "        # print(mask_loc.shape)\n",
    "\n",
    "        # Cannot visit the depot if just visited and still unserved nodes\n",
    "        mask_depot = (self.prev_a == 0) & ((mask_loc == 0).int().sum(-1) > 0)\n",
    "        # print((self.prev_a==0),((mask_loc == 0).int().sum(-1)>0))\n",
    "        return torch.cat((mask_depot[:, :, None], mask_loc), -1)\n",
    "\n",
    "    def construct_solutions(self, actions):\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate sample usage\n",
    "CAPACITIES = {\n",
    "                10: 20.,\n",
    "                20: 30.,\n",
    "                50: 40.,\n",
    "                100: 50.\n",
    "            }\n",
    "size = 20\n",
    "num_samples = 2\n",
    "\n",
    "data = {\n",
    "        'loc': torch.FloatTensor(num_samples, size, 2).uniform_(0, 1),\n",
    "        # Uniform 1 - 9, scaled by capacities\n",
    "        'demand': (torch.FloatTensor(num_samples, size).uniform_(0, 9).int() + 1).float() / CAPACITIES[size],\n",
    "        'depot': torch.FloatTensor(num_samples, 2).uniform_(0, 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b23d9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 21])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = StateCVRP.initialize(data)\n",
    "# state = state.update(selected=torch.tensor([3, 1]))\n",
    "# state = state.update(selected=torch.tensor([5, 3]))\n",
    "# state = state.update(selected=torch.tensor([0, 2]))\n",
    "state.get_mask().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4abe09ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Actions: tensor([ 6, 12]), Used Capacity: [0.30000001192092896, 0.13333334028720856]\n",
      "Step 2, Actions: tensor([5, 9]), Used Capacity: [0.6000000238418579, 0.3333333432674408]\n",
      "Step 3, Actions: tensor([3, 0]), Used Capacity: [0.800000011920929, 0.0]\n",
      "Step 4, Actions: tensor([8, 1]), Used Capacity: [0.8333333730697632, 0.30000001192092896]\n",
      "Step 5, Actions: tensor([15,  6]), Used Capacity: [0.8666667342185974, 0.36666667461395264]\n",
      "Step 6, Actions: tensor([0, 7]), Used Capacity: [0.0, 0.6666666865348816]\n",
      "Step 7, Actions: tensor([ 1, 19]), Used Capacity: [0.30000001192092896, 0.7000000476837158]\n",
      "Step 8, Actions: tensor([14, 17]), Used Capacity: [0.4333333373069763, 0.73333340883255]\n",
      "Step 9, Actions: tensor([16, 13]), Used Capacity: [0.5, 0.9000000953674316]\n",
      "Step 10, Actions: tensor([10,  0]), Used Capacity: [0.7666666507720947, 0.0]\n",
      "Step 11, Actions: tensor([0, 2]), Used Capacity: [0.0, 0.30000001192092896]\n",
      "Step 12, Actions: tensor([12, 16]), Used Capacity: [0.20000000298023224, 0.5]\n",
      "Step 13, Actions: tensor([0, 3]), Used Capacity: [0.0, 0.6666666865348816]\n",
      "Step 14, Actions: tensor([18,  5]), Used Capacity: [0.1666666716337204, 0.9333333969116211]\n",
      "Step 15, Actions: tensor([19, 20]), Used Capacity: [0.2666666805744171, 0.9666667580604553]\n",
      "Step 16, Actions: tensor([7, 0]), Used Capacity: [0.5, 0.0]\n",
      "Step 17, Actions: tensor([ 9, 10]), Used Capacity: [0.800000011920929, 0.2666666805744171]\n",
      "Step 18, Actions: tensor([2, 0]), Used Capacity: [0.9333333373069763, 0.0]\n",
      "Step 19, Actions: tensor([ 0, 11]), Used Capacity: [0.0, 0.06666667014360428]\n",
      "Step 20, Actions: tensor([17, 14]), Used Capacity: [0.1666666716337204, 0.3333333432674408]\n",
      "Step 21, Actions: tensor([20,  8]), Used Capacity: [0.4333333373069763, 0.6000000238418579]\n",
      "Step 22, Actions: tensor([11, 18]), Used Capacity: [0.7333333492279053, 0.8666666746139526]\n",
      "Step 23, Actions: tensor([ 0, 15]), Used Capacity: [0.0, 0.9000000357627869]\n",
      "Step 24, Actions: tensor([13,  0]), Used Capacity: [0.23333333432674408, 0.0]\n",
      "Step 25, Actions: tensor([0, 4]), Used Capacity: [0.0, 0.10000000149011612]\n",
      "Step 26, Actions: tensor([4, 0]), Used Capacity: [0.30000001192092896, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#Simulate environment\n",
    "\n",
    "B = 2\n",
    "N = 21\n",
    "step = 0\n",
    "all_actions = []         # to store actions at each step\n",
    "all_used_capacity = []   # optional\n",
    "\n",
    "while not state.all_finished():\n",
    "    # STEP 1: Random logits for actions (could come from a model)\n",
    "    logits = torch.randn(B, N)\n",
    "\n",
    "    mask = state.get_mask().squeeze(1)\n",
    "\n",
    "    # STEP 2: Apply mask â†’ invalid actions should never be selected\n",
    "    masked_logits = logits.masked_fill(mask, float('-inf'))\n",
    "\n",
    "    # STEP 3: Sample action using Categorical distribution\n",
    "    dist = torch.distributions.Categorical(logits=masked_logits)\n",
    "    actions = dist.sample()  # shape: (B,), each in [0, N-1]\n",
    "\n",
    "    # STEP 4: Update environment â€” you define this logic\n",
    "    # Example: increase state by action ID\n",
    "    state = state.update(selected=actions)\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    all_actions.append(actions)\n",
    "    all_used_capacity.append(state.used_capacity.squeeze(1).tolist())\n",
    "\n",
    "    print(f\"Step {step}, Actions: {actions}, Used Capacity: {state.used_capacity.squeeze(1).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "407b3d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateCVRP(coords=tensor([[[0.9359, 0.8094],\n",
       "         [0.3842, 0.9583],\n",
       "         [0.0892, 0.4242],\n",
       "         [0.1374, 0.0858],\n",
       "         [0.5848, 0.5434],\n",
       "         [0.8646, 0.2474],\n",
       "         [0.2220, 0.0850],\n",
       "         [0.7090, 0.1951],\n",
       "         [0.0187, 0.9646],\n",
       "         [0.0357, 0.7732],\n",
       "         [0.0245, 0.8721],\n",
       "         [0.0467, 0.1822],\n",
       "         [0.4289, 0.7181],\n",
       "         [0.5766, 0.0239],\n",
       "         [0.3267, 0.2894],\n",
       "         [0.7753, 0.0683],\n",
       "         [0.3620, 0.5189],\n",
       "         [0.4260, 0.5312],\n",
       "         [0.1635, 0.0479],\n",
       "         [0.8702, 0.1300],\n",
       "         [0.7979, 0.8993]],\n",
       "\n",
       "        [[0.0892, 0.4157],\n",
       "         [0.0515, 0.1085],\n",
       "         [0.1209, 0.7558],\n",
       "         [0.9405, 0.1585],\n",
       "         [0.1589, 0.8651],\n",
       "         [0.3682, 0.9875],\n",
       "         [0.3204, 0.5968],\n",
       "         [0.4885, 0.7541],\n",
       "         [0.5534, 0.1837],\n",
       "         [0.9547, 0.7369],\n",
       "         [0.4706, 0.6497],\n",
       "         [0.9392, 0.1252],\n",
       "         [0.9775, 0.8978],\n",
       "         [0.5726, 0.8046],\n",
       "         [0.2181, 0.8927],\n",
       "         [0.0345, 0.7501],\n",
       "         [0.2662, 0.5151],\n",
       "         [0.0745, 0.8483],\n",
       "         [0.7544, 0.2627],\n",
       "         [0.4130, 0.7006],\n",
       "         [0.6913, 0.2014]]]), demand=tensor([[0.3000, 0.1333, 0.2000, 0.3000, 0.3000, 0.3000, 0.2333, 0.0333, 0.3000,\n",
       "         0.2667, 0.3000, 0.2000, 0.2333, 0.1333, 0.0333, 0.0667, 0.1667, 0.1667,\n",
       "         0.1000, 0.2667],\n",
       "        [0.3000, 0.3000, 0.1667, 0.1000, 0.2667, 0.0667, 0.3000, 0.2667, 0.2000,\n",
       "         0.2667, 0.0667, 0.1333, 0.1667, 0.2667, 0.0333, 0.2000, 0.0333, 0.2667,\n",
       "         0.0333, 0.0333]]), ids=tensor([[0],\n",
       "        [1]]), prev_a=tensor([[4],\n",
       "        [0]]), used_capacity=tensor([[0.3000],\n",
       "        [0.0000]]), visited_=tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
       "       dtype=torch.uint8), lengths=tensor([[18.6897],\n",
       "        [14.6221]]), cur_coord=tensor([[[0.5848, 0.5434]],\n",
       "\n",
       "        [[0.0892, 0.4157]]]), i=tensor([26]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dca306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
